{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "sys.path.append('./mcunet')\n",
    "\n",
    "from mcunet.gumbel_module.gumbel_net import GumbelMCUNets\n",
    "\n",
    "from mcunet.tinynas.nn.modules import MBInvertedConvLayer\n",
    "from mcunet.tinynas.nn.networks import MobileInvertedResidualBlock\n",
    "from mcunet.model_zoo import build_model\n",
    "\n",
    "from mcunet.utils import MyModule, MyNetwork, SEModule, build_activation, get_same_padding, sub_filter_start_end\n",
    "from mcunet.tinynas.nn.modules import ZeroLayer, set_layer_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, img_size, desc = build_model(net_id='mcunet-in4', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'name': 'MobileInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBInvertedConvLayer', 'in_channels': 32, 'out_channels': 16, 'kernel_size': 3, 'stride': 1, 'expand_ratio': 1, 'mid_channels': None, 'act_func': 'relu6', 'use_se': False}, 'shortcut': None}\n",
      "1 {'name': 'MobileInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBInvertedConvLayer', 'in_channels': 16, 'out_channels': 24, 'kernel_size': 7, 'stride': 2, 'expand_ratio': 3, 'mid_channels': 48, 'act_func': 'relu6', 'use_se': False}, 'shortcut': None}\n",
      "load first_conv.conv.weight params (torch.Size([32, 3, 3, 3]))\n",
      "load first_conv.bn.weight params (torch.Size([32]))\n",
      "load first_conv.bn.bias params (torch.Size([32]))\n",
      "load blocks.0.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([32, 1, 3, 3]))\n",
      "load blocks.0.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([32]))\n",
      "load blocks.0.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([32]))\n",
      "load blocks.0.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([16, 32, 1, 1]))\n",
      "load blocks.0.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([16]))\n",
      "load blocks.0.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([16]))\n",
      "load blocks.1.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([48, 16, 1, 1]))\n",
      "load blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([48]))\n",
      "load blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([48]))\n",
      "load blocks.1.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([48, 1, 7, 7]))\n",
      "load blocks.1.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([48]))\n",
      "load blocks.1.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([48]))\n",
      "load blocks.1.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([24, 48, 1, 1]))\n",
      "load blocks.1.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([24]))\n",
      "load blocks.1.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([24]))\n",
      "load blocks.2.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([120, 24, 1, 1]))\n",
      "load blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([120]))\n",
      "load blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([120]))\n",
      "load blocks.2.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([120, 1, 3, 3]))\n",
      "load blocks.2.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([120]))\n",
      "load blocks.2.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([120]))\n",
      "load blocks.2.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([24, 120, 1, 1]))\n",
      "load blocks.2.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([24]))\n",
      "load blocks.2.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([24]))\n",
      "load blocks.3.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([96, 24, 1, 1]))\n",
      "load blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([96]))\n",
      "load blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([96]))\n",
      "load blocks.3.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([96, 1, 5, 5]))\n",
      "load blocks.3.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([96]))\n",
      "load blocks.3.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([96]))\n",
      "load blocks.3.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([24, 96, 1, 1]))\n",
      "load blocks.3.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([24]))\n",
      "load blocks.3.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([24]))\n",
      "load blocks.4.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([120, 24, 1, 1]))\n",
      "load blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([120]))\n",
      "load blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([120]))\n",
      "load blocks.4.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([120, 1, 7, 7]))\n",
      "load blocks.4.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([120]))\n",
      "load blocks.4.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([120]))\n",
      "load blocks.4.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([40, 120, 1, 1]))\n",
      "load blocks.4.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([40]))\n",
      "load blocks.4.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([40]))\n",
      "load blocks.5.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([160, 40, 1, 1]))\n",
      "load blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([160]))\n",
      "load blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([160]))\n",
      "load blocks.5.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([160, 1, 3, 3]))\n",
      "load blocks.5.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([160]))\n",
      "load blocks.5.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([160]))\n",
      "load blocks.5.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([40, 160, 1, 1]))\n",
      "load blocks.5.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([40]))\n",
      "load blocks.5.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([40]))\n",
      "load blocks.6.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([160, 40, 1, 1]))\n",
      "load blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([160]))\n",
      "load blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([160]))\n",
      "load blocks.6.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([160, 1, 7, 7]))\n",
      "load blocks.6.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([160]))\n",
      "load blocks.6.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([160]))\n",
      "load blocks.6.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([40, 160, 1, 1]))\n",
      "load blocks.6.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([40]))\n",
      "load blocks.6.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([40]))\n",
      "load blocks.7.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([120, 40, 1, 1]))\n",
      "load blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([120]))\n",
      "load blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([120]))\n",
      "load blocks.7.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([120, 1, 7, 7]))\n",
      "load blocks.7.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([120]))\n",
      "load blocks.7.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([120]))\n",
      "load blocks.7.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([80, 120, 1, 1]))\n",
      "load blocks.7.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([80]))\n",
      "load blocks.7.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([80]))\n",
      "load blocks.8.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([240, 80, 1, 1]))\n",
      "load blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([240]))\n",
      "load blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([240]))\n",
      "load blocks.8.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([240, 1, 3, 3]))\n",
      "load blocks.8.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([240]))\n",
      "load blocks.8.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([240]))\n",
      "load blocks.8.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([80, 240, 1, 1]))\n",
      "load blocks.8.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([80]))\n",
      "load blocks.8.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([80]))\n",
      "load blocks.9.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([240, 80, 1, 1]))\n",
      "load blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([240]))\n",
      "load blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([240]))\n",
      "load blocks.9.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([240, 1, 7, 7]))\n",
      "load blocks.9.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([240]))\n",
      "load blocks.9.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([240]))\n",
      "load blocks.9.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([80, 240, 1, 1]))\n",
      "load blocks.9.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([80]))\n",
      "load blocks.9.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([80]))\n",
      "load blocks.10.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([320, 80, 1, 1]))\n",
      "load blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([320]))\n",
      "load blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([320]))\n",
      "load blocks.10.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([320, 1, 3, 3]))\n",
      "load blocks.10.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([320]))\n",
      "load blocks.10.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([320]))\n",
      "load blocks.10.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([96, 320, 1, 1]))\n",
      "load blocks.10.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([96]))\n",
      "load blocks.10.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([96]))\n",
      "load blocks.11.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([288, 96, 1, 1]))\n",
      "load blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([288]))\n",
      "load blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([288]))\n",
      "load blocks.11.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([288, 1, 5, 5]))\n",
      "load blocks.11.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([288]))\n",
      "load blocks.11.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([288]))\n",
      "load blocks.11.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([96, 288, 1, 1]))\n",
      "load blocks.11.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([96]))\n",
      "load blocks.11.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([96]))\n",
      "load blocks.12.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([288, 96, 1, 1]))\n",
      "load blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([288]))\n",
      "load blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([288]))\n",
      "load blocks.12.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([288, 1, 5, 5]))\n",
      "load blocks.12.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([288]))\n",
      "load blocks.12.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([288]))\n",
      "load blocks.12.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([96, 288, 1, 1]))\n",
      "load blocks.12.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([96]))\n",
      "load blocks.12.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([96]))\n",
      "load blocks.13.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([384, 96, 1, 1]))\n",
      "load blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([384]))\n",
      "load blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([384]))\n",
      "load blocks.13.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([384, 1, 7, 7]))\n",
      "load blocks.13.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([384]))\n",
      "load blocks.13.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([384]))\n",
      "load blocks.13.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([192, 384, 1, 1]))\n",
      "load blocks.13.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([192]))\n",
      "load blocks.13.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([192]))\n",
      "load blocks.14.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([576, 192, 1, 1]))\n",
      "load blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([576]))\n",
      "load blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([576]))\n",
      "load blocks.14.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([576, 1, 7, 7]))\n",
      "load blocks.14.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([576]))\n",
      "load blocks.14.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([576]))\n",
      "load blocks.14.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([192, 576, 1, 1]))\n",
      "load blocks.14.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([192]))\n",
      "load blocks.14.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([192]))\n",
      "load blocks.15.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([576, 192, 1, 1]))\n",
      "load blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([576]))\n",
      "load blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([576]))\n",
      "load blocks.15.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([576, 1, 5, 5]))\n",
      "load blocks.15.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([576]))\n",
      "load blocks.15.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([576]))\n",
      "load blocks.15.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([192, 576, 1, 1]))\n",
      "load blocks.15.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([192]))\n",
      "load blocks.15.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([192]))\n",
      "load blocks.16.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([768, 192, 1, 1]))\n",
      "load blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([768]))\n",
      "load blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([768]))\n",
      "load blocks.16.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([768, 1, 5, 5]))\n",
      "load blocks.16.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([768]))\n",
      "load blocks.16.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([768]))\n",
      "load blocks.16.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([320, 768, 1, 1]))\n",
      "load blocks.16.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([320]))\n",
      "load blocks.16.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([320]))\n",
      "load classifier.linear.weight params (torch.Size([1000, 320]))\n",
      "load classifier.linear.bias params (torch.Size([1000]))\n"
     ]
    }
   ],
   "source": [
    "gubmel_config = {'global_expand_ratio_list':[1,3,5,6], 'global_kernel_size_list':[3,5,7], 'gumbel_feature_extract_block':2}\n",
    "net = GumbelMCUNets.build_from_config(model.config, gubmel_config)\n",
    "net.load_pretrained_mcunet_param(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(16, 3, 160, 160)\n",
    "\n",
    "out = net.forward_original(inputs)\n",
    "out2 = model.forward(inputs)\n",
    "+\n",
    "print(out - out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before forward grad :  None\n",
      "0 idx 0 expand 3 kernel 1\n",
      "gumbel shape :  torch.Size([32, 3])\n",
      "1 idx 3 expand 1 kernel 2\n",
      "gumbel shape :  torch.Size([32, 2])\n",
      "1 4 3 5 torch.Size([96, 1, 5, 5])\n",
      "2 idx 5 expand 3 kernel 3\n",
      "3 idx 11 expand 1 kernel 1\n",
      "4 idx 11 expand 1 kernel 3\n",
      "gumbel shape :  torch.Size([32, 3])\n",
      "1 6 5 7 torch.Size([160, 1, 7, 7])\n",
      "1 4 3 5 torch.Size([160, 1, 7, 7])\n",
      "5 idx 14 expand 2 kernel 3\n",
      "6 idx 19 expand 2 kernel 1\n",
      "gumbel shape :  torch.Size([32, 2])\n",
      "7 idx 21 expand 2 kernel 3\n",
      "gumbel shape :  torch.Size([32, 5])\n",
      "1 6 5 7 torch.Size([240, 1, 7, 7])\n",
      "1 4 3 5 torch.Size([240, 1, 7, 7])\n",
      "8 idx 26 expand 1 kernel 1\n",
      "9 idx 26 expand 2 kernel 2\n",
      "gumbel shape :  torch.Size([32, 4])\n",
      "1 4 3 5 torch.Size([288, 1, 5, 5])\n",
      "10 idx 30 expand 2 kernel 2\n",
      "gumbel shape :  torch.Size([32, 4])\n",
      "1 4 3 5 torch.Size([288, 1, 5, 5])\n",
      "11 idx 34 expand 1 kernel 3\n",
      "12 idx 37 expand 2 kernel 3\n",
      "gumbel shape :  torch.Size([32, 5])\n",
      "1 6 5 7 torch.Size([576, 1, 7, 7])\n",
      "1 4 3 5 torch.Size([576, 1, 7, 7])\n",
      "13 idx 42 expand 2 kernel 2\n",
      "gumbel shape :  torch.Size([32, 4])\n",
      "1 4 3 5 torch.Size([576, 1, 5, 5])\n",
      "14 idx 46 expand 1 kernel 2\n",
      "after forward grad : \n",
      " tensor([[ 1.5579e-06, -3.6754e-07, -5.6299e-07,  ...,  2.2749e-06,\n",
      "         -1.1263e-06, -6.0949e-07],\n",
      "        [-5.6689e-06, -2.7243e-06,  7.6726e-06,  ..., -1.2923e-06,\n",
      "         -5.3162e-06, -5.8807e-06],\n",
      "        [ 4.3257e-07,  2.3587e-06, -5.6974e-06,  ..., -2.8985e-06,\n",
      "          6.0482e-07, -1.2306e-06],\n",
      "        ...,\n",
      "        [ 2.3472e-06, -2.7084e-07, -8.4750e-08,  ...,  2.2909e-07,\n",
      "         -2.2209e-06,  8.1460e-07],\n",
      "        [ 6.2847e-06,  3.0346e-06, -3.1045e-06,  ...,  1.5993e-06,\n",
      "          6.7801e-06,  7.1899e-06],\n",
      "        [-3.7265e-06,  2.1225e-08,  3.8718e-06,  ..., -3.8565e-06,\n",
      "          2.3975e-06, -2.5180e-07]])\n"
     ]
    }
   ],
   "source": [
    "print(\"before forward grad : \", net.gumbel_fc1.weight.grad)\n",
    "out = net(torch.randn(32, 3, 160, 160))\n",
    "\n",
    "out.sum().backward()\n",
    "\n",
    "print(\"after forward grad : \\n\", net.gumbel_fc1.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0600e-06, -1.1182e-06, -4.1251e-06,  ...,  7.1878e-06,\n",
       "          1.6874e-06,  2.5609e-06],\n",
       "        [ 6.7503e-06,  5.0171e-06, -5.8395e-06,  ...,  6.9475e-07,\n",
       "         -1.2265e-06,  8.7869e-06],\n",
       "        [-3.8922e-06, -2.3463e-06, -9.2838e-07,  ...,  4.8356e-06,\n",
       "         -4.1079e-06, -1.0903e-06],\n",
       "        ...,\n",
       "        [ 3.7491e-06,  4.1430e-06, -8.1688e-06,  ..., -1.1423e-05,\n",
       "         -5.2271e-06, -8.3704e-06],\n",
       "        [ 2.5260e-06,  1.3305e-06,  1.4562e-08,  ...,  9.1271e-06,\n",
       "         -3.0333e-06,  3.6833e-06],\n",
       "        [ 2.8772e-07, -1.1172e-06,  2.8125e-06,  ...,  7.8197e-07,\n",
       "          3.9362e-06, -2.5796e-07]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_conv.conv.weight\n",
      "first_conv.bn.weight\n",
      "first_conv.bn.bias\n",
      "blocks.0.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.0.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.0.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.0.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.0.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.0.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.1.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.1.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.1.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.1.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.1.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.1.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.1.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.2.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.2.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.2.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.2.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.2.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.2.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.2.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.3.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.3.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.3.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.3.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.3.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.3.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.3.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.4.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.4.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.4.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.4.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.4.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.4.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.4.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.5.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.5.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.5.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.5.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.5.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.5.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.5.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.6.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.6.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.6.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.6.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.6.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.6.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.6.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.7.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.7.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.7.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.7.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.7.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.7.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.7.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.8.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.8.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.8.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.8.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.8.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.8.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.8.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.9.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.9.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.9.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.9.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.9.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.9.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.9.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.10.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.10.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.10.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.10.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.10.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.10.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.10.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.11.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.11.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.11.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.11.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.11.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.11.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.11.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.12.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.12.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.12.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.12.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.12.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.12.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.12.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.13.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.13.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.13.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.13.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.13.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.13.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.13.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.14.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.14.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.14.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.14.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.14.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.14.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.14.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.15.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.15.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.15.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.15.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.15.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.15.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.15.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.16.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.16.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.16.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.16.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.16.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.16.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.16.mobile_inverted_conv.point_linear.bn.bias\n",
      "classifier.linear.weight\n",
      "classifier.linear.bias\n"
     ]
    }
   ],
   "source": [
    "for n, p in net.named_parameters():\n",
    "    if has_deep_attr(model, n):\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProxylessNASNets(\n",
       "  (first_conv): ConvLayer(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): ReLU6(inplace=True)\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(48, 48, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=48, bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(24, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
       "          (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(120, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (3): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (4): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(24, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(120, 120, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=120, bias=False)\n",
       "          (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (6): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160, bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (7): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(120, 120, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=120, bias=False)\n",
       "          (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(120, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (9): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(240, 240, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=240, bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (10): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(320, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "          (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (12): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "          (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (13): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=384, bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(576, 576, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=576, bias=False)\n",
       "          (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (15): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (16): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
       "          (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(768, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): LinearLayer(\n",
       "    (linear): Linear(in_features=320, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'MBGumbelInvertedConvLayer',\n",
       " 'in_channels': 16,\n",
       " 'out_channels': 24,\n",
       " 'kernel_size': 7,\n",
       " 'kernel_size_list': [7, 5, 3],\n",
       " 'stride': 2,\n",
       " 'expand_ratio': 3,\n",
       " 'expand_ratio_list': [1, 3],\n",
       " 'mid_channels': 48,\n",
       " 'act_func': 'relu6',\n",
       " 'use_se': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbconv_test = MBGumbelInvertedConvLayer.build_from_config(m.mobile_inverted_conv.config)\n",
    "mbconv_test.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(2, 16, 32, 32)\n",
    "gumbel_inputs = torch.randn(2, 4, 8, 8)\n",
    "gumbel_inputs.requires_grad = True\n",
    "gumbel_layer = nn.Linear(4*8*8, 5)\n",
    "gumbel_output = gumbel_layer(gumbel_inputs.view(2, -1))\n",
    "gumbel_index = F.gumbel_softmax(gumbel_output, tau=1, hard=True)\n",
    "print(gumbel_index)\n",
    "out = mbconv_test.forward(torch.randn(2, 16, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.]], grad_fn=<AddBackward0>)\n",
      "gumbel shape :  torch.Size([2, 5])\n",
      "1 6 5 7 torch.Size([48, 1, 7, 7])\n",
      "1 4 3 5 torch.Size([48, 1, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(2, 16, 32, 32)\n",
    "gumbel_inputs = torch.randn(2, 4, 8, 8)\n",
    "gumbel_inputs.requires_grad = True\n",
    "gumbel_layer = nn.Linear(4*8*8, 5)\n",
    "gumbel_output = gumbel_layer(gumbel_inputs.view(2, -1))\n",
    "gumbel_index = F.gumbel_softmax(gumbel_output, tau=1, hard=True)\n",
    "print(gumbel_index)\n",
    "out = mbconv_test.forward(torch.randn(2, 16, 32, 32), gumbel_index)\n",
    "out.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gumbel_layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_mbconv_test_weight = copy.deepcopy(mbconv_test.depth_conv.conv.weight)\n",
    "print(original_mbconv_test_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m.mobile_inverted_conv.depth_conv.conv.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in m.mobile_inverted_conv.named_parameters():\n",
    "    if has_deep_attr(mbconv_test, n):\n",
    "        print(n, p)\n",
    "        set_deep_attr(mbconv_test, n, p)\n",
    "        print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in m.mobile_inverted_conv.named_parameters():\n",
    "    if has_deep_attr(mbconv_test, n):\n",
    "        print(n)\n",
    "        print(get_deep_attr(mbconv_test, n) - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbconv_test.forward(torch.randn(1,32,16,16), gumbel=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_layer = nn.BatchNorm2d(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 12, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 12\n",
    "out = F.batch_norm(x, bn_layer.running_mean[:feature_dim], bn_layer.running_var[:feature_dim], bn_layer.weight[:feature_dim], bn_layer.bias[:feature_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, img_size, desc = build_model(net_id='mcunet-in4', pretrained=True)\n",
    "\n",
    "backup_model = copy.deepcopy(model)\n",
    "model_copy = build_model(net_id='mcunet-in4', pretrained=False)[0]\n",
    "\n",
    "for (n1, p1), (n2, p2) in zip(backup_model.named_parameters(), model_copy.named_parameters()):\n",
    "    if n1 == n2:\n",
    "        print((p1 - p2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    if has_deep_attr(model_copy, n):\n",
    "        print(n)\n",
    "        set_deep_attr(model_copy, n, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (n1, p1), (n2, p2) in zip(backup_model.named_parameters(), model_copy.named_parameters()):\n",
    "    if n1 == n2:\n",
    "        print((p1-p2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
