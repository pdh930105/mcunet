{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "sys.path.append('./mcunet')\n",
    "\n",
    "from mcunet.gumbel_module.gumbel_net import GumbelMCUNets\n",
    "from mcunet.gumbel_module.gumbel_layer import MBGumbelInvertedConvLayer, MobileGumbelInvertedResidualBlock\n",
    "from mcunet.tinynas.nn.modules import MBInvertedConvLayer\n",
    "from mcunet.tinynas.nn.networks import MobileInvertedResidualBlock\n",
    "from mcunet.model_zoo import build_model\n",
    "\n",
    "from mcunet.utils import MyModule, MyNetwork, SEModule, build_activation, get_same_padding, sub_filter_start_end\n",
    "from mcunet.tinynas.nn.modules import ZeroLayer, set_layer_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load pretrained mcumodel to gumbel net\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0 tensor(1, device='cuda:0')\n",
      "1 tensor(3, device='cuda:0')\n",
      "2 tensor(4, device='cuda:0')\n",
      "tensor([[1., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 1.]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "tensor([[0., 1., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 1.]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "tensor([[0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0 tensor(1, device='cuda:0')\n",
      "1 tensor(3, device='cuda:0')\n",
      "tensor([[0., 0., 1., 1., 0., 0.],\n",
      "        [0., 0., 1., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 1., 0., 0.],\n",
      "        [0., 0., 1., 1., 0., 0.],\n",
      "        [0., 1., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 1.]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "tensor([[0., 1., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [0., 1., 0., 1., 0.],\n",
      "        [1., 0., 0., 1., 0.],\n",
      "        [0., 1., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 1.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 0.],\n",
      "        [0., 1., 1., 0., 0.],\n",
      "        [0., 1., 0., 1., 0.],\n",
      "        [1., 0., 0., 1., 0.]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0 tensor(1, device='cuda:0')\n",
      "tensor([[0., 1., 1., 0., 0.],\n",
      "        [0., 1., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 1., 0.],\n",
      "        [0., 1., 1., 0., 0.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 1.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 1.]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "tensor([[0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0 tensor(1, device='cuda:0')\n",
      "1 tensor(3, device='cuda:0')\n",
      "tensor([[0., 1., 1., 0.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1.]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "tensor([[1., 0., 0., 1.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [1., 0., 0., 1.]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "tensor([[0., 0., 1., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 1., 0.],\n",
      "        [1., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 1., 0., 0.],\n",
      "        [0., 0., 1., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 0.]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "tensor([[1., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 1., 0.],\n",
      "        [0., 1., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 1.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [0., 1., 1., 0., 0.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [0., 1., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 1.]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "tensor([[0., 1., 0., 1.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [1., 0., 1., 0.]], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 1., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 1.],\n",
      "        [1., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 1.]], device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ori_model, img_size, desc = build_model(net_id='mcunet-in4', pretrained=True)\n",
    "gubmel_config = {'global_expand_ratio_list':[1,3,4,5,6], 'global_kernel_size_list':[3,5,7], 'gumbel_feature_extract_block':2}\n",
    "gumbel_model = GumbelMCUNets.build_from_config(ori_model.config, gubmel_config)\n",
    "gumbel_model.load_pretrained_mcunet_param(ori_model)\n",
    "\n",
    "inputs = torch.randn(16, 3, 160, 160)\n",
    "gumbel_model = gumbel_model.cuda()\n",
    "output, gumbel_list = gumbel_model.forward(inputs.cuda())\n",
    "#out = gumbel_model.forward_original(inputs)\n",
    "#out2 = ori_model.forward(inputs)\n",
    "#print((out - out2).sum())\n",
    "#gumbel_model.set_static_flops(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::add_ encountered 1 time(s)\n",
      "Unsupported operator aten::hardtanh_ encountered 1 time(s)\n",
      "Unsupported operator aten::hardtanh_ encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mobile_inverted_conv.depth_conv.bn, mobile_inverted_conv.point_linear.bn\n",
      "Unsupported operator aten::hardtanh_ encountered 2 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mobile_inverted_conv.depth_conv.bn, mobile_inverted_conv.inverted_bottleneck.bn, mobile_inverted_conv.point_linear.bn\n",
      "Unsupported operator aten::hardtanh_ encountered 2 time(s)\n",
      "Unsupported operator aten::add encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mobile_inverted_conv.depth_conv.bn, mobile_inverted_conv.inverted_bottleneck.bn, mobile_inverted_conv.point_linear.bn, shortcut\n",
      "Unsupported operator aten::hardtanh_ encountered 2 time(s)\n",
      "Unsupported operator aten::add encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mobile_inverted_conv.depth_conv.bn, mobile_inverted_conv.inverted_bottleneck.bn, mobile_inverted_conv.kernel_transform_linear_list.0, mobile_inverted_conv.point_linear.bn, shortcut\n",
      "Unsupported operator aten::hardtanh_ encountered 2 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mobile_inverted_conv.depth_conv.bn, mobile_inverted_conv.inverted_bottleneck.bn, mobile_inverted_conv.kernel_transform_linear_list.0, mobile_inverted_conv.kernel_transform_linear_list.1, mobile_inverted_conv.point_linear.bn\n",
      "Unsupported operator aten::hardtanh_ encountered 2 time(s)\n",
      "Unsupported operator aten::add encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mobile_inverted_conv.depth_conv.bn, mobile_inverted_conv.inverted_bottleneck.bn, mobile_inverted_conv.point_linear.bn, shortcut\n",
      "Unsupported operator aten::hardtanh_ encountered 2 time(s)\n",
      "Unsupported operator aten::add encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mobile_inverted_conv.depth_conv.bn, mobile_inverted_conv.inverted_bottleneck.bn, mobile_inverted_conv.kernel_transform_linear_list.0, mobile_inverted_conv.kernel_transform_linear_list.1, mobile_inverted_conv.point_linear.bn, shortcut\n",
      "Unsupported operator aten::hardtanh_ encountered 2 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mobile_inverted_conv.depth_conv.bn, mobile_inverted_conv.inverted_bottleneck.bn, mobile_inverted_conv.kernel_transform_linear_list.0, mobile_inverted_conv.kernel_transform_linear_list.1, mobile_inverted_conv.point_linear.bn\n",
      "Unsupported operator aten::hardtanh_ encountered 2 time(s)\n",
      "Unsupported operator aten::add encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mobile_inverted_conv.depth_conv.bn, mobile_inverted_conv.inverted_bottleneck.bn, mobile_inverted_conv.point_linear.bn, shortcut\n",
      "Unsupported operator aten::hardtanh_ encountered 2 time(s)\n",
      "Unsupported operator aten::add encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mobile_inverted_conv.depth_conv.bn, mobile_inverted_conv.inverted_bottleneck.bn, mobile_inverted_conv.kernel_transform_linear_list.0, mobile_inverted_conv.kernel_transform_linear_list.1, mobile_inverted_conv.point_linear.bn, shortcut\n",
      "Unsupported operator aten::hardtanh_ encountered 2 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mobile_inverted_conv.depth_conv.bn, mobile_inverted_conv.inverted_bottleneck.bn, mobile_inverted_conv.point_linear.bn\n",
      "Unsupported operator aten::hardtanh_ encountered 2 time(s)\n",
      "Unsupported operator aten::add encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mobile_inverted_conv.depth_conv.bn, mobile_inverted_conv.inverted_bottleneck.bn, mobile_inverted_conv.kernel_transform_linear_list.0, mobile_inverted_conv.point_linear.bn, shortcut\n",
      "Unsupported operator aten::hardtanh_ encountered 2 time(s)\n",
      "Unsupported operator aten::add encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mobile_inverted_conv.depth_conv.bn, mobile_inverted_conv.inverted_bottleneck.bn, mobile_inverted_conv.kernel_transform_linear_list.0, mobile_inverted_conv.point_linear.bn, shortcut\n",
      "Unsupported operator aten::hardtanh_ encountered 2 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mobile_inverted_conv.depth_conv.bn, mobile_inverted_conv.inverted_bottleneck.bn, mobile_inverted_conv.kernel_transform_linear_list.0, mobile_inverted_conv.kernel_transform_linear_list.1, mobile_inverted_conv.point_linear.bn\n",
      "Unsupported operator aten::hardtanh_ encountered 2 time(s)\n",
      "Unsupported operator aten::add encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mobile_inverted_conv.depth_conv.bn, mobile_inverted_conv.inverted_bottleneck.bn, mobile_inverted_conv.kernel_transform_linear_list.0, mobile_inverted_conv.kernel_transform_linear_list.1, mobile_inverted_conv.point_linear.bn, shortcut\n",
      "Unsupported operator aten::hardtanh_ encountered 2 time(s)\n",
      "Unsupported operator aten::add encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mobile_inverted_conv.depth_conv.bn, mobile_inverted_conv.inverted_bottleneck.bn, mobile_inverted_conv.kernel_transform_linear_list.0, mobile_inverted_conv.point_linear.bn, shortcut\n",
      "Unsupported operator aten::hardtanh_ encountered 2 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mobile_inverted_conv.depth_conv.bn, mobile_inverted_conv.inverted_bottleneck.bn, mobile_inverted_conv.kernel_transform_linear_list.0, mobile_inverted_conv.point_linear.bn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Log Static & Dynamic Flops : 367427584, 1670131200\n",
      "initialize FLOPs table\n",
      "expand ratio list > 1, kernel size list = 1\n",
      "inverted blocks flops : tensor([ 921600., 2764800., 3686400., 4608000.], device='cuda:0')\n",
      "dw blocks flops : tensor([14400., 43200., 57600., 72000.], device='cuda:0')\n",
      "pw blocks flops : tensor([ 4608000., 13824000., 18432000., 23040000.], device='cuda:0')\n",
      "initialize FLOPs table\n",
      "expand ratio list > 1 (3), kernel size list > 1 (2)\n",
      "inverted blocks flops : tensor([ 921600., 2764800., 3686400.], device='cuda:0')\n",
      "dw convert flops :,  tensor([   0., 7776.], device='cuda:0')\n",
      "dw blocks flops : tensor([3840000., 1382400.], device='cuda:0')\n",
      "pw blocks flops : tensor([ 3686400., 11059200., 14745600.], device='cuda:0')\n",
      "initialize FLOPs table\n",
      "expand ratio list > 1 (4), kernel size list > 1 (3)\n",
      "inverted blocks flops : tensor([ 921600., 2764800., 3686400., 4608000.], device='cuda:0')\n",
      "dw convert flops :,  tensor([    0., 75000., 84720.], device='cuda:0')\n",
      "dw blocks flops : tensor([18816000.,  9600000.,  3456000.], device='cuda:0')\n",
      "pw blocks flops : tensor([15360000., 46080000., 61440000., 76800000.], device='cuda:0')\n",
      "initialize FLOPs table\n",
      "expand ratio list > 1, kernel size list = 1\n",
      "inverted blocks flops : tensor([ 640000., 1920000., 2560000.], device='cuda:0')\n",
      "dw blocks flops : tensor([ 3600., 10800., 14400.], device='cuda:0')\n",
      "pw blocks flops : tensor([ 2560000.,  7680000., 10240000.], device='cuda:0')\n",
      "initialize FLOPs table\n",
      "expand ratio list > 1 (3), kernel size list > 1 (3)\n",
      "inverted blocks flops : tensor([ 640000., 1920000., 2560000.], device='cuda:0')\n",
      "dw convert flops :,  tensor([     0., 100000., 112960.], device='cuda:0')\n",
      "dw blocks flops : tensor([3136000., 1600000.,  576000.], device='cuda:0')\n",
      "pw blocks flops : tensor([ 2560000.,  7680000., 10240000.], device='cuda:0')\n",
      "initialize FLOPs table\n",
      "expand ratio list > 1 (2), kernel size list > 1 (3)\n",
      "inverted blocks flops : tensor([ 640000., 1920000.], device='cuda:0')\n",
      "dw convert flops :,  tensor([    0., 75000., 84720.], device='cuda:0')\n",
      "dw blocks flops : tensor([4704000., 2400000.,  864000.], device='cuda:0')\n",
      "pw blocks flops : tensor([ 7680000., 23040000.], device='cuda:0')\n",
      "initialize FLOPs table\n",
      "expand ratio list > 1, kernel size list = 1\n",
      "inverted blocks flops : tensor([ 640000., 1920000.], device='cuda:0')\n",
      "dw blocks flops : tensor([ 900., 2700.], device='cuda:0')\n",
      "pw blocks flops : tensor([1920000., 5760000.], device='cuda:0')\n",
      "initialize FLOPs table\n",
      "expand ratio list > 1 (2), kernel size list > 1 (3)\n",
      "inverted blocks flops : tensor([ 640000., 1920000.], device='cuda:0')\n",
      "dw convert flops :,  tensor([     0., 150000., 169440.], device='cuda:0')\n",
      "dw blocks flops : tensor([1176000.,  600000.,  216000.], device='cuda:0')\n",
      "pw blocks flops : tensor([1920000., 5760000.], device='cuda:0')\n",
      "initialize FLOPs table\n",
      "expand ratio list > 1, kernel size list = 1\n",
      "inverted blocks flops : tensor([ 640000., 1920000., 2560000.], device='cuda:0')\n",
      "dw blocks flops : tensor([ 900., 2700., 3600.], device='cuda:0')\n",
      "pw blocks flops : tensor([ 3072000.,  9216000., 12288000.], device='cuda:0')\n",
      "initialize FLOPs table\n",
      "expand ratio list > 1 (2), kernel size list > 1 (2)\n",
      "inverted blocks flops : tensor([ 921600., 2764800.], device='cuda:0')\n",
      "dw convert flops :,  tensor([    0., 23328.], device='cuda:0')\n",
      "dw blocks flops : tensor([720000., 259200.], device='cuda:0')\n",
      "pw blocks flops : tensor([2764800., 8294400.], device='cuda:0')\n",
      "initialize FLOPs table\n",
      "expand ratio list > 1 (2), kernel size list > 1 (2)\n",
      "inverted blocks flops : tensor([ 921600., 2764800.], device='cuda:0')\n",
      "dw convert flops :,  tensor([    0., 23328.], device='cuda:0')\n",
      "dw blocks flops : tensor([720000., 259200.], device='cuda:0')\n",
      "pw blocks flops : tensor([2764800., 8294400.], device='cuda:0')\n",
      "initialize FLOPs table\n",
      "expand ratio list > 1 (3), kernel size list > 1 (3)\n",
      "inverted blocks flops : tensor([ 921600., 2764800., 3686400.], device='cuda:0')\n",
      "dw convert flops :,  tensor([     0., 240000., 271104.], device='cuda:0')\n",
      "dw blocks flops : tensor([3763200., 1920000.,  691200.], device='cuda:0')\n",
      "pw blocks flops : tensor([14745600., 44236800., 58982400.], device='cuda:0')\n",
      "initialize FLOPs table\n",
      "expand ratio list > 1 (2), kernel size list > 1 (3)\n",
      "inverted blocks flops : tensor([ 921600., 2764800.], device='cuda:0')\n",
      "dw convert flops :,  tensor([     0., 360000., 406656.], device='cuda:0')\n",
      "dw blocks flops : tensor([705600., 360000., 129600.], device='cuda:0')\n",
      "pw blocks flops : tensor([2764800., 8294400.], device='cuda:0')\n",
      "initialize FLOPs table\n",
      "expand ratio list > 1 (2), kernel size list > 1 (2)\n",
      "inverted blocks flops : tensor([ 921600., 2764800.], device='cuda:0')\n",
      "dw convert flops :,  tensor([    0., 46656.], device='cuda:0')\n",
      "dw blocks flops : tensor([360000., 129600.], device='cuda:0')\n",
      "pw blocks flops : tensor([2764800., 8294400.], device='cuda:0')\n",
      "initialize FLOPs table\n",
      "expand ratio list > 1 (3), kernel size list > 1 (2)\n",
      "inverted blocks flops : tensor([ 921600., 2764800., 3686400.], device='cuda:0')\n",
      "dw convert flops :,  tensor([    0., 62208.], device='cuda:0')\n",
      "dw blocks flops : tensor([480000., 172800.], device='cuda:0')\n",
      "pw blocks flops : tensor([ 6144000., 18432000., 24576000.], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2.9094e+08, 2.7615e+08, 2.8728e+08, 2.6650e+08, 1.8582e+08, 2.1202e+08,\n",
       "        2.3700e+08, 2.2872e+08, 2.7107e+08, 2.6607e+08, 3.1530e+08, 2.5496e+08,\n",
       "        1.7824e+08, 2.4217e+08, 2.1952e+08, 2.4054e+08], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gumbel_model.set_static_flops(inputs.cuda())\n",
    "gumbel_model.compute_flops(inputs, gumbel_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  6, 12, 20])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3,4])* torch.tensor(block.mobile_inverted_conv.expand_ratio_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/pdh/torch/NAS/TinyML_NAS/mcunet/test_gumbel_net.ipynb ì…€ 5\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7064685f62715f70745f32323130222c2273657474696e6773223a7b22686f7374223a227373683a2f2f37385f706468227d7d/home/pdh/torch/NAS/TinyML_NAS/mcunet/test_gumbel_net.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m [\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m4\u001b[39;49m] \u001b[39m*\u001b[39;49m [\u001b[39m2\u001b[39;49m,\u001b[39m6\u001b[39;49m,\u001b[39m8\u001b[39;49m,\u001b[39m12\u001b[39;49m]\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'list'"
     ]
    }
   ],
   "source": [
    "[1,2,3,4] * [2,6,8,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdentityLayer() (1, 1)\n"
     ]
    }
   ],
   "source": [
    "for i, block in enumerate(gumbel_model.blocks):\n",
    "    if isinstance(block, MobileGumbelInvertedResidualBlock):\n",
    "        print(block.shortcut, block.mobile_inverted_conv.depth_conv.conv.stride)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel_model.forward(inputs)\n",
    "\n",
    "gumbel_model.eval()\n",
    "print(gumbel_model.training)\n",
    "out_origin = gumbel_model.forward(inputs)\n",
    "for i in range(10):\n",
    "    print(out_origin - gumbel_model.forward(inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_gumbel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.test_layer = nn.Linear(20, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        gumbel_input = self.test_layer(x)\n",
    "        if self.training:\n",
    "            gumbel_out = F.gumbel_softmax(gumbel_input, tau=1, hard=True, eps=1e-10, dim=-1)\n",
    "        else:\n",
    "            index = gumbel_input.max(dim=-1, keepdim=True)[1]\n",
    "            gumbel_out = torch.zeros_like(gumbel_input, memory_format=torch.legacy_contiguous_format).scatter_(-1, index, 1.0)\n",
    "        \n",
    "        return gumbel_out\n",
    "inputs = torch.randn(5, 20)\n",
    "gumbel = test_gumbel()\n",
    "\n",
    "# train\n",
    "gumbel.train()\n",
    "for i in range(5):\n",
    "    out = gumbel(inputs)\n",
    "    print(f\"{i} iter -> \", out)\n",
    "\n",
    "# test\n",
    "gumbel.eval()\n",
    "for i in range(5):\n",
    "    out = gumbel(inputs)\n",
    "    print(f\"{i} iter -> \", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchprofile import profile_macs\n",
    "\n",
    "total_mac = profile_macs(gumbel_model.cuda(), torch.randn(2, 3,160, 160).cuda())\n",
    "print(total_mac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchprofile.utils.flatten import Flatten\n",
    "import warnings\n",
    "with warnings.catch_warnings(record=True):\n",
    "    graph, _ = torch.jit._get_trace_graph(Flatten(gumbel_model.cuda()), torch.randn(2,3,160,160).cuda(), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = dict()\n",
    "for x in graph.nodes():\n",
    "    for v in list(x.inputs()):\n",
    "        if 'tensor' in v.type().kind().lower():\n",
    "            print(v.debugName(), v.type().scalarType(), v.type().sizes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in graph.nodes():\n",
    "    if 'mul_' in x.kind().lower():\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_model_size = sum([p.numel() for p in ori_model.parameters()]) * 4 / 2**20\n",
    "gumbel_model_size = sum([p.numel() for p in gumbel_model.parameters()]) * 4 / 2**20\n",
    "print(\"Ori model size : %.1f MB\" % ori_model_size)\n",
    "print(\"Gumbel model size : %.1f MB\" % gumbel_model_size)\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(gumbel_model, input_size=(4, 3, 160, 160), col_width=16, col_names=['kernel_size', 'output_size', 'num_params', 'mult_adds', 'params_percent'], depth=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before forward grad : \", gumbel_model.gumbel_fc1.weight.grad)\n",
    "out = gumbel_model(torch.randn(32, 3, 160, 160))\n",
    "\n",
    "out.sum().backward()\n",
    "\n",
    "print(\"after forward grad : \\n\", gumbel_model.gumbel_fc1.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in net.named_parameters():\n",
    "    if has_deep_attr(model, n):\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbconv_test = MBGumbelInvertedConvLayer.build_from_config(m.mobile_inverted_conv.config)\n",
    "mbconv_test.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(2, 16, 32, 32)\n",
    "gumbel_inputs = torch.randn(2, 4, 8, 8)\n",
    "gumbel_inputs.requires_grad = True\n",
    "gumbel_layer = nn.Linear(4*8*8, 5)\n",
    "gumbel_output = gumbel_layer(gumbel_inputs.view(2, -1))\n",
    "gumbel_index = F.gumbel_softmax(gumbel_output, tau=1, hard=True)\n",
    "print(gumbel_index)\n",
    "out = mbconv_test.forward(torch.randn(2, 16, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(2, 16, 32, 32)\n",
    "gumbel_inputs = torch.randn(2, 4, 8, 8)\n",
    "gumbel_inputs.requires_grad = True\n",
    "gumbel_layer = nn.Linear(4*8*8, 5)\n",
    "gumbel_output = gumbel_layer(gumbel_inputs.view(2, -1))\n",
    "gumbel_index = F.gumbel_softmax(gumbel_output, tau=1, hard=True)\n",
    "print(gumbel_index)\n",
    "out = mbconv_test.forward(torch.randn(2, 16, 32, 32), gumbel_index)\n",
    "out.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel_layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_mbconv_test_weight = copy.deepcopy(mbconv_test.depth_conv.conv.weight)\n",
    "print(original_mbconv_test_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m.mobile_inverted_conv.depth_conv.conv.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in m.mobile_inverted_conv.named_parameters():\n",
    "    if has_deep_attr(mbconv_test, n):\n",
    "        print(n, p)\n",
    "        set_deep_attr(mbconv_test, n, p)\n",
    "        print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in m.mobile_inverted_conv.named_parameters():\n",
    "    if has_deep_attr(mbconv_test, n):\n",
    "        print(n)\n",
    "        print(get_deep_attr(mbconv_test, n) - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbconv_test.forward(torch.randn(1,32,16,16), gumbel=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_layer = nn.BatchNorm2d(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 12, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 12\n",
    "out = F.batch_norm(x, bn_layer.running_mean[:feature_dim], bn_layer.running_var[:feature_dim], bn_layer.weight[:feature_dim], bn_layer.bias[:feature_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, img_size, desc = build_model(net_id='mcunet-in4', pretrained=True)\n",
    "\n",
    "backup_model = copy.deepcopy(model)\n",
    "model_copy = build_model(net_id='mcunet-in4', pretrained=False)[0]\n",
    "\n",
    "for (n1, p1), (n2, p2) in zip(backup_model.named_parameters(), model_copy.named_parameters()):\n",
    "    if n1 == n2:\n",
    "        print((p1 - p2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    if has_deep_attr(model_copy, n):\n",
    "        print(n)\n",
    "        set_deep_attr(model_copy, n, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (n1, p1), (n2, p2) in zip(backup_model.named_parameters(), model_copy.named_parameters()):\n",
    "    if n1 == n2:\n",
    "        print((p1-p2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
