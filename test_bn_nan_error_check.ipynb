{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "sys.path.append('./mcunet')\n",
    "\n",
    "from mcunet.gumbel_module.gumbel_net import GumbelMCUNet\n",
    "from mcunet.gumbel_module.gumbel_layer import MBGumbelInvertedConvLayer, MobileGumbelInvertedResidualBlock, count_conv_gumbel_flops\n",
    "from mcunet.tinynas.nn.modules import MBInvertedConvLayer\n",
    "from mcunet.tinynas.nn.networks import MobileInvertedResidualBlock\n",
    "from mcunet.model_zoo import build_model\n",
    "\n",
    "from mcunet.utils import MyModule, MyNetwork, SEModule, build_activation, get_same_padding, sub_filter_start_end, rm_bn_from_net, set_deep_attr, get_deep_attr, has_deep_attr\n",
    "from mcunet.tinynas.nn.modules import ZeroLayer, set_layer_from_config\n",
    "\n",
    "from fvcore.nn import FlopCountAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load pretrained mcu model parameter to gumbel net\n",
      "before num_batches_tracked  first_conv.bn.num_batches_tracked tensor(774245)\n",
      "after : first_conv.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.0.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(774245)\n",
      "after : blocks.0.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.0.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(774245)\n",
      "after : blocks.0.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.1.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.1.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.1.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.1.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.2.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.2.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.2.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.2.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.3.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.3.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.3.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.3.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.4.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.4.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.4.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.4.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.5.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.5.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.5.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.5.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.6.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.6.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.6.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.6.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.7.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.7.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.7.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.7.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.8.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.8.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.8.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.8.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.9.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.9.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.9.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.9.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.10.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.10.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.10.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.10.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.11.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.11.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.11.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.11.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.12.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.12.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.12.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.12.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.13.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.13.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.13.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.13.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.14.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.14.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.14.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.14.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.15.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.15.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.15.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.15.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.16.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.16.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "before num_batches_tracked  blocks.16.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(60095)\n",
      "after : blocks.16.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  first_conv.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.0.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.0.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.1.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.1.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.2.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.2.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.3.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.3.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.4.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.4.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.5.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.5.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.6.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.6.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.7.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.7.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.8.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.8.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.9.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.9.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.10.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.10.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.11.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.11.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.12.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.12.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.13.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.13.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.14.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.14.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.15.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.15.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.16.mobile_inverted_conv.depth_conv.bn.num_batches_tracked tensor(0)\n",
      "after num_batches_tracked  blocks.16.mobile_inverted_conv.point_linear.bn.num_batches_tracked tensor(0)\n",
      "load pretrained mcu model buffer to gumbel net\n"
     ]
    }
   ],
   "source": [
    "ori_model, img_size, desc = build_model(net_id='mcunet-in4', pretrained=True)\n",
    "gubmel_config = {'global_expand_ratio_list':[1,3,4,5,6], 'global_kernel_size_list':[3,5,7], 'gumbel_feature_extract_block_idx':2}\n",
    "gumbel_model = GumbelMCUNet.build_from_config(ori_model.config, gubmel_config)\n",
    "gumbel_model.load_pretrained_mcunet_param(ori_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import distrib\n",
    "from src import dataset\n",
    "from src.trainer import Trainer\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = edict()\n",
    "args.db = edict()\n",
    "args.db.name = 'imagenet'\n",
    "args.db.root = '/dataset/ImageNet/Classification/'\n",
    "args.flops_penalty = 0.0\n",
    "args.lr_sched = None\n",
    "args.device = 0\n",
    "args.epochs = 0\n",
    "args.max_norm = 0.5\n",
    "args.continue_from = True\n",
    "args.checkpoint = None\n",
    "args.history_file = None\n",
    "args.restart=True\n",
    "args.num_prints=10\n",
    "args.mixed=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, num_class = dataset.get_loader(args, img_resize=160)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=4)\n",
    "data= {'tr':train_loader, 'tt':test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([-0.0148, -0.0012,  0.0120, -0.0059,  0.0142, -0.0135, -0.0068,  0.0145]) tensor([ 0.0278,  0.0173, -0.0243,  0.0166,  0.0347,  0.0055,  0.0184, -0.0235])\n",
      "re setup bn\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([-0.0002,  0.0002,  0.0012, -0.0038,  0.0000,  0.0000,  0.0000,  0.0000]) tensor([ 0.0112, -0.0026,  0.0066,  0.0081,  0.0000,  0.0000,  0.0000,  0.0000])\n",
      "re setup bn\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) tensor([0.9000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
      "tensor([0.1900, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) tensor([0.8100, 0.9000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
      "tensor([0.2710, 0.1900, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) tensor([0.7290, 0.8100, 0.9000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
      "tensor([0.3439, 0.2710, 0.1900, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000]) tensor([0.6561, 0.7290, 0.8100, 0.9000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
      "tensor([0.4095, 0.3439, 0.2710, 0.1900, 0.1000, 0.0000, 0.0000, 0.0000]) tensor([0.5905, 0.6561, 0.7290, 0.8100, 0.9000, 1.0000, 1.0000, 1.0000])\n",
      "tensor([0.4686, 0.4095, 0.3439, 0.2710, 0.1900, 0.1000, 0.0000, 0.0000]) tensor([0.5314, 0.5905, 0.6561, 0.7290, 0.8100, 0.9000, 1.0000, 1.0000])\n",
      "tensor([0.5217, 0.4686, 0.4095, 0.3439, 0.2710, 0.1900, 0.1000, 0.0000]) tensor([0.4783, 0.5314, 0.5905, 0.6561, 0.7290, 0.8100, 0.9000, 1.0000])\n",
      "tensor([0.5695, 0.5217, 0.4686, 0.4095, 0.3439, 0.2710, 0.1900, 0.1000]) tensor([0.4305, 0.4783, 0.5314, 0.5905, 0.6561, 0.7290, 0.8100, 0.9000])\n"
     ]
    }
   ],
   "source": [
    "from mcunet.gumbel_module.gumbel_layer import DynamicGumbelBatchNorm2d\n",
    "\n",
    "inputs = torch.randn(4, 8, 4, 4)\n",
    "bn = DynamicGumbelBatchNorm2d(8)\n",
    "backup_bn = copy.deepcopy(bn)\n",
    "\n",
    "print(backup_bn.bn.running_mean, backup_bn.bn.running_var)\n",
    "bn.eval()\n",
    "bn(inputs)\n",
    "print(backup_bn.bn.running_mean - bn.bn.running_mean, backup_bn.bn.running_var - bn.bn.running_var)\n",
    "bn.train()\n",
    "bn(inputs)\n",
    "\n",
    "print(backup_bn.bn.running_mean - bn.bn.running_mean, backup_bn.bn.running_var - bn.bn.running_var)\n",
    "print(\"re setup bn\")\n",
    "bn = copy.deepcopy(backup_bn)\n",
    "print(bn.bn.running_mean, bn.bn.running_var)\n",
    "inputs = torch.randn(4,4,4,4)\n",
    "bn.eval()\n",
    "bn(inputs)\n",
    "print(backup_bn.bn.running_mean - bn.bn.running_mean, backup_bn.bn.running_var - bn.bn.running_var)\n",
    "bn.train()\n",
    "bn(inputs)\n",
    "print(backup_bn.bn.running_mean - bn.bn.running_mean, backup_bn.bn.running_var - bn.bn.running_var)\n",
    "\n",
    "print(\"re setup bn\")\n",
    "\n",
    "bn = copy.deepcopy(backup_bn)\n",
    "print(bn.bn.running_mean, bn.bn.running_var)\n",
    "\n",
    "bn.train()\n",
    "inputs = torch.ones(4,8,4,4).to(torch.float32)\n",
    "\n",
    "for i in range(8):\n",
    "    bn(inputs[:, :i+1, :, :])\n",
    "    print(bn.bn.running_mean, bn.bn.running_var)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re setup bn\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) tensor([0.9000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
      "tensor([0.1900, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) tensor([0.8100, 0.9000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
      "tensor([0.2710, 0.1900, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) tensor([0.7290, 0.8100, 0.9000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
      "tensor([0.3439, 0.2710, 0.1900, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000]) tensor([0.6561, 0.7290, 0.8100, 0.9000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
      "tensor([0.4095, 0.3439, 0.2710, 0.1900, 0.1000, 0.0000, 0.0000, 0.0000]) tensor([0.5905, 0.6561, 0.7290, 0.8100, 0.9000, 1.0000, 1.0000, 1.0000])\n",
      "tensor([0.4686, 0.4095, 0.3439, 0.2710, 0.1900, 0.1000, 0.0000, 0.0000]) tensor([0.5314, 0.5905, 0.6561, 0.7290, 0.8100, 0.9000, 1.0000, 1.0000])\n",
      "tensor([0.5217, 0.4686, 0.4095, 0.3439, 0.2710, 0.1900, 0.1000, 0.0000]) tensor([0.4783, 0.5314, 0.5905, 0.6561, 0.7290, 0.8100, 0.9000, 1.0000])\n",
      "tensor([0.5695, 0.5217, 0.4686, 0.4095, 0.3439, 0.2710, 0.1900, 0.1000]) tensor([0.4305, 0.4783, 0.5314, 0.5905, 0.6561, 0.7290, 0.8100, 0.9000])\n"
     ]
    }
   ],
   "source": [
    "from mcunet.gumbel_module.gumbel_layer import DynamicGumbelBatchNorm2d\n",
    "\n",
    "inputs = torch.randn(4, 8, 4, 4)\n",
    "bn = DynamicGumbelBatchNorm2d(8)\n",
    "backup_bn = copy.deepcopy(bn)\n",
    "\n",
    "print(\"re setup bn\")\n",
    "\n",
    "bn = copy.deepcopy(backup_bn)\n",
    "print(bn.bn.running_mean, bn.bn.running_var)\n",
    "\n",
    "bn.train()\n",
    "inputs = torch.ones(4,8,4,4).to(torch.float32)\n",
    "\n",
    "for i in range(8):\n",
    "    out = F.batch_norm(inputs[:, :i+1, :, :], bn.bn.running_mean[:i+1], bn.bn.running_var[:i+1], bn.bn.weight[:i+1], bn.bn.bias[:i+1], training=True, momentum=0.1, eps=1e-5)\n",
    "    print(bn.bn.running_mean, bn.bn.running_var)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for n, m in gumbel_model.named_modules():\n",
    "    if isinstance(m, MBGumbelInvertedConvLayer):\n",
    "        break\n",
    "\n",
    "bnn = m.inverted_bottleneck.bn\n",
    "\n",
    "bnn.num_batches_tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "print(bn.bn.training)\n",
    "print(bn.bn.track_running_stats)\n",
    "print(bn.bn.num_batches_tracked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MBGumbelInvertedLayer BatchNorm check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbgumbel_list = []\n",
    "for n, m in gumbel_model.named_modules():\n",
    "    if isinstance(m, MBGumbelInvertedConvLayer):\n",
    "        mbgumbel_list.append([n,m])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, m in mbgumbel_list:\n",
    "    print(f\"{n} module test\")\n",
    "    test_module = copy.deepcopy(m)\n",
    "\n",
    "    test_module.cuda()\n",
    "    test_module.train()\n",
    "    inputs = torch.randn(4, test_module.config['in_channels'], 32, 32).cuda()\n",
    "    out = test_module.forward(inputs) # original output\n",
    "\n",
    "    expand_index, kernel_index = len(test_module.expand_ratio_list), len(test_module.kernel_size_list)\n",
    "                \n",
    "    if expand_index > 1 and kernel_index > 1:\n",
    "        gumbel_one_hot = torch.zeros((inputs.shape[0], expand_index + kernel_index), device=inputs.device)\n",
    "        gumbel_one_hot[:, expand_index-1] = 1\n",
    "        gumbel_one_hot[:, expand_index] = 1\n",
    "    elif expand_index > 1:\n",
    "        gumbel_one_hot = torch.zeros((inputs.shape[0], expand_index), device=inputs.device)\n",
    "        gumbel_one_hot[:, expand_index -1] = 1\n",
    "    elif kernel_index >1:\n",
    "        gumbel_one_hot = torch.zeros((inputs.shape[0], kernel_index), device=inputs.device)\n",
    "        gumbel_one_hot[:, 0] = 1\n",
    "    else:\n",
    "        gumbel_one_hot = None\n",
    "\n",
    "    out_gumbel = test_module.forward(inputs, gumbel_one_hot)\n",
    "\n",
    "    print(\"train mode\")\n",
    "    print(out - out_gumbel)\n",
    "\n",
    "    test_module.eval()\n",
    "    out = test_module.forward(inputs) # original output\n",
    "    out_gumbel = test_module.forward(inputs, gumbel_one_hot)\n",
    "    print(\"eval mode\")\n",
    "    print(out - out_gumbel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, m in mbgumbel_list:\n",
    "    print(f\"{n} module test\")\n",
    "    test_module = copy.deepcopy(m)\n",
    "\n",
    "    test_module.cuda()\n",
    "    test_module.train()\n",
    "    inputs = torch.randn(4, test_module.config['in_channels'], 32, 32).cuda()\n",
    "    out = test_module.forward(inputs) # original output\n",
    "\n",
    "    expand_index, kernel_index = len(test_module.expand_ratio_list), len(test_module.kernel_size_list)\n",
    "                \n",
    "    if expand_index > 1 and kernel_index > 1:\n",
    "        gumbel_one_hot = torch.zeros((inputs.shape[0], expand_index + kernel_index), device=inputs.device)\n",
    "        gumbel_one_hot[:, expand_index-1] = 1\n",
    "        gumbel_one_hot[:, expand_index] = 1\n",
    "    elif expand_index > 1:\n",
    "        gumbel_one_hot = torch.zeros((inputs.shape[0], expand_index), device=inputs.device)\n",
    "        gumbel_one_hot[:, expand_index -1] = 1\n",
    "    elif kernel_index >1:\n",
    "        gumbel_one_hot = torch.zeros((inputs.shape[0], kernel_index), device=inputs.device)\n",
    "        gumbel_one_hot[:, 0] = 1\n",
    "    else:\n",
    "        gumbel_one_hot = None\n",
    "\n",
    "    out_gumbel = test_module.forward(inputs, gumbel_one_hot)\n",
    "    out_gumbel.sum().backward()\n",
    "    \n",
    "\n",
    "    print(\"train mode\")\n",
    "    print(out - out_gumbel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel_model.cuda()\n",
    "gumbel_train_model = copy.deepcopy(gumbel_model)\n",
    "\n",
    "load_from = './outputs/exp_bn_check/log=bn_check/checkpoint.th'\n",
    "package = torch.load(load_from, 'cpu')\n",
    "gumbel_train_model.load_state_dict(package['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel_train_model.train()\n",
    "gumbel_train_model2 = copy.deepcopy(gumbel_train_model)\n",
    "\n",
    "gumbel_train_model.cuda()\n",
    "gumbel_train_model2.cuda()\n",
    "inputs = torch.randn(1,3,160,160).cuda()\n",
    "\n",
    "g_1= gumbel_train_model.forward_original(inputs)\n",
    "g_2= gumbel_train_model2.forward_gumbel_approx(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_1[0].sum().backward()\n",
    "g_2[0].sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (n, m), (tn, tm) in zip(gumbel_train_model.named_modules(), gumbel_train_model2.named_modules()):\n",
    "    if isinstance(tm, nn.BatchNorm2d):\n",
    "        print(n)\n",
    "        print((m.weight.data - tm.weight.data).max())\n",
    "        print((m.bias.data - tm.bias.data).max())\n",
    "        print((m.weight.grad.data - tm.weight.grad.data).max())\n",
    "        print((m.bias.grad.data - tm.bias.grad.data).max())\n",
    "        \n",
    "        print((m.running_mean.data - tm.running_mean.data).max())\n",
    "        print((m.running_var.data - tm.running_var.data).max())\n",
    "        print(\"====\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input =torch.randn(3, 4, 2, 2)\n",
    "test_bn =nn.BatchNorm2d(4)\n",
    "test_bn.eval()\n",
    "\n",
    "out1 = test_bn(test_input)\n",
    "out2 = F.batch_norm(test_input, test_bn.running_mean, test_bn.running_var, test_bn.weight, test_bn.bias, False, 0.0, 1e-5)\n",
    "\n",
    "print(out1-out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "BN and F.batchnorm output check (train mode)\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "BN and F.batchnorm output check (train mode 1 iter after)\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "BN and F.batchnorm output check (train mode 2 iter after)\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "bn weight's gradinet check\n",
      "tensor([ 3.2685e-08,  4.1659e-07, -6.5098e-08, -1.5111e-07]) tensor([ 3.2685e-08,  4.1659e-07, -6.5098e-08, -1.5111e-07])\n",
      "BN and F.batchnorm output check (train mode 2 iter after and weight update)\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "BN and F.batchnorm output check (eval mode 2 iter after and weight update)\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "tensor([0., 0., 0., 0.]) tensor([1., 1., 1., 1.])\n",
      "tensor([0., 0., 0., 0.]) tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "test_input =torch.randn(3, 4, 2, 2)\n",
    "test_bn =nn.BatchNorm2d(4, momentum=0.0, eps=1e-5)\n",
    "test_bn.eval()\n",
    "\n",
    "out1 = test_bn(test_input)\n",
    "out2 = F.batch_norm(test_input, test_bn.running_mean, test_bn.running_var, test_bn.weight, test_bn.bias, False, 0.0, 1e-5)\n",
    "\n",
    "print((out1-out2).sum())\n",
    "\n",
    "\n",
    "test_bn2 = copy.deepcopy(test_bn)\n",
    "test_bn2.train()\n",
    "test_bn.train()\n",
    "\n",
    "out1 = test_bn2(test_input)\n",
    "out2 = F.batch_norm(test_input, test_bn.running_mean, test_bn.running_var, test_bn.weight, test_bn.bias, True, 0.0, 1e-5)\n",
    "print(\"BN and F.batchnorm output check (train mode)\")\n",
    "print((out1-out2).sum())\n",
    "out1 = test_bn2(test_input)\n",
    "out2 = F.batch_norm(test_input, test_bn.running_mean, test_bn.running_var, test_bn.weight, test_bn.bias, True, 0.0, 1e-5)\n",
    "print(\"BN and F.batchnorm output check (train mode 1 iter after)\")\n",
    "print((out1-out2).sum())\n",
    "out1 = test_bn2(test_input)\n",
    "out2 = F.batch_norm(test_input, test_bn.running_mean, test_bn.running_var, test_bn.weight, test_bn.bias, True, 0.0, 1e-5)\n",
    "print(\"BN and F.batchnorm output check (train mode 2 iter after)\")\n",
    "print((out1-out2).sum())\n",
    "\n",
    "out1.sum().backward()\n",
    "out2.sum().backward()\n",
    "print(\"bn weight's gradinet check\")\n",
    "print(test_bn.weight.grad,test_bn2.weight.grad)\n",
    "\n",
    "out1 = test_bn2(test_input)\n",
    "out2 = F.batch_norm(test_input, test_bn.running_mean, test_bn.running_var, test_bn.weight, test_bn.bias, True, 0.0, 1e-5)\n",
    "print(\"BN and F.batchnorm output check (train mode 2 iter after and weight update)\")\n",
    "print((out1-out2).sum())\n",
    "\n",
    "test_bn2.eval()\n",
    "test_bn.eval()\n",
    "out1 = test_bn2(test_input)\n",
    "out2 = F.batch_norm(test_input, test_bn.running_mean, test_bn.running_var, test_bn.weight, test_bn.bias, False, 0.0, 1e-5)\n",
    "print(\"BN and F.batchnorm output check (eval mode 2 iter after and weight update)\")\n",
    "print((out1-out2).sum())\n",
    "print(test_bn.running_mean, test_bn.running_var)\n",
    "print(test_bn2.running_mean, test_bn2.running_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "BN and F.batchnorm output check (train mode)\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "BN and F.batchnorm output check (train mode 1 iter after)\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "BN and F.batchnorm output check (train mode 2 iter after)\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "bn weight's gradinet check\n",
      "tensor([-1.7993e-07,  1.6251e-07, -1.3427e-07, -1.2154e-07]) tensor([-1.7993e-07,  1.6251e-07, -1.3427e-07, -1.2154e-07])\n",
      "BN and F.batchnorm output check (train mode 2 iter after and weight update)\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "BN and F.batchnorm output check (eval mode 2 iter after and weight update)\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "tensor([ 0.0113, -0.0004, -0.0224, -0.1097]) tensor([0.9964, 0.9134, 1.0304, 0.8591])\n",
      "tensor([ 0.0113, -0.0004, -0.0224, -0.1097]) tensor([0.9964, 0.9134, 1.0304, 0.8591])\n"
     ]
    }
   ],
   "source": [
    "test_input =torch.randn(3, 4, 2, 2)\n",
    "test_bn =nn.BatchNorm2d(4, momentum=0.1, eps=1e-5)\n",
    "test_bn.eval()\n",
    "\n",
    "out1 = test_bn(test_input)\n",
    "out2 = F.batch_norm(test_input, test_bn.running_mean, test_bn.running_var, test_bn.weight, test_bn.bias, False, 0.0, 1e-5) # eval mode check\n",
    "\n",
    "print((out1-out2).sum())\n",
    "\n",
    "\n",
    "test_bn2 = copy.deepcopy(test_bn)\n",
    "test_bn2.train()\n",
    "test_bn.train()\n",
    "\n",
    "out1 = test_bn2(test_input)\n",
    "out2 = F.batch_norm(test_input, test_bn.running_mean, test_bn.running_var, test_bn.weight, test_bn.bias, True, 0.1, 1e-5)\n",
    "print(\"BN and F.batchnorm output check (train mode)\")\n",
    "print((out1-out2).sum())\n",
    "out1 = test_bn2(test_input)\n",
    "out2 = F.batch_norm(test_input, test_bn.running_mean, test_bn.running_var, test_bn.weight, test_bn.bias, True, 0.1, 1e-5)\n",
    "print(\"BN and F.batchnorm output check (train mode 1 iter after)\")\n",
    "print((out1-out2).sum())\n",
    "out1 = test_bn2(test_input)\n",
    "out2 = F.batch_norm(test_input, test_bn.running_mean, test_bn.running_var, test_bn.weight, test_bn.bias, True, 0.1, 1e-5)\n",
    "print(\"BN and F.batchnorm output check (train mode 2 iter after)\")\n",
    "print((out1-out2).sum())\n",
    "\n",
    "out1.sum().backward()\n",
    "out2.sum().backward()\n",
    "print(\"bn weight's gradinet check\")\n",
    "print(test_bn.weight.grad,test_bn2.weight.grad)\n",
    "\n",
    "out1 = test_bn2(test_input)\n",
    "out2 = F.batch_norm(test_input, test_bn.running_mean, test_bn.running_var, test_bn.weight, test_bn.bias, True, 0.1, 1e-5)\n",
    "print(\"BN and F.batchnorm output check (train mode 2 iter after and weight update)\")\n",
    "print((out1-out2).sum())\n",
    "\n",
    "test_bn2.eval()\n",
    "test_bn.eval()\n",
    "out1 = test_bn2(test_input)\n",
    "out2 = F.batch_norm(test_input, test_bn.running_mean, test_bn.running_var, test_bn.weight, test_bn.bias, False, 0.1, 1e-5)\n",
    "print(\"BN and F.batchnorm output check (eval mode 2 iter after and weight update)\")\n",
    "print((out1-out2).sum())\n",
    "print(test_bn.running_mean, test_bn.running_var)\n",
    "print(test_bn2.running_mean, test_bn2.running_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_bn2.running_mean, test_bn2.running_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_bn.running_mean, test_bn.running_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (n, m), (tn, tm) in zip(gumbel_model.named_modules(), gumbel_train_model.named_modules()):\n",
    "    if isinstance(tm, nn.BatchNorm2d):\n",
    "        print(n)\n",
    "        print((m.weight.data - tm.weight.data).max())\n",
    "        print((m.bias.data - tm.bias.data).max())\n",
    "        print((m.running_mean.data - tm.running_mean.data).max())\n",
    "        print((m.running_var.data - tm.running_var.data).max())\n",
    "        print(\"====\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = None\n",
    "original_flops = 100000\n",
    "gumbel_trainer = Trainer(data, gumbel_model.cuda(), criterion, optimizer, args, original_flops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel_trainer.test(ori_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, label in test_loader:\n",
    "    data = data[:32].cuda()\n",
    "    label = label[:32].cuda()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hook:\n",
    "    def __init__(self, name, module):\n",
    "        self.name = name\n",
    "        self.module = module\n",
    "        self.hook = module.register_forward_hook(self.hook_fn)\n",
    "        self.output = None\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.module = module\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "    def close(self):\n",
    "        self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_hook_list = []\n",
    "ori_model.cuda()\n",
    "for n, m in ori_model.named_modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        ori_hook_list.append(Hook(n, m))\n",
    "\n",
    "ori_model(data).max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel_hook_list = []\n",
    "gumbel_model.cuda()\n",
    "for n, m in gumbel_model.named_modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        gumbel_hook_list.append(Hook(n, m))\n",
    "\n",
    "gumbel_model.forward(data)[0].max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, hook in enumerate(ori_hook_list):\n",
    "    print(hook.name)\n",
    "    #print(\"original model's bn statistics :\", hook.module.running_mean, hook.module.running_var)\n",
    "    input_data = hook.input[0][:10]\n",
    "    n, c, h, w = input_data.shape\n",
    "    input_mean, input_std = input_data.reshape(n, c, -1).mean(dim=-1), input_data.reshape(n, c, -1).var(dim=-1)\n",
    "    diff_input_mean = input_mean - hook.module.running_mean\n",
    "    diff_input_std = input_std - hook.module.running_var\n",
    "    print(\"bn and inputs difference mean statistics : \")\n",
    "    print(f\"diff mean's statistics :\\n avg : {diff_input_mean.mean():.6f}, std : {diff_input_mean.std():.6f}, max : {diff_input_mean.max():.6f}, min : {diff_input_mean.min():.6f}\")\n",
    "    print(f\"diff var's statistics :\\n avg : {diff_input_std.mean():.6f}, std : {diff_input_std.std():.6f}, max : {diff_input_std.max():.6f}, min : {diff_input_std.min():.6f}\")\n",
    "    print(\"==\"*30)\n",
    "    if i > 5:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, hook in enumerate(gumbel_hook_list):\n",
    "    print(\"gumbel model statistics\")\n",
    "    print(hook.name)\n",
    "    #print(\"original model's bn statistics :\", hook.module.running_mean, hook.module.running_var)\n",
    "    input_data = hook.input[0][:10]\n",
    "    n, c, h, w = input_data.shape\n",
    "    input_mean, input_std = input_data.reshape(n, c, -1).mean(dim=-1), input_data.reshape(n, c, -1).var(dim=-1)\n",
    "    diff_input_mean = input_mean - hook.module.running_mean\n",
    "    diff_input_std = input_std - hook.module.running_var\n",
    "    print(\"bn and inputs difference mean statistics : \")\n",
    "    print(f\"diff mean's statistics :\\n avg : {diff_input_mean.mean():.6f}, std : {diff_input_mean.std():.6f}, max : {diff_input_mean.max():.6f}, min : {diff_input_mean.min():.6f}\")\n",
    "    print(f\"diff var's statistics :\\n avg : {diff_input_std.mean():.6f}, std : {diff_input_std.std():.6f}, max : {diff_input_std.max():.6f}, min : {diff_input_std.min():.6f}\")\n",
    "    print(\"==\"*30)\n",
    "    if i > 5:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, m in gumbel_model.named_parameters():\n",
    "    print(n, m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel_trainer.test(ori_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.randn(10)\n",
    "h = 5\n",
    "print(g)\n",
    "g.unsqueeze(0).repeat(h, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel_model.eval()\n",
    "ori_model.eval()\n",
    "for n, m in gumbel_model.named_modules():\n",
    "    if has_deep_attr(ori_model, n):\n",
    "        if isinstance(m, MobileGumbelInvertedResidualBlock):\n",
    "            ori_m = get_deep_attr(ori_model, n)\n",
    "            m = m.cuda()\n",
    "            ori_m = ori_m.cuda()\n",
    "            in_c = ori_m.mobile_inverted_conv.in_channels\n",
    "            input_rand_tensor = torch.randn(1, in_c, 16, 16).cuda()\n",
    "            ori_out = ori_m(input_rand_tensor)\n",
    "            expand_ratio_list, kernel_size_list = m.mobile_inverted_conv.expand_ratio_list, m.mobile_inverted_conv.kernel_size_list\n",
    "            if len(expand_ratio_list) == 1 and len(kernel_size_list) == 1:\n",
    "                gumbel_idx = None\n",
    "            elif len(expand_ratio_list) > 1 and len(kernel_size_list) == 1:\n",
    "                gumbel_idx = torch.zeros(len(expand_ratio_list)).long().to(input_rand_tensor.device)\n",
    "                gumbel_idx[len(expand_ratio_list)-1] = 1\n",
    "            \n",
    "            elif len(expand_ratio_list) == 1 and len(kernel_size_list) > 1:\n",
    "                gumbel_idx = torch.zeros(len(kernel_size_list)).long().to(input_rand_tensor.device)\n",
    "                gumbel_idx[0] = 1 \n",
    "            else:\n",
    "                gumbel_idx = torch.zeros(len(expand_ratio_list)+len(kernel_size_list)).long().to(input_rand_tensor.device)\n",
    "                gumbel_idx[len(expand_ratio_list)-1] = 1\n",
    "                gumbel_idx[len(expand_ratio_list)] = 1\n",
    "            \n",
    "            gumbel_idx = gumbel_idx.unsqueeze(0).repeat(input_rand_tensor.shape[0], 1)\n",
    "            out = m(input_rand_tensor, gumbel_idx)\n",
    "            print(f\"module name : {n}\")\n",
    "            print(\"distance : \", (ori_out-out).sum())\n",
    "            print(\"==\"*20)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test = torch.randn(1,3, 160, 160).cuda()\n",
    "ori_model = ori_model.cuda()\n",
    "gumbel_model = gumbel_model.cuda()\n",
    "ori_output = ori_model.first_conv(inputs_test)\n",
    "gumbel_output = gumbel_model.first_conv(inputs_test)\n",
    "print(\"difference : \", ori_output - gumbel_output)\n",
    "\n",
    "for i in range(len(ori_model.blocks)):\n",
    "    ori_output = ori_model.blocks[i](ori_output)\n",
    "    gumbel_output = gumbel_model.blocks[i](gumbel_output)\n",
    "    print(f\"{i}'s difference : \", ori_output - gumbel_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_output = ori_output.mean(3).mean(2)\n",
    "gumbel_output = gumbel_output.mean(3).mean(2)\n",
    "ori_output = ori_model.classifier(ori_output)\n",
    "gumbel_output = gumbel_model.classifier(gumbel_output)\n",
    "print(\"difference : \", (ori_output - gumbel_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
