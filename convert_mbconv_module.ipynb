{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mcunet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from mcunet.tinynas.nn.modules import MBInvertedConvLayer\n",
    "from mcunet.tinynas.nn.networks import MobileInvertedResidualBlock\n",
    "from mcunet.model_zoo import build_model\n",
    "\n",
    "from mcunet.utils import MyModule, MyNetwork, SEModule, build_activation, get_same_padding, sub_filter_start_end\n",
    "from mcunet.tinynas.nn.modules import ZeroLayer, set_layer_from_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deep_attr(obj, attrs):\n",
    "    for attr in attrs.split(\".\"):\n",
    "        obj = getattr(obj, attr)\n",
    "    return obj\n",
    "\n",
    "def has_deep_attr(obj, attrs):\n",
    "    try:\n",
    "        get_deep_attr(obj, attrs)\n",
    "        return True\n",
    "    except AttributeError:\n",
    "        return False\n",
    "\n",
    "def set_deep_attr(obj, attrs, value):\n",
    "    for attr in attrs.split(\".\")[:-1]:\n",
    "        obj = getattr(obj, attr)\n",
    "    setattr(obj, attrs.split(\".\")[-1], value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, img_size, desc = build_model(net_id='mcunet-in4', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.0\n",
      "MobileInvertedResidualBlock(\n",
      "  (mobile_inverted_conv): MBInvertedConvLayer(\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "blocks.1\n",
      "MobileInvertedResidualBlock(\n",
      "  (mobile_inverted_conv): MBInvertedConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(48, 48, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=48, bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for n, m in model.named_modules():\n",
    "    if isinstance(m, MobileInvertedResidualBlock):\n",
    "        print(n)\n",
    "        print(m)\n",
    "        count += 2\n",
    "        if count > 3: \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'MobileInvertedResidualBlock',\n",
       " 'mobile_inverted_conv': {'name': 'MBInvertedConvLayer',\n",
       "  'in_channels': 16,\n",
       "  'out_channels': 24,\n",
       "  'kernel_size': 7,\n",
       "  'stride': 2,\n",
       "  'expand_ratio': 3,\n",
       "  'mid_channels': 48,\n",
       "  'act_func': 'relu6',\n",
       "  'use_se': False},\n",
       " 'shortcut': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm  = m.mobile_inverted_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'MBInvertedConvLayer',\n",
       " 'in_channels': 16,\n",
       " 'out_channels': 24,\n",
       " 'kernel_size': 7,\n",
       " 'stride': 2,\n",
       " 'expand_ratio': 3,\n",
       " 'mid_channels': 48,\n",
       " 'act_func': 'relu6',\n",
       " 'use_se': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class MBGumbelInvertedConvLayer(MyModule):\n",
    "    global_kernel_size_list = [3,5,7]\n",
    "    global_expand_ratio_list = [1,3,4,5,6]\n",
    "    def __init__(self, in_channels, out_channels,\n",
    "                 kernel_size=3, stride=1, expand_ratio=6, mid_channels=None, act_func='relu6', use_se=False, **kwargs):\n",
    "        super(MBGumbelInvertedConvLayer, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.max_kernel_size = kernel_size\n",
    "        self.kernel_size_list = []\n",
    "        self.stride = stride\n",
    "        self.max_expand_ratio = expand_ratio\n",
    "        self.expand_ratio_list = []\n",
    "        self.mid_channels = mid_channels\n",
    "        self.act_func = act_func\n",
    "        self.use_se = use_se\n",
    "        \n",
    "        \n",
    "        if self.max_kernel_size in self.global_kernel_size_list:\n",
    "            for kernel in sorted(self.global_kernel_size_list):\n",
    "                if kernel == self.max_kernel_size:\n",
    "                    self.kernel_size_list.append(kernel)\n",
    "                    break\n",
    "                self.kernel_size_list.append(kernel)\n",
    "            \n",
    "            self.kernel_size_list.reverse() # sorted in descending order\n",
    "        \n",
    "        else:\n",
    "            self.kernel_size_list = [self.max_kernel_size]\n",
    "        \n",
    "        if self.max_expand_ratio in self.global_expand_ratio_list:        \n",
    "            for expand in sorted(self.global_expand_ratio_list):\n",
    "                if expand == self.max_expand_ratio:\n",
    "                    self.expand_ratio_list.append(expand)\n",
    "                    break\n",
    "                self.expand_ratio_list.append(expand)\n",
    "        \n",
    "        else:\n",
    "            self.expand_ratio_list = [self.max_expand_ratio]\n",
    "        \n",
    "\n",
    "        if self.mid_channels is None:\n",
    "            feature_dim = round(self.in_channels * self.max_expand_ratio)\n",
    "        else:\n",
    "            feature_dim = self.mid_channels\n",
    "\n",
    "        if self.max_expand_ratio == 1:\n",
    "            self.inverted_bottleneck = None\n",
    "        else:\n",
    "            self.inverted_bottleneck = nn.Sequential(OrderedDict([\n",
    "                ('conv', nn.Conv2d(self.in_channels, feature_dim, 1, 1, 0, bias=False)),\n",
    "                ('bn', nn.BatchNorm2d(feature_dim)),\n",
    "                ('act', build_activation(self.act_func, inplace=True)),\n",
    "            ]))\n",
    "\n",
    "        pad = get_same_padding(self.max_kernel_size)\n",
    "        depth_conv_modules = [\n",
    "            ('conv', nn.Conv2d(feature_dim, feature_dim, kernel_size, stride, pad, groups=feature_dim, bias=False)),\n",
    "            ('bn', nn.BatchNorm2d(feature_dim)),\n",
    "            ('act', build_activation(self.act_func, inplace=True))\n",
    "        ]\n",
    "        if self.use_se:\n",
    "            depth_conv_modules.append(('se', SEModule(feature_dim)))\n",
    "        self.depth_conv = nn.Sequential(OrderedDict(depth_conv_modules))\n",
    "\n",
    "        self.point_linear = nn.Sequential(OrderedDict([\n",
    "            ('conv', nn.Conv2d(feature_dim, out_channels, 1, 1, 0, bias=False)),\n",
    "            ('bn', nn.BatchNorm2d(out_channels)),\n",
    "        ]))\n",
    "\n",
    "        self.kernel_transform_linear_list = nn.ModuleList()\n",
    "        \n",
    "        for i, kernel in enumerate(self.kernel_size_list[1:]):\n",
    "            kernel_linear = nn.Linear(kernel*kernel, kernel*kernel)\n",
    "            self.kernel_transform_linear_list.append(kernel_linear)\n",
    "\n",
    "    def forward(self, x, gumbel=None):\n",
    "        \"\"\"\n",
    "        gumbel: [batch_size, len(self.expand_ratio_list) + len(self.kernel_size_list)]\n",
    "        \"\"\"\n",
    "        if gumbel==None:\n",
    "            if self.inverted_bottleneck:\n",
    "                x = self.inverted_bottleneck(x)\n",
    "            x = self.depth_conv(x)\n",
    "            x = self.point_linear(x)\n",
    "            return x\n",
    "        else:\n",
    "            print(\"gumbel shape : \", gumbel.shape)    \n",
    "            if len(self.expand_ratio_list) == 1: ## \n",
    "                if len(self.kernel_size_list) == 1:\n",
    "                    if self.inverted_bottleneck:\n",
    "                        x = self.inverted_bottleneck(x)\n",
    "                    x = self.depth_conv(x)\n",
    "                    x = self.point_linear(x)\n",
    "                    return x\n",
    "                else:\n",
    "                    # expand_ratio only one, multiple kernel size, so gumbel length is multple of kernel size\n",
    "                    assert len(gumbel[0]) == len(self.kernel_size_list), \"gumbel size is not match with kernel_size_list\"\n",
    "                    if self.inverted_bottleneck:\n",
    "                        x = self.inverted_bottleneck(x)\n",
    "                    depth_weight = self.depth_conv.conv.weight\n",
    "                    pad = get_same_padding(self.max_kernel_size)\n",
    "                    kernel_max_out = F.conv2d(x, depth_weight, stride=self.stride, padding=pad, groups=x.size(1))\n",
    "                    kernel_max_out = self.depth_conv.bn(kernel_max_out)\n",
    "                    kernel_max_out = self.depth_conv.act(kernel_max_out)\n",
    "                    kernel_max_out *= gumbel[:, 0].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                    for i, active_kernel_size in enumerate(self.kernel_size_list[1:]):\n",
    "                        start, end = sub_filter_start_end(self.kernel_size_list[i], active_kernel_size)\n",
    "                        print(start, end, active_kernel_size, self.kernel_size_list[i], depth_weight.shape)\n",
    "                        kernel_weight = depth_weight[:, :, start:end, start:end].contiguous()\n",
    "                        kernel_weight = kernel_weight.view(kernel_weight.size(0), kernel_weight.size(1), -1)\n",
    "                        kernel_weight = self.kernel_transform_linear_list[i](kernel_weight)\n",
    "                        kernel_weight = kernel_weight.view(kernel_weight.size(0), kernel_weight.size(1), active_kernel_size, active_kernel_size)\n",
    "                        pad = get_same_padding(active_kernel_size)\n",
    "                        kernel_out = F.conv2d(x, kernel_weight, stride=self.stride, padding=pad, groups=x.size(1))\n",
    "                        kernel_out = self.depth_conv.bn(kernel_out)\n",
    "                        kernel_out = self.depth_conv.act(kernel_out)\n",
    "                        kernel_out *= gumbel[:, i].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                        kernel_max_out += kernel_out\n",
    "                    x = kernel_max_out\n",
    "                    if self.use_se:\n",
    "                        x = self.depth_conv.se(x)\n",
    "                    # 3. pointwise convolution weights (out_channels)\n",
    "                    x = self.point_linear(x)\n",
    "                    return x\n",
    "            \n",
    "            elif len(self.kernel_size_list) == 1:\n",
    "                # kernel size only one, multiple expand ratio, so gumbel length is multple of expand ratio\n",
    "                assert len(gumbel[0]) == len(self.expand_ratio_list), \"gumbel size is not match with expand_ratio_list\"\n",
    "                \n",
    "                if self.inverted_bottleneck:\n",
    "                    # 1. inverted bottleneck weights (max_expand_ratio)\n",
    "                    expand_weight = self.inverted_bottleneck.conv.weight\n",
    "                    expand_max_out = F.conv2d(x, expand_weight, stride=1, padding=0)\n",
    "                    expand_max_out = self.inverted_bottleneck.bn(expand_max_out)\n",
    "                    expand_max_out = self.inverted_bottleneck.act(expand_max_out)\n",
    "                    expand_max_out *= gumbel[:, -1].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                    for i, expand_ratio in enumerate(self.expand_ratio_list[:-1]):\n",
    "                        out = F.conv2d(x, expand_weight[:expand_ratio*self.in_channels, :, :, :], stride=1, padding=0)\n",
    "                        out = F.batch_norm(out, self.inverted_bottleneck.bn.running_mean[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.running_var[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.weight[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.bias[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.training, self.inverted_bottleneck.bn.momentum, self.inverted_bottleneck.bn.eps)\n",
    "                        out = self.inverted_bottleneck.act(out)\n",
    "                        out *= gumbel[:, i].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                        out = F.pad(out, [0, 0, 0, 0, 0, expand_max_out.size(1) - out.size(1)], mode='constant', value=0) # zero pad\n",
    "                        expand_max_out += out\n",
    "                    x = expand_max_out\n",
    "                x = self.depth_conv(x)\n",
    "                x = self.point_linear(x)\n",
    "                return x\n",
    "                \n",
    "            elif len(gumbel[0]) == len(self.expand_ratio_list) + len(self.kernel_size_list):\n",
    "                if self.inverted_bottleneck:\n",
    "                    # 1. inverted bottleneck weights (max_expand_ratio)\n",
    "                    expand_weight = self.inverted_bottleneck.conv.weight\n",
    "                    expand_max_out = F.conv2d(x, expand_weight, stride=1, padding=0)\n",
    "                    expand_max_out = self.inverted_bottleneck.bn(expand_max_out)\n",
    "                    expand_max_out = self.inverted_bottleneck.act(expand_max_out)\n",
    "                    expand_max_out *= gumbel[:, len(self.expand_ratio_list)-1].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                    for i, expand_ratio in enumerate(self.expand_ratio_list[:-1]):\n",
    "                        out = F.conv2d(x, expand_weight[:expand_ratio*self.in_channels, :, :, :], stride=1, padding=0)\n",
    "                        out = F.batch_norm(out, self.inverted_bottleneck.bn.running_mean[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.running_var[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.weight[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.bias[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.training, self.inverted_bottleneck.bn.momentum, self.inverted_bottleneck.bn.eps)\n",
    "                        out = self.inverted_bottleneck.act(out)\n",
    "                        out *= gumbel[:, i].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                        out = F.pad(out, [0, 0, 0, 0, 0, expand_max_out.size(1) - out.size(1)], mode='constant', value=0) # zero pad\n",
    "                        expand_max_out += out\n",
    "                    x = expand_max_out\n",
    "                # 2. depthwise convolution weights (max_kernel_size)\n",
    "                depth_weight = self.depth_conv.conv.weight\n",
    "                pad = get_same_padding(self.max_kernel_size)\n",
    "                kernel_max_out = F.conv2d(x, depth_weight, stride=self.stride, padding=pad, groups=x.size(1))\n",
    "                kernel_max_out = self.depth_conv.bn(kernel_max_out)\n",
    "                kernel_max_out = self.depth_conv.act(kernel_max_out)\n",
    "                kernel_max_out *= gumbel[:, len(self.expand_ratio_list)].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                for i, active_kernel_size in enumerate(self.kernel_size_list[1:]):\n",
    "                    start, end = sub_filter_start_end(self.kernel_size_list[i], active_kernel_size)\n",
    "                    print(start, end, active_kernel_size, self.kernel_size_list[i], depth_weight.shape)\n",
    "                    kernel_weight = depth_weight[:, :, start:end, start:end].contiguous()\n",
    "                    kernel_weight = kernel_weight.view(kernel_weight.size(0), kernel_weight.size(1), -1)\n",
    "                    kernel_weight = self.kernel_transform_linear_list[i](kernel_weight)\n",
    "                    kernel_weight = kernel_weight.view(kernel_weight.size(0), kernel_weight.size(1), active_kernel_size, active_kernel_size)\n",
    "                    pad = get_same_padding(active_kernel_size)\n",
    "                    kernel_out = F.conv2d(x, kernel_weight, stride=self.stride, padding=pad, groups=x.size(1))\n",
    "                    kernel_out = self.depth_conv.bn(kernel_out)\n",
    "                    kernel_out = self.depth_conv.act(kernel_out)\n",
    "                    kernel_out *= gumbel[:, len(self.expand_ratio_list) + i+1].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                    kernel_max_out += kernel_out\n",
    "                x = kernel_max_out\n",
    "                if self.use_se:\n",
    "                    x = self.depth_conv.se(x)\n",
    "                # 3. pointwise convolution weights (out_channels)\n",
    "                x = self.point_linear(x)\n",
    "                return x\n",
    "            else:\n",
    "                assert False, \"gumbel size is not match with expand_ratio_list and kernel_size_list\"\n",
    "            \n",
    "    \n",
    "    @property\n",
    "    def module_str(self):\n",
    "        if self.mid_channels is None:\n",
    "            expand_ratio = self.max_expand_ratio\n",
    "        else:\n",
    "            expand_ratio = self.mid_channels // self.in_channels\n",
    "        layer_str = '%dx%d_GumbelMBConv%d_%s' % (self.max_kernel_size, self.max_kernel_size, expand_ratio, self.act_func.upper())\n",
    "        if self.use_se:\n",
    "            layer_str = 'SE_' + layer_str\n",
    "        layer_str += '_O%d' % self.out_channels\n",
    "        return layer_str\n",
    "\n",
    "    @property\n",
    "    def config(self):\n",
    "        return {\n",
    "            'name': MBGumbelInvertedConvLayer.__name__,\n",
    "            'in_channels': self.in_channels,\n",
    "            'out_channels': self.out_channels,\n",
    "            'kernel_size': self.max_kernel_size,\n",
    "            'kernel_size_list': self.kernel_size_list,\n",
    "            'stride': self.stride,\n",
    "            'expand_ratio': self.max_expand_ratio,\n",
    "            'expand_ratio_list': self.expand_ratio_list,\n",
    "            'mid_channels': self.mid_channels,\n",
    "            'act_func': self.act_func,\n",
    "            'use_se': self.use_se,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def build_from_config(config):\n",
    "        return MBGumbelInvertedConvLayer(**config)\n",
    "    \n",
    "    #@staticmethod\n",
    "    #def build_from_module(module: MBInvertedConvLayer):\n",
    "    #    mbgumbel = MBGumbelInvertedConvLayer.build_from_config(module.config)\n",
    "    #    for n, m in module.named_parameters():\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MobileGumbelInvertedResidualBlock(MyModule):\n",
    "\n",
    "    def __init__(self, mobile_inverted_conv, shortcut):\n",
    "        super(MobileGumbelInvertedResidualBlock, self).__init__()\n",
    "\n",
    "        self.mobile_inverted_conv = mobile_inverted_conv\n",
    "        self.shortcut = shortcut\n",
    "\n",
    "    def forward(self, x, gumbel_idx=None):\n",
    "        if self.mobile_inverted_conv is None or isinstance(self.mobile_inverted_conv, ZeroLayer):\n",
    "            res = x\n",
    "        elif self.shortcut is None or isinstance(self.shortcut, ZeroLayer) and gumbel_idx == None:\n",
    "            res = self.mobile_inverted_conv(x)\n",
    "        elif self.shortcut is None or isinstance(self.shortcut, ZeroLayer) and gumbel_idx != None:\n",
    "            res = self.mobile_inverted_conv(x, gumbel_idx)\n",
    "        elif self.shortcut is not None and gumbel_idx == None:\n",
    "            res = self.mobile_inverted_conv(x) + self.shortcut(x)\n",
    "        else:\n",
    "            res = self.mobile_inverted_conv(x, gumbel_idx) + self.shortcut(x)\n",
    "        return res\n",
    "\n",
    "    @property\n",
    "    def module_str(self):\n",
    "        return '(%s, %s)' % (\n",
    "            self.mobile_inverted_conv.module_str if self.mobile_inverted_conv is not None else None,\n",
    "            self.shortcut.module_str if self.shortcut is not None else None\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def config(self):\n",
    "        return {\n",
    "            'name': MobileGumbelInvertedResidualBlock.__name__,\n",
    "            'mobile_inverted_conv': self.mobile_inverted_conv.config if self.mobile_inverted_conv is not None else None,\n",
    "            'shortcut': self.shortcut.config if self.shortcut is not None else None,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def build_from_config(config):\n",
    "        mobile_inverted_conv = MBGumbelInvertedConvLayer.build_from_config(config['mobile_inverted_conv'])\n",
    "        shortcut = set_layer_from_config(config['shortcut'])\n",
    "        return MobileGumbelInvertedResidualBlock(mobile_inverted_conv, shortcut)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_from_module(module):\n",
    "        if isinstance(module, MobileGumbelInvertedResidualBlock):\n",
    "            print(\"build from gumbel module\")\n",
    "            return module\n",
    "        elif isinstance(module, MobileInvertedResidualBlock):\n",
    "            print(\"build from normal MobileInvertedResidualBlock module\")\n",
    "            mobile_inverted_conv = module.mobile_inverted_conv\n",
    "            shortcut = module.shortcut\n",
    "            return MobileGumbelInvertedResidualBlock(module.mobile_inverted_conv, module.shortcut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GumbelMCUNets(MyNetwork):\n",
    "    def __init__(self, first_conv, blocks, feature_mix_layer, classifier, gumbel_feature_extract_block):\n",
    "        super(GumbelMCUNets, self).__init__()\n",
    "        \n",
    "        self.first_conv = first_conv\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "        self.feature_mix_layer = feature_mix_layer\n",
    "        self.classifier = classifier\n",
    "        self.gumbel_feature_extract_block = gumbel_feature_extract_block\n",
    "        \n",
    "        self.gumbel_index_list = []\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            if i < self.gumbel_feature_extract_block:\n",
    "                continue\n",
    "            if len(block.mobile_inverted_conv.expand_ratio_list) > 1:\n",
    "                self.gumbel_index_list.append(len(block.mobile_inverted_conv.expand_ratio_list))\n",
    "                \n",
    "            if len(block.mobile_inverted_conv.kernel_size_list) > 1:\n",
    "                self.gumbel_index_list.append(len(block.mobile_inverted_conv.kernel_size_list))\n",
    "        \n",
    "        \n",
    "        self.gumbel_input_channel = blocks[gumbel_feature_extract_block].mobile_inverted_conv.out_channels\n",
    "        \n",
    "        self.avgpool_policy = nn.AdaptiveAvgPool2d((8, 8))\n",
    "        self.gumbel_features_flatten = nn.Flatten()\n",
    "        self.gumbel_fc1 = nn.Linear(self.gumbel_input_channel*8*8, 256)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.gumbel_fc2 = nn.Linear(256, sum(self.gumbel_index_list))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.first_conv(x)\n",
    "        for i, block in enumerate(self.blocks):            \n",
    "            if i == self.gumbel_feature_extract_block:\n",
    "                # feautre map and gumbel output extract\n",
    "                gumbel_input = self.avgpool_policy(x)\n",
    "                gumbel_input = self.gumbel_features_flatten(gumbel_input)\n",
    "                gumbel_input = self.gumbel_fc1(gumbel_input)\n",
    "                gumbel_input = self.dropout(gumbel_input)\n",
    "                gumbel_output = self.gumbel_fc2(gumbel_input)\n",
    "                gumbel_output = gumbel_output.view(-1, sum(self.gumbel_index_list))\n",
    "                break\n",
    "            x = block(x)\n",
    "\n",
    "        gumbel_index = 0\n",
    "        for j, block in enumerate(self.blocks[self.gumbel_feature_extract_block:]):\n",
    "            expand_index, kernel_index = len(block.mobile_inverted_conv.expand_ratio_list), len(block.mobile_inverted_conv.kernel_size_list)\n",
    "            print(f'{j} idx {gumbel_index} expand {expand_index} kernel {kernel_index}')\n",
    "            if expand_index > 1 and kernel_index > 1:\n",
    "                gumbel_input = gumbel_output[:, gumbel_index: gumbel_index + expand_index  + kernel_index]\n",
    "                gumbel_one_hot = F.gumbel_softmax(gumbel_input, tau=1, hard=True)\n",
    "                gumbel_index += expand_index + kernel_index\n",
    "                \n",
    "            elif expand_index > 1:\n",
    "                gumbel_input = gumbel_output[:, gumbel_index: gumbel_index + expand_index]\n",
    "                gumbel_one_hot = F.gumbel_softmax(gumbel_input, tau=1, hard=True)\n",
    "                gumbel_index += expand_index\n",
    "            elif kernel_index >1:\n",
    "                gumbel_input = gumbel_output[:, gumbel_index: gumbel_index + kernel_index]\n",
    "                gumbel_one_hot = F.gumbel_softmax(gumbel_input, tau=1, hard=True)\n",
    "                gumbel_index += kernel_index\n",
    "            else:\n",
    "                gumbel_one_hot = None\n",
    "            x = block(x, gumbel_one_hot)    \n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def module_str(self):\n",
    "        _str = self.first_conv.module_str + '\\n'\n",
    "        for block in self.blocks:\n",
    "            _str += block.module_str + '\\n'\n",
    "        _str += self.feature_mix_layer.module_str + '\\n'\n",
    "        _str += self.classifier.module_str\n",
    "        return _str\n",
    "        \n",
    "    @property\n",
    "    def config(self):\n",
    "        return {\n",
    "            'name': GumbelMCUNets.__name__,\n",
    "            'bn': self.get_bn_param(),\n",
    "            'first_conv': self.first_conv.config,\n",
    "            'blocks': [\n",
    "                block.config for block in self.blocks\n",
    "            ],\n",
    "            'feature_mix_layer': None if self.feature_mix_layer is None else self.feature_mix_layer.config,\n",
    "            'classifier': self.classifier.config,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def build_from_config(net_config, gumbel_config):\n",
    "        MBGumbelInvertedConvLayer.global_expand_ratio_list = gumbel_config['global_expand_ratio_list']\n",
    "        MBGumbelInvertedConvLayer.global_kernel_size_list = gumbel_config['global_kernel_size_list']\n",
    "        gumbel_feature_extract_block = gumbel_config['gumbel_feature_extract_block']\n",
    "        \n",
    "        first_conv = set_layer_from_config(net_config['first_conv'])\n",
    "        feature_mix_layer = set_layer_from_config(net_config['feature_mix_layer'])\n",
    "        classifier = set_layer_from_config(net_config['classifier'])\n",
    "        \n",
    "        blocks = []\n",
    "        \n",
    "        for i, block_config in enumerate(net_config['blocks']):\n",
    "            if i < gumbel_feature_extract_block:\n",
    "                print(i, block_config)\n",
    "                blocks.append(MobileInvertedResidualBlock.build_from_config(block_config))\n",
    "            else:\n",
    "                blocks.append(MobileGumbelInvertedResidualBlock.build_from_config(block_config))\n",
    "        \n",
    "        net = GumbelMCUNets(first_conv, blocks, feature_mix_layer, classifier, gumbel_feature_extract_block)\n",
    "        \n",
    "        if 'bn' in net_config:\n",
    "            net.set_bn_param(**net_config['bn'])\n",
    "        else:\n",
    "            net.set_bn_param(momentum=0.1, eps=1e-3)\n",
    "        \n",
    "        return net\n",
    "    \n",
    "    def load_pretrained_mcunet_param(self, mcunet):\n",
    "        \n",
    "        for n, p in self.named_parameters():\n",
    "            if has_deep_attr(mcunet, n):\n",
    "                print(\"load {} params ({})\".format(n, p.shape))\n",
    "                set_deep_attr(self, n, get_deep_attr(mcunet, n))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'name': 'MobileInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBInvertedConvLayer', 'in_channels': 32, 'out_channels': 16, 'kernel_size': 3, 'stride': 1, 'expand_ratio': 1, 'mid_channels': None, 'act_func': 'relu6', 'use_se': False}, 'shortcut': None}\n",
      "1 {'name': 'MobileInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBInvertedConvLayer', 'in_channels': 16, 'out_channels': 24, 'kernel_size': 7, 'stride': 2, 'expand_ratio': 3, 'mid_channels': 48, 'act_func': 'relu6', 'use_se': False}, 'shortcut': None}\n",
      "load first_conv.conv.weight params (torch.Size([32, 3, 3, 3]))\n",
      "load first_conv.bn.weight params (torch.Size([32]))\n",
      "load first_conv.bn.bias params (torch.Size([32]))\n",
      "load blocks.0.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([32, 1, 3, 3]))\n",
      "load blocks.0.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([32]))\n",
      "load blocks.0.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([32]))\n",
      "load blocks.0.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([16, 32, 1, 1]))\n",
      "load blocks.0.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([16]))\n",
      "load blocks.0.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([16]))\n",
      "load blocks.1.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([48, 16, 1, 1]))\n",
      "load blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([48]))\n",
      "load blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([48]))\n",
      "load blocks.1.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([48, 1, 7, 7]))\n",
      "load blocks.1.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([48]))\n",
      "load blocks.1.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([48]))\n",
      "load blocks.1.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([24, 48, 1, 1]))\n",
      "load blocks.1.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([24]))\n",
      "load blocks.1.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([24]))\n",
      "load blocks.2.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([120, 24, 1, 1]))\n",
      "load blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([120]))\n",
      "load blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([120]))\n",
      "load blocks.2.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([120, 1, 3, 3]))\n",
      "load blocks.2.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([120]))\n",
      "load blocks.2.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([120]))\n",
      "load blocks.2.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([24, 120, 1, 1]))\n",
      "load blocks.2.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([24]))\n",
      "load blocks.2.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([24]))\n",
      "load blocks.3.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([96, 24, 1, 1]))\n",
      "load blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([96]))\n",
      "load blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([96]))\n",
      "load blocks.3.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([96, 1, 5, 5]))\n",
      "load blocks.3.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([96]))\n",
      "load blocks.3.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([96]))\n",
      "load blocks.3.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([24, 96, 1, 1]))\n",
      "load blocks.3.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([24]))\n",
      "load blocks.3.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([24]))\n",
      "load blocks.4.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([120, 24, 1, 1]))\n",
      "load blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([120]))\n",
      "load blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([120]))\n",
      "load blocks.4.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([120, 1, 7, 7]))\n",
      "load blocks.4.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([120]))\n",
      "load blocks.4.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([120]))\n",
      "load blocks.4.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([40, 120, 1, 1]))\n",
      "load blocks.4.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([40]))\n",
      "load blocks.4.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([40]))\n",
      "load blocks.5.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([160, 40, 1, 1]))\n",
      "load blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([160]))\n",
      "load blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([160]))\n",
      "load blocks.5.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([160, 1, 3, 3]))\n",
      "load blocks.5.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([160]))\n",
      "load blocks.5.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([160]))\n",
      "load blocks.5.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([40, 160, 1, 1]))\n",
      "load blocks.5.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([40]))\n",
      "load blocks.5.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([40]))\n",
      "load blocks.6.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([160, 40, 1, 1]))\n",
      "load blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([160]))\n",
      "load blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([160]))\n",
      "load blocks.6.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([160, 1, 7, 7]))\n",
      "load blocks.6.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([160]))\n",
      "load blocks.6.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([160]))\n",
      "load blocks.6.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([40, 160, 1, 1]))\n",
      "load blocks.6.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([40]))\n",
      "load blocks.6.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([40]))\n",
      "load blocks.7.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([120, 40, 1, 1]))\n",
      "load blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([120]))\n",
      "load blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([120]))\n",
      "load blocks.7.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([120, 1, 7, 7]))\n",
      "load blocks.7.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([120]))\n",
      "load blocks.7.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([120]))\n",
      "load blocks.7.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([80, 120, 1, 1]))\n",
      "load blocks.7.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([80]))\n",
      "load blocks.7.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([80]))\n",
      "load blocks.8.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([240, 80, 1, 1]))\n",
      "load blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([240]))\n",
      "load blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([240]))\n",
      "load blocks.8.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([240, 1, 3, 3]))\n",
      "load blocks.8.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([240]))\n",
      "load blocks.8.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([240]))\n",
      "load blocks.8.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([80, 240, 1, 1]))\n",
      "load blocks.8.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([80]))\n",
      "load blocks.8.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([80]))\n",
      "load blocks.9.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([240, 80, 1, 1]))\n",
      "load blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([240]))\n",
      "load blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([240]))\n",
      "load blocks.9.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([240, 1, 7, 7]))\n",
      "load blocks.9.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([240]))\n",
      "load blocks.9.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([240]))\n",
      "load blocks.9.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([80, 240, 1, 1]))\n",
      "load blocks.9.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([80]))\n",
      "load blocks.9.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([80]))\n",
      "load blocks.10.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([320, 80, 1, 1]))\n",
      "load blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([320]))\n",
      "load blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([320]))\n",
      "load blocks.10.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([320, 1, 3, 3]))\n",
      "load blocks.10.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([320]))\n",
      "load blocks.10.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([320]))\n",
      "load blocks.10.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([96, 320, 1, 1]))\n",
      "load blocks.10.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([96]))\n",
      "load blocks.10.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([96]))\n",
      "load blocks.11.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([288, 96, 1, 1]))\n",
      "load blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([288]))\n",
      "load blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([288]))\n",
      "load blocks.11.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([288, 1, 5, 5]))\n",
      "load blocks.11.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([288]))\n",
      "load blocks.11.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([288]))\n",
      "load blocks.11.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([96, 288, 1, 1]))\n",
      "load blocks.11.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([96]))\n",
      "load blocks.11.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([96]))\n",
      "load blocks.12.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([288, 96, 1, 1]))\n",
      "load blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([288]))\n",
      "load blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([288]))\n",
      "load blocks.12.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([288, 1, 5, 5]))\n",
      "load blocks.12.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([288]))\n",
      "load blocks.12.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([288]))\n",
      "load blocks.12.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([96, 288, 1, 1]))\n",
      "load blocks.12.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([96]))\n",
      "load blocks.12.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([96]))\n",
      "load blocks.13.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([384, 96, 1, 1]))\n",
      "load blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([384]))\n",
      "load blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([384]))\n",
      "load blocks.13.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([384, 1, 7, 7]))\n",
      "load blocks.13.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([384]))\n",
      "load blocks.13.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([384]))\n",
      "load blocks.13.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([192, 384, 1, 1]))\n",
      "load blocks.13.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([192]))\n",
      "load blocks.13.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([192]))\n",
      "load blocks.14.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([576, 192, 1, 1]))\n",
      "load blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([576]))\n",
      "load blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([576]))\n",
      "load blocks.14.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([576, 1, 7, 7]))\n",
      "load blocks.14.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([576]))\n",
      "load blocks.14.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([576]))\n",
      "load blocks.14.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([192, 576, 1, 1]))\n",
      "load blocks.14.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([192]))\n",
      "load blocks.14.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([192]))\n",
      "load blocks.15.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([576, 192, 1, 1]))\n",
      "load blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([576]))\n",
      "load blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([576]))\n",
      "load blocks.15.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([576, 1, 5, 5]))\n",
      "load blocks.15.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([576]))\n",
      "load blocks.15.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([576]))\n",
      "load blocks.15.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([192, 576, 1, 1]))\n",
      "load blocks.15.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([192]))\n",
      "load blocks.15.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([192]))\n",
      "load blocks.16.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([768, 192, 1, 1]))\n",
      "load blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([768]))\n",
      "load blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([768]))\n",
      "load blocks.16.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([768, 1, 5, 5]))\n",
      "load blocks.16.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([768]))\n",
      "load blocks.16.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([768]))\n",
      "load blocks.16.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([320, 768, 1, 1]))\n",
      "load blocks.16.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([320]))\n",
      "load blocks.16.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([320]))\n",
      "load classifier.linear.weight params (torch.Size([1000, 320]))\n",
      "load classifier.linear.bias params (torch.Size([1000]))\n"
     ]
    }
   ],
   "source": [
    "gubmel_config = {'global_expand_ratio_list':[1,3,5,6], 'global_kernel_size_list':[3,5,7], 'gumbel_feature_extract_block':2}\n",
    "net = GumbelMCUNets.build_from_config(model.config, gubmel_config)\n",
    "net.load_pretrained_mcunet_param(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 idx 0 expand 3 kernel 1\n",
      "gumbel shape :  torch.Size([32, 3])\n",
      "1 idx 3 expand 1 kernel 2\n",
      "gumbel shape :  torch.Size([32, 2])\n",
      "1 4 3 5 torch.Size([96, 1, 5, 5])\n",
      "2 idx 5 expand 3 kernel 3\n",
      "3 idx 11 expand 1 kernel 1\n",
      "4 idx 11 expand 1 kernel 3\n",
      "gumbel shape :  torch.Size([32, 3])\n",
      "1 6 5 7 torch.Size([160, 1, 7, 7])\n",
      "1 4 3 5 torch.Size([160, 1, 7, 7])\n",
      "5 idx 14 expand 2 kernel 3\n",
      "6 idx 19 expand 2 kernel 1\n",
      "gumbel shape :  torch.Size([32, 2])\n",
      "7 idx 21 expand 2 kernel 3\n",
      "gumbel shape :  torch.Size([32, 5])\n",
      "1 6 5 7 torch.Size([240, 1, 7, 7])\n",
      "1 4 3 5 torch.Size([240, 1, 7, 7])\n",
      "8 idx 26 expand 1 kernel 1\n",
      "9 idx 26 expand 2 kernel 2\n",
      "gumbel shape :  torch.Size([32, 4])\n",
      "1 4 3 5 torch.Size([288, 1, 5, 5])\n",
      "10 idx 30 expand 2 kernel 2\n",
      "gumbel shape :  torch.Size([32, 4])\n",
      "1 4 3 5 torch.Size([288, 1, 5, 5])\n",
      "11 idx 34 expand 1 kernel 3\n",
      "12 idx 37 expand 2 kernel 3\n",
      "gumbel shape :  torch.Size([32, 5])\n",
      "1 6 5 7 torch.Size([576, 1, 7, 7])\n",
      "1 4 3 5 torch.Size([576, 1, 7, 7])\n",
      "13 idx 42 expand 2 kernel 2\n",
      "gumbel shape :  torch.Size([32, 4])\n",
      "1 4 3 5 torch.Size([576, 1, 5, 5])\n",
      "14 idx 46 expand 1 kernel 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.3990e-01,  1.1834e+00,  5.0777e-01,  1.5521e+00,  1.2887e+00],\n",
       "          [-9.3998e-01,  4.4247e-01,  1.2818e+00,  1.3321e+00, -3.2027e-01],\n",
       "          [ 4.1081e-01,  1.3616e+00,  9.2334e-01,  2.7235e+00,  1.7387e+00],\n",
       "          [ 8.7208e-01,  7.8590e-01,  1.5917e+00,  1.5816e+00,  1.5297e+00],\n",
       "          [ 6.2008e-01,  1.5646e+00,  2.2941e+00,  2.0672e+00,  1.5485e+00]],\n",
       "\n",
       "         [[-1.7681e+00, -1.6789e+00, -1.2385e+00, -1.2919e+00, -1.0917e+00],\n",
       "          [-3.8603e+00, -1.7437e+00, -2.2686e+00, -1.8106e+00, -1.2070e+00],\n",
       "          [-3.0332e+00, -3.2537e+00, -1.8364e+00, -8.1870e-01, -8.4870e-01],\n",
       "          [-3.3548e+00, -3.0304e+00, -3.3130e+00, -1.0186e+00, -5.7489e-01],\n",
       "          [-3.0177e+00, -1.6780e+00, -9.3492e-01, -1.2598e+00, -6.3860e-01]],\n",
       "\n",
       "         [[-6.0577e-01, -1.6760e+00, -1.9246e+00, -2.2948e+00, -6.9886e-01],\n",
       "          [-2.1461e+00, -1.9383e+00, -2.4877e+00, -1.9728e+00, -1.7040e+00],\n",
       "          [-2.5991e+00, -3.8519e+00, -1.7046e+00, -2.9907e+00, -2.2588e+00],\n",
       "          [-3.1843e+00, -2.5154e+00, -2.7792e+00, -2.0902e+00, -1.5090e+00],\n",
       "          [-2.6224e+00, -2.7753e+00, -3.1933e+00, -1.4513e+00, -1.3816e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.3910e+00,  1.8132e+00,  1.9734e+00,  1.5061e+00,  9.2104e-01],\n",
       "          [ 7.2467e-01,  2.2729e+00,  1.3276e+00,  1.1431e+00,  1.0909e+00],\n",
       "          [ 3.4689e-01,  6.9997e-01,  3.6179e+00,  1.5831e+00, -7.5813e-01],\n",
       "          [ 1.4448e+00, -1.2211e+00,  3.2071e-01,  7.6139e-01,  6.9699e-01],\n",
       "          [ 6.6202e-01, -1.9445e-01,  4.7047e-01,  3.5602e-01,  4.4815e-01]],\n",
       "\n",
       "         [[ 2.5623e+00,  3.4476e+00,  2.7009e+00,  1.1300e+00,  1.1293e+00],\n",
       "          [ 4.6590e+00,  4.7992e+00,  4.3899e+00,  4.6084e+00,  1.9664e+00],\n",
       "          [ 4.2436e+00,  5.0659e+00,  7.0633e+00,  2.4217e+00,  1.0696e+00],\n",
       "          [ 2.4797e+00,  4.6775e+00,  4.3944e+00,  1.7498e+00,  7.9929e-01],\n",
       "          [ 1.0759e+00,  2.4668e+00,  1.0172e+00,  5.6666e-01,  4.4483e-02]],\n",
       "\n",
       "         [[ 1.3263e+00,  1.5860e+00,  1.4962e+00,  1.2956e+00,  1.1261e+00],\n",
       "          [ 1.6967e+00,  1.6731e+00,  1.8868e+00,  1.8361e+00,  1.8989e+00],\n",
       "          [ 2.5750e+00,  1.7524e+00,  2.6814e+00,  2.7348e+00,  2.3413e+00],\n",
       "          [ 2.1368e+00,  1.5780e+00,  2.2342e+00,  1.8784e+00,  2.1482e+00],\n",
       "          [ 1.6152e+00,  1.7753e+00,  1.8726e+00,  2.4656e+00,  1.1760e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 9.1932e-01,  7.5164e-01,  7.6551e-01, -9.8163e-01,  8.1195e-03],\n",
       "          [ 2.4146e-01,  9.3416e-01,  9.0851e-01, -1.0770e+00, -8.4846e-01],\n",
       "          [ 7.1400e-01,  1.0968e+00,  4.1776e-01, -1.9614e+00, -7.7818e-01],\n",
       "          [ 6.0107e-01,  7.0067e-01, -8.7682e-01, -1.1010e+00, -1.7742e-01],\n",
       "          [ 5.8944e-01, -1.2048e-01, -3.0342e-02, -5.7784e-01, -5.9675e-01]],\n",
       "\n",
       "         [[-3.2725e-01, -9.9286e-01, -6.9873e-01, -6.5668e-01, -3.4442e-01],\n",
       "          [-1.2667e+00, -1.1359e+00, -1.0179e+00, -9.8198e-01, -4.1244e-01],\n",
       "          [-1.6286e-01, -7.4914e-01, -5.5984e-01, -1.6345e-01, -4.9977e-01],\n",
       "          [-4.3055e-01, -3.9955e-01,  2.0381e-02,  3.7917e-01, -6.6830e-01],\n",
       "          [-5.3834e-01,  9.6734e-02,  2.5373e-01, -4.7886e-01, -5.4181e-01]],\n",
       "\n",
       "         [[ 5.2025e-01,  6.4079e-01,  1.1615e+00,  7.5297e-01,  4.2143e-01],\n",
       "          [ 1.9297e-01,  8.6601e-01,  5.0050e-01,  6.9508e-01,  2.1464e-01],\n",
       "          [ 2.3824e-01,  9.9016e-01,  1.4058e-01, -9.6597e-01,  7.6867e-01],\n",
       "          [-3.2846e-01,  1.8767e-01,  1.3667e+00, -1.0140e+00, -1.4686e-01],\n",
       "          [ 2.0093e-01,  2.6909e-01, -2.3614e-01, -4.2198e-03, -1.8256e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.2417e-01,  2.9849e-01,  7.7654e-02,  1.4242e+00,  6.7259e-01],\n",
       "          [ 8.9021e-01,  1.3308e-01,  6.9819e-01,  6.8923e-01,  7.9899e-01],\n",
       "          [ 9.5110e-01,  1.4927e+00,  1.0272e-01,  1.4451e+00,  1.0881e+00],\n",
       "          [ 1.2548e+00,  1.1855e+00,  7.3226e-01,  1.4460e+00,  7.7121e-01],\n",
       "          [ 7.9944e-01,  1.0558e+00,  1.4775e+00,  1.2957e+00,  7.0905e-01]],\n",
       "\n",
       "         [[ 3.1697e-01,  1.0076e+00,  7.9895e-01,  1.3034e+00,  1.0782e+00],\n",
       "          [ 8.5284e-01,  1.7175e+00,  6.5076e-01,  7.1278e-01,  1.2797e+00],\n",
       "          [ 2.7221e-01,  9.5187e-01,  2.8568e-01,  1.5722e+00,  1.0437e+00],\n",
       "          [ 3.3448e-01, -2.5557e-03,  8.8990e-01,  7.7681e-01,  7.7771e-01],\n",
       "          [ 1.0577e+00,  1.3558e+00,  3.9970e-01,  4.3431e-01,  1.0368e+00]],\n",
       "\n",
       "         [[ 6.1533e-01,  5.4658e-01, -5.0439e-01, -2.2296e-01,  4.3156e-01],\n",
       "          [ 5.8879e-01,  5.7510e-02,  7.2346e-01, -1.4606e-01,  6.2763e-01],\n",
       "          [ 1.9764e-01,  6.0207e-01,  4.4361e-01,  7.8264e-01,  1.6319e-01],\n",
       "          [ 4.8585e-01, -5.2577e-01, -8.8906e-01,  6.7498e-02,  5.3574e-01],\n",
       "          [ 2.9755e-01, -3.1500e-01, -3.6746e-02,  1.9779e-01,  6.5905e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5066e+00, -5.9876e-01, -4.6753e-01,  9.4847e-01,  1.1026e+00],\n",
       "          [ 1.2864e+00,  1.8943e+00,  4.1573e-01,  6.6932e-01, -1.9642e-01],\n",
       "          [ 3.5991e-01, -6.7770e-01,  1.3322e+00,  4.5379e-01,  5.5291e-01],\n",
       "          [ 1.6033e+00,  5.9124e-01,  4.5350e-01,  1.8179e+00,  1.2781e+00],\n",
       "          [-2.2662e-01,  1.9542e-01, -1.3631e+00,  8.3194e-01,  4.0166e-01]],\n",
       "\n",
       "         [[ 1.3363e+00,  2.8927e+00,  4.4465e+00,  2.1039e+00,  2.5190e+00],\n",
       "          [ 2.0045e+00,  3.7887e+00,  4.0541e+00,  2.7485e+00,  3.1227e+00],\n",
       "          [ 4.4935e+00,  2.5197e+00,  4.0751e+00,  5.0030e+00,  3.0289e+00],\n",
       "          [ 3.0193e+00,  3.6066e+00,  3.4367e+00,  3.7567e+00,  3.6683e+00],\n",
       "          [ 1.7388e+00,  3.6851e+00,  4.6296e+00,  1.7134e+00,  1.8110e+00]],\n",
       "\n",
       "         [[-1.1639e+00, -2.3625e+00, -7.2245e-01, -1.9892e+00, -3.2166e+00],\n",
       "          [-1.0656e+00, -1.3190e+00, -3.9606e+00, -3.2443e+00, -4.7179e-01],\n",
       "          [-1.2623e+00, -3.6349e+00, -1.0146e+00, -2.9505e+00, -3.3710e+00],\n",
       "          [-2.0592e+00, -1.6554e+00, -5.3505e-01, -3.1304e+00, -3.5381e+00],\n",
       "          [-2.0358e-02,  2.0367e-01, -1.4792e+00, -2.7932e+00, -6.0314e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.1866e+00, -2.4254e+00, -1.9136e+00, -1.6125e+00, -2.0294e+00],\n",
       "          [-1.5289e+00, -6.7775e-01, -2.6861e+00, -1.8109e+00, -4.3168e+00],\n",
       "          [-1.4442e+00, -4.1774e-01, -2.8784e+00, -1.6699e+00, -1.1320e+00],\n",
       "          [ 1.2176e+00, -7.8728e-02, -1.8921e+00, -2.7517e+00, -2.2460e-01],\n",
       "          [ 5.4488e-01, -7.1096e-01,  8.1655e-01, -3.9842e-01, -1.0959e+00]],\n",
       "\n",
       "         [[ 1.1223e+00,  1.0189e+00,  1.2400e+00,  1.3652e+00,  1.7124e+00],\n",
       "          [ 3.3377e+00,  1.7788e+00,  1.3598e+00,  2.1208e+00,  1.9489e+00],\n",
       "          [ 2.9816e+00,  2.7527e+00,  8.5057e-01,  5.2095e-01,  1.2791e+00],\n",
       "          [ 1.8781e+00,  8.2789e-01,  1.1702e+00,  6.3843e-01,  1.9995e+00],\n",
       "          [ 1.3789e+00,  1.2878e+00,  1.3720e-01,  5.5133e-01,  6.2132e-01]],\n",
       "\n",
       "         [[-2.0802e-02, -6.4139e-03,  5.5046e-01, -3.1403e-01, -9.5774e-02],\n",
       "          [-6.3428e-01,  7.3633e-01, -6.3865e-01, -7.1058e-01,  8.3853e-01],\n",
       "          [-1.3593e-01, -4.6227e-01, -5.3863e-01,  3.8846e-01, -9.3116e-01],\n",
       "          [-6.0477e-01, -5.9569e-01, -8.2062e-01, -6.9954e-01, -1.2131e+00],\n",
       "          [ 5.4034e-01, -5.3103e-01, -4.5627e-02, -9.1411e-01,  2.7601e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 8.6665e-01,  9.2622e-01,  1.2874e+00,  1.0679e+00,  1.2480e+00],\n",
       "          [ 1.3989e+00,  1.1281e+00,  1.8782e+00,  1.3278e+00,  1.1430e+00],\n",
       "          [ 1.6433e+00,  1.9031e+00,  3.0740e+00,  2.6889e+00,  1.8352e+00],\n",
       "          [ 1.1685e+00,  1.0564e+00,  1.5811e+00,  1.3202e+00,  1.6768e+00],\n",
       "          [ 1.5442e-01,  9.4494e-01,  5.0749e-01,  1.2379e+00,  1.3712e+00]],\n",
       "\n",
       "         [[ 1.1167e+00,  1.3219e+00,  1.5090e+00,  1.5609e+00,  1.4291e+00],\n",
       "          [ 1.5040e+00,  1.4429e+00,  2.0480e+00,  2.1884e+00,  1.5921e+00],\n",
       "          [ 1.8688e+00,  1.9998e+00,  2.3960e+00,  2.8424e+00,  2.1667e+00],\n",
       "          [ 1.8419e+00,  2.6684e+00,  2.2446e+00,  2.2965e+00,  1.6768e+00],\n",
       "          [ 1.5038e+00,  1.7878e+00,  2.1694e+00,  2.1067e+00,  1.4010e+00]],\n",
       "\n",
       "         [[ 6.6018e-01,  9.1002e-02, -6.9259e-01, -2.5839e-01,  1.8180e-02],\n",
       "          [-1.0725e-01, -4.5353e-01, -1.0248e+00, -1.4734e+00, -5.1553e-01],\n",
       "          [-5.7125e-01, -1.3077e+00, -1.9538e+00, -3.1020e+00, -1.2446e+00],\n",
       "          [-4.5075e-01, -1.2051e+00, -2.3301e+00, -2.0974e+00, -8.4861e-01],\n",
       "          [ 3.5117e-02, -7.1369e-01, -1.4357e+00, -9.8188e-01, -2.5785e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.1418e-01,  5.1254e-01,  9.4864e-01,  3.9800e-01,  1.5894e-01],\n",
       "          [-2.2529e-01, -1.2998e-01,  1.9928e-01,  5.2589e-01, -6.3034e-02],\n",
       "          [-4.5038e-01,  1.4494e+00,  9.4852e-01,  5.7999e-01,  4.4781e-01],\n",
       "          [ 3.3493e-01,  1.3462e+00,  2.3573e+00,  1.3545e+00,  2.6427e-01],\n",
       "          [-9.2256e-04,  3.0681e-01,  1.6218e+00,  6.3024e-01, -3.1683e-01]],\n",
       "\n",
       "         [[ 1.2555e+00,  1.2932e+00,  1.0934e+00,  1.2496e+00,  1.4095e+00],\n",
       "          [ 2.1172e-01,  3.2069e-01,  1.4412e-01,  7.2283e-01,  5.9848e-01],\n",
       "          [ 9.4192e-01,  3.4615e-01,  1.1177e-03,  4.3591e-01,  8.9704e-01],\n",
       "          [ 1.6415e-01,  3.3190e-01, -4.2486e-01,  4.4116e-01,  4.4644e-01],\n",
       "          [ 2.5475e-01,  9.8250e-02,  5.1233e-01,  2.8747e-02,  9.0475e-01]],\n",
       "\n",
       "         [[ 6.9728e-02,  1.6598e-01, -1.6789e-02,  5.5630e-03,  1.2164e-01],\n",
       "          [ 4.4966e-01,  6.5104e-01,  4.4615e-01, -1.5798e-01,  4.1502e-01],\n",
       "          [ 4.1336e-02,  5.7225e-01,  7.1826e-01,  7.5688e-02,  1.4130e-01],\n",
       "          [ 2.4489e-01, -5.3902e-01, -4.2312e-01, -3.1617e-01, -5.8769e-02],\n",
       "          [ 2.7488e-01,  2.4605e-01, -3.9443e-01, -1.4995e-01, -2.5153e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.6736e+00, -7.2455e-01,  1.6680e+00,  7.4417e-01,  5.5790e-01],\n",
       "          [ 1.6769e+00, -4.0187e+00, -3.7249e+00, -3.8274e+00,  2.3819e-01],\n",
       "          [-1.8585e+00, -3.3212e+00, -3.9247e+00, -9.6719e+00, -1.6701e+00],\n",
       "          [-5.9507e-01, -4.2280e+00, -2.1354e+00, -4.6947e+00, -2.2683e+00],\n",
       "          [ 1.7171e+00, -2.5816e+00, -5.6064e+00, -2.7066e+00,  3.0758e-01]],\n",
       "\n",
       "         [[-2.2302e+00, -3.9666e-01,  7.4110e-01,  4.4859e-01, -9.1164e-01],\n",
       "          [-2.7408e+00, -2.0184e+00,  1.4296e+00, -8.8512e-01,  3.9612e-01],\n",
       "          [-9.9558e-01, -7.3925e-01,  4.0468e-01,  7.4684e-01,  2.1355e+00],\n",
       "          [-1.3632e+00, -2.5916e+00, -5.2791e-01,  9.6784e-01,  8.5239e-01],\n",
       "          [-2.6526e+00, -7.9676e-01, -1.4237e-01, -1.8820e+00, -1.0365e+00]],\n",
       "\n",
       "         [[ 2.6619e+00,  2.9837e+00,  2.0884e+00,  1.0137e+00,  2.7498e-01],\n",
       "          [ 3.0014e+00,  1.8887e+00,  3.7798e+00, -8.6158e-01,  2.6103e-02],\n",
       "          [ 6.3465e-01,  4.1272e+00,  3.0540e+00, -2.2903e+00, -2.8947e-01],\n",
       "          [ 1.5603e+00,  1.6251e+00,  2.9834e+00,  1.3327e+00,  6.3567e-01],\n",
       "          [ 3.9746e-01, -1.8626e-01,  3.4466e+00,  1.7570e+00, -5.4463e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.8217e-01,  1.1104e+00,  3.4390e+00,  1.1038e+00,  1.4961e+00],\n",
       "          [ 2.7939e+00,  1.9338e+00,  3.8415e+00,  3.3706e+00,  3.0643e+00],\n",
       "          [ 1.1344e+00,  3.3973e+00,  9.2625e-01,  2.6763e+00,  3.8008e+00],\n",
       "          [-4.1465e-01,  4.1689e-01, -1.0825e+00,  3.0537e-01, -9.6463e-01],\n",
       "          [-3.1094e+00, -2.3570e+00, -5.3011e-01, -1.3394e+00, -2.1477e+00]],\n",
       "\n",
       "         [[-8.0379e-01, -2.9189e+00, -4.4682e+00, -2.6983e+00, -1.5240e+00],\n",
       "          [-8.4507e-01, -3.4014e+00, -5.1008e+00, -3.4156e+00, -3.9467e+00],\n",
       "          [-1.5386e+00, -3.1367e+00, -4.0893e+00, -6.0143e+00, -5.5738e+00],\n",
       "          [-3.3355e+00, -5.3697e+00, -3.9139e+00, -3.9878e+00, -5.3646e+00],\n",
       "          [-7.3688e-01, -2.6086e+00, -3.5478e+00, -2.2478e+00, -1.5981e+00]],\n",
       "\n",
       "         [[ 2.3100e+00,  4.4611e+00,  5.2110e+00,  2.3815e+00,  2.9199e+00],\n",
       "          [ 4.7230e+00,  5.3984e+00,  6.3769e+00,  5.4428e+00,  3.6096e+00],\n",
       "          [ 6.0289e+00,  6.2004e+00,  6.0497e+00,  6.2677e+00,  4.8816e+00],\n",
       "          [ 3.0828e+00,  5.2436e+00,  3.9554e+00,  3.8407e+00,  3.6342e+00],\n",
       "          [ 1.5800e+00,  4.0926e+00,  2.9676e+00,  1.6505e+00,  1.8379e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 9.1862e-01,  1.2088e+00,  1.3299e+00,  1.5763e+00,  1.2211e+00],\n",
       "          [ 8.2593e-01,  1.2864e+00,  1.5159e+00,  1.4231e+00,  8.8488e-01],\n",
       "          [ 1.7833e+00,  1.1808e+00,  1.3235e+00,  1.7132e+00,  1.1431e+00],\n",
       "          [ 1.9117e+00,  1.5771e+00,  1.8681e+00,  1.8583e+00,  1.3683e+00],\n",
       "          [ 1.1956e+00,  1.5897e+00,  1.6885e+00,  1.3246e+00,  7.9386e-01]],\n",
       "\n",
       "         [[-4.8475e-01, -5.0039e-01, -1.3122e+00, -7.9509e-01, -3.1719e-01],\n",
       "          [-1.0645e+00, -8.8294e-01, -7.9688e-01, -4.7372e-01, -5.2476e-01],\n",
       "          [-4.4806e-01, -7.2307e-01, -3.3555e-01, -2.5333e-01, -2.9889e-01],\n",
       "          [-4.9572e-01, -9.0359e-01, -3.8748e-01,  2.3164e-02,  7.9952e-02],\n",
       "          [-1.8815e-01, -3.7352e-01, -3.1716e-01,  8.0989e-02, -1.1927e-01]],\n",
       "\n",
       "         [[ 9.6621e-02, -1.7231e-01, -3.0373e-01, -3.1420e-02,  6.9171e-01],\n",
       "          [ 3.5521e-01, -4.6171e-01,  1.3834e-01,  4.2714e-01,  7.0673e-01],\n",
       "          [ 6.4931e-01, -1.3701e+00, -2.6734e-01,  9.2785e-01,  1.4677e+00],\n",
       "          [-1.5088e-01, -1.8840e-01, -3.0646e-01,  5.9409e-01,  9.0077e-01],\n",
       "          [ 5.4196e-01,  8.8806e-01,  3.6783e-01,  7.5546e-02,  1.1141e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.7493e+00,  2.4169e+00,  2.8563e+00,  2.6829e+00,  2.5142e+00],\n",
       "          [ 2.2536e+00,  2.7442e+00,  2.6075e+00,  2.1758e+00,  1.9875e+00],\n",
       "          [ 2.6938e+00,  3.6703e+00,  3.7895e+00,  3.1904e+00,  2.6191e+00],\n",
       "          [ 2.0872e+00,  2.8901e+00,  3.9460e+00,  2.9240e+00,  2.5207e+00],\n",
       "          [ 1.9566e+00,  2.8296e+00,  2.6300e+00,  2.8094e+00,  1.8041e+00]],\n",
       "\n",
       "         [[ 1.2151e-01,  8.2870e-01,  1.4904e+00,  1.0551e+00,  1.1355e+00],\n",
       "          [ 4.4744e-01,  3.3892e-01,  1.4489e+00,  1.2289e+00,  1.1272e+00],\n",
       "          [ 7.9188e-01,  1.4722e+00,  1.3010e+00,  2.0025e+00,  1.3980e+00],\n",
       "          [ 4.3105e-01,  1.1059e+00,  1.3441e+00,  8.9598e-01,  1.1500e+00],\n",
       "          [ 2.7349e-01,  4.5415e-01,  7.6388e-01,  5.4727e-01,  2.8002e-01]],\n",
       "\n",
       "         [[ 8.6784e-01,  4.5139e-01,  3.2347e-01, -2.9647e-01, -6.1446e-03],\n",
       "          [ 1.1272e+00,  4.3088e-01,  2.3106e-01, -1.5855e-01,  2.3840e-01],\n",
       "          [ 1.0154e+00,  8.0223e-01,  1.3336e+00,  4.7048e-01,  5.1858e-01],\n",
       "          [ 5.4714e-01,  7.3666e-01,  7.8706e-01,  6.5438e-02, -2.1121e-01],\n",
       "          [ 4.1409e-01,  7.7613e-02,  3.8901e-01,  1.5623e-01,  1.4416e-01]]]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(torch.randn(32, 3, 160, 160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_conv.conv.weight\n",
      "first_conv.bn.weight\n",
      "first_conv.bn.bias\n",
      "blocks.0.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.0.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.0.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.0.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.0.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.0.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.1.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.1.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.1.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.1.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.1.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.1.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.1.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.2.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.2.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.2.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.2.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.2.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.2.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.2.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.3.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.3.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.3.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.3.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.3.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.3.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.3.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.4.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.4.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.4.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.4.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.4.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.4.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.4.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.5.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.5.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.5.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.5.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.5.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.5.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.5.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.6.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.6.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.6.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.6.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.6.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.6.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.6.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.7.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.7.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.7.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.7.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.7.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.7.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.7.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.8.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.8.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.8.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.8.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.8.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.8.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.8.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.9.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.9.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.9.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.9.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.9.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.9.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.9.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.10.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.10.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.10.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.10.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.10.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.10.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.10.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.11.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.11.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.11.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.11.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.11.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.11.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.11.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.12.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.12.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.12.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.12.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.12.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.12.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.12.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.13.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.13.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.13.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.13.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.13.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.13.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.13.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.14.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.14.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.14.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.14.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.14.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.14.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.14.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.15.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.15.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.15.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.15.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.15.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.15.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.15.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.16.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.16.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.16.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.16.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.16.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.16.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.16.mobile_inverted_conv.point_linear.bn.bias\n",
      "classifier.linear.weight\n",
      "classifier.linear.bias\n"
     ]
    }
   ],
   "source": [
    "for n, p in net.named_parameters():\n",
    "    if has_deep_attr(model, n):\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbconv_test = MBGumbelInvertedConvLayer.build_from_config(m.mobile_inverted_conv.config)\n",
    "mbconv_test.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(2, 16, 32, 32)\n",
    "gumbel_inputs = torch.randn(2, 4, 8, 8)\n",
    "gumbel_inputs.requires_grad = True\n",
    "gumbel_layer = nn.Linear(4*8*8, 5)\n",
    "gumbel_output = gumbel_layer(gumbel_inputs.view(2, -1))\n",
    "gumbel_index = F.gumbel_softmax(gumbel_output, tau=1, hard=True)\n",
    "print(gumbel_index)\n",
    "out = mbconv_test.forward(torch.randn(2, 16, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(2, 16, 32, 32)\n",
    "gumbel_inputs = torch.randn(2, 4, 8, 8)\n",
    "gumbel_inputs.requires_grad = True\n",
    "gumbel_layer = nn.Linear(4*8*8, 5)\n",
    "gumbel_output = gumbel_layer(gumbel_inputs.view(2, -1))\n",
    "gumbel_index = F.gumbel_softmax(gumbel_output, tau=1, hard=True)\n",
    "print(gumbel_index)\n",
    "out = mbconv_test.forward(torch.randn(2, 16, 32, 32), gumbel_index)\n",
    "out.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel_layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbconv_test(torch.randn(1, 32, 32, 32), gumbel=[1, 0, 0, 1, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_mbconv_test_weight = copy.deepcopy(mbconv_test.depth_conv.conv.weight)\n",
    "print(original_mbconv_test_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m.mobile_inverted_conv.depth_conv.conv.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in m.mobile_inverted_conv.named_parameters():\n",
    "    if has_deep_attr(mbconv_test, n):\n",
    "        print(n, p)\n",
    "        set_deep_attr(mbconv_test, n, p)\n",
    "        print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in m.mobile_inverted_conv.named_parameters():\n",
    "    if has_deep_attr(mbconv_test, n):\n",
    "        print(n)\n",
    "        print(get_deep_attr(mbconv_test, n) - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbconv_test.forward(torch.randn(1,32,16,16), gumbel=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_layer = nn.BatchNorm2d(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 12, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 12\n",
    "out = F.batch_norm(x, bn_layer.running_mean[:feature_dim], bn_layer.running_var[:feature_dim], bn_layer.weight[:feature_dim], bn_layer.bias[:feature_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, img_size, desc = build_model(net_id='mcunet-in4', pretrained=True)\n",
    "\n",
    "backup_model = copy.deepcopy(model)\n",
    "model_copy = build_model(net_id='mcunet-in4', pretrained=False)[0]\n",
    "\n",
    "for (n1, p1), (n2, p2) in zip(backup_model.named_parameters(), model_copy.named_parameters()):\n",
    "    if n1 == n2:\n",
    "        print((p1 - p2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    if has_deep_attr(model_copy, n):\n",
    "        print(n)\n",
    "        set_deep_attr(model_copy, n, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (n1, p1), (n2, p2) in zip(backup_model.named_parameters(), model_copy.named_parameters()):\n",
    "    if n1 == n2:\n",
    "        print((p1-p2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
