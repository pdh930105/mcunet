{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import mcunet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from mcunet.tinynas.nn.modules import MBInvertedConvLayer\n",
    "from mcunet.tinynas.nn.networks import MobileInvertedResidualBlock\n",
    "from mcunet.model_zoo import build_model\n",
    "\n",
    "from mcunet.utils import MyModule, MyNetwork, SEModule, build_activation, get_same_padding, sub_filter_start_end\n",
    "from mcunet.tinynas.nn.modules import ZeroLayer, set_layer_from_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deep_attr(obj, attrs):\n",
    "    for attr in attrs.split(\".\"):\n",
    "        obj = getattr(obj, attr)\n",
    "    return obj\n",
    "\n",
    "def has_deep_attr(obj, attrs):\n",
    "    try:\n",
    "        get_deep_attr(obj, attrs)\n",
    "        return True\n",
    "    except AttributeError:\n",
    "        return False\n",
    "\n",
    "def set_deep_attr(obj, attrs, value):\n",
    "    for attr in attrs.split(\".\")[:-1]:\n",
    "        obj = getattr(obj, attr)\n",
    "    setattr(obj, attrs.split(\".\")[-1], value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, img_size, desc = build_model(net_id='mcunet-in4', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.0\n",
      "MobileInvertedResidualBlock(\n",
      "  (mobile_inverted_conv): MBInvertedConvLayer(\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "blocks.1\n",
      "MobileInvertedResidualBlock(\n",
      "  (mobile_inverted_conv): MBInvertedConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(48, 48, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=48, bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for n, m in model.named_modules():\n",
    "    if isinstance(m, MobileInvertedResidualBlock):\n",
    "        print(n)\n",
    "        print(m)\n",
    "        count += 2\n",
    "        if count > 3: \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'MobileInvertedResidualBlock',\n",
       " 'mobile_inverted_conv': {'name': 'MBInvertedConvLayer',\n",
       "  'in_channels': 16,\n",
       "  'out_channels': 24,\n",
       "  'kernel_size': 7,\n",
       "  'stride': 2,\n",
       "  'expand_ratio': 3,\n",
       "  'mid_channels': 48,\n",
       "  'act_func': 'relu6',\n",
       "  'use_se': False},\n",
       " 'shortcut': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBGumbelInvertedConvLayer(MyModule):\n",
    "    global_kernel_size_list = [3,5,7]\n",
    "    global_expand_ratio_list = [1,3,4,5,6]\n",
    "    def __init__(self, in_channels, out_channels,\n",
    "                 kernel_size=3, stride=1, expand_ratio=6, mid_channels=None, act_func='relu6', use_se=False, **kwargs):\n",
    "        super(MBGumbelInvertedConvLayer, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.max_kernel_size = kernel_size\n",
    "        self.kernel_size_list = []\n",
    "        self.stride = stride\n",
    "        self.max_expand_ratio = expand_ratio\n",
    "        self.expand_ratio_list = []\n",
    "        self.mid_channels = mid_channels\n",
    "        self.act_func = act_func\n",
    "        self.use_se = use_se\n",
    "        \n",
    "        \n",
    "        if self.max_kernel_size in self.global_kernel_size_list:\n",
    "            for kernel in sorted(self.global_kernel_size_list):\n",
    "                if kernel == self.max_kernel_size:\n",
    "                    self.kernel_size_list.append(kernel)\n",
    "                    break\n",
    "                self.kernel_size_list.append(kernel)\n",
    "            \n",
    "            self.kernel_size_list.reverse() # sorted in descending order\n",
    "        \n",
    "        else:\n",
    "            self.kernel_size_list = [self.max_kernel_size]\n",
    "        \n",
    "        if self.max_expand_ratio in self.global_expand_ratio_list:        \n",
    "            for expand in sorted(self.global_expand_ratio_list):\n",
    "                if expand == self.max_expand_ratio:\n",
    "                    self.expand_ratio_list.append(expand)\n",
    "                    break\n",
    "                self.expand_ratio_list.append(expand)\n",
    "        \n",
    "        else:\n",
    "            self.expand_ratio_list = [self.max_expand_ratio]\n",
    "        \n",
    "\n",
    "        if self.mid_channels is None:\n",
    "            feature_dim = round(self.in_channels * self.max_expand_ratio)\n",
    "        else:\n",
    "            feature_dim = self.mid_channels\n",
    "\n",
    "        if self.max_expand_ratio == 1:\n",
    "            self.inverted_bottleneck = None\n",
    "        else:\n",
    "            self.inverted_bottleneck = nn.Sequential(OrderedDict([\n",
    "                ('conv', nn.Conv2d(self.in_channels, feature_dim, 1, 1, 0, bias=False)),\n",
    "                ('bn', nn.BatchNorm2d(feature_dim)),\n",
    "                ('act', build_activation(self.act_func, inplace=True)),\n",
    "            ]))\n",
    "\n",
    "        pad = get_same_padding(self.max_kernel_size)\n",
    "        depth_conv_modules = [\n",
    "            ('conv', nn.Conv2d(feature_dim, feature_dim, kernel_size, stride, pad, groups=feature_dim, bias=False)),\n",
    "            ('bn', nn.BatchNorm2d(feature_dim)),\n",
    "            ('act', build_activation(self.act_func, inplace=True))\n",
    "        ]\n",
    "        if self.use_se:\n",
    "            depth_conv_modules.append(('se', SEModule(feature_dim)))\n",
    "        self.depth_conv = nn.Sequential(OrderedDict(depth_conv_modules))\n",
    "\n",
    "        self.point_linear = nn.Sequential(OrderedDict([\n",
    "            ('conv', nn.Conv2d(feature_dim, out_channels, 1, 1, 0, bias=False)),\n",
    "            ('bn', nn.BatchNorm2d(out_channels)),\n",
    "        ]))\n",
    "\n",
    "        self.kernel_transform_linear_list = nn.ModuleList()\n",
    "        \n",
    "        for i, kernel in enumerate(self.kernel_size_list[1:]):\n",
    "            kernel_linear = nn.Linear(kernel*kernel, kernel*kernel)\n",
    "            self.kernel_transform_linear_list.append(kernel_linear)\n",
    "\n",
    "    def forward(self, x, gumbel=None):\n",
    "        \"\"\"\n",
    "        gumbel: [batch_size, len(self.expand_ratio_list) + len(self.kernel_size_list)]\n",
    "        \"\"\"\n",
    "        self.input_width, self.input_height = x.size(2), x.size(3)\n",
    "        \n",
    "        if gumbel==None:\n",
    "            if self.inverted_bottleneck:\n",
    "                x = self.inverted_bottleneck(x)\n",
    "            x = self.depth_conv(x)\n",
    "            x = self.point_linear(x)\n",
    "            return x\n",
    "        else:\n",
    "            if len(self.expand_ratio_list) == 1: ## \n",
    "                if len(self.kernel_size_list) == 1:\n",
    "                    if self.inverted_bottleneck:\n",
    "                        x = self.inverted_bottleneck(x)\n",
    "                    x = self.depth_conv(x)\n",
    "                    x = self.point_linear(x)\n",
    "                    return x\n",
    "                else:\n",
    "                    # expand_ratio only one, multiple kernel size, so gumbel length is multple of kernel size\n",
    "                    assert len(gumbel[0]) == len(self.kernel_size_list), \"gumbel size is not match with kernel_size_list\"\n",
    "                    if self.inverted_bottleneck:\n",
    "                        x = self.inverted_bottleneck(x)\n",
    "                    depth_weight = self.depth_conv.conv.weight\n",
    "                    pad = get_same_padding(self.max_kernel_size)\n",
    "                    kernel_max_out = F.conv2d(x, depth_weight, stride=self.stride, padding=pad, groups=x.size(1))\n",
    "                    kernel_max_out = self.depth_conv.bn(kernel_max_out)\n",
    "                    kernel_max_out = self.depth_conv.act(kernel_max_out)\n",
    "                    kernel_max_out *= gumbel[:, 0].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                    for i, active_kernel_size in enumerate(self.kernel_size_list[1:]):\n",
    "                        start, end = sub_filter_start_end(self.kernel_size_list[i], active_kernel_size)\n",
    "                        kernel_weight = depth_weight[:, :, start:end, start:end].contiguous()\n",
    "                        kernel_weight = kernel_weight.view(kernel_weight.size(0), kernel_weight.size(1), -1)\n",
    "                        kernel_weight = self.kernel_transform_linear_list[i](kernel_weight)\n",
    "                        kernel_weight = kernel_weight.view(kernel_weight.size(0), kernel_weight.size(1), active_kernel_size, active_kernel_size)\n",
    "                        pad = get_same_padding(active_kernel_size)\n",
    "                        kernel_out = F.conv2d(x, kernel_weight, stride=self.stride, padding=pad, groups=x.size(1))\n",
    "                        kernel_out = self.depth_conv.bn(kernel_out)\n",
    "                        kernel_out = self.depth_conv.act(kernel_out)\n",
    "                        kernel_out *= gumbel[:, i].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                        kernel_max_out += kernel_out\n",
    "                    x = kernel_max_out\n",
    "                    if self.use_se:\n",
    "                        x = self.depth_conv.se(x)\n",
    "                    # 3. pointwise convolution weights (out_channels)\n",
    "                    x = self.point_linear(x)\n",
    "                    return x\n",
    "            \n",
    "            elif len(self.kernel_size_list) == 1:\n",
    "                # kernel size only one, multiple expand ratio, so gumbel length is multple of expand ratio\n",
    "                assert len(gumbel[0]) == len(self.expand_ratio_list), \"gumbel size is not match with expand_ratio_list\"\n",
    "                \n",
    "                if self.inverted_bottleneck:\n",
    "                    # 1. inverted bottleneck weights (max_expand_ratio)\n",
    "                    expand_weight = self.inverted_bottleneck.conv.weight\n",
    "                    expand_max_out = F.conv2d(x, expand_weight, stride=1, padding=0)\n",
    "                    expand_max_out = self.inverted_bottleneck.bn(expand_max_out)\n",
    "                    expand_max_out = self.inverted_bottleneck.act(expand_max_out)\n",
    "                    expand_max_out *= gumbel[:, -1].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                    for i, expand_ratio in enumerate(self.expand_ratio_list[:-1]):\n",
    "                        out = F.conv2d(x, expand_weight[:expand_ratio*self.in_channels, :, :, :], stride=1, padding=0)\n",
    "                        out = F.batch_norm(out, self.inverted_bottleneck.bn.running_mean[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.running_var[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.weight[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.bias[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.training, self.inverted_bottleneck.bn.momentum, self.inverted_bottleneck.bn.eps)\n",
    "                        out = self.inverted_bottleneck.act(out)\n",
    "                        out *= gumbel[:, i].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                        out = F.pad(out, [0, 0, 0, 0, 0, expand_max_out.size(1) - out.size(1)], mode='constant', value=0) # zero pad\n",
    "                        expand_max_out += out\n",
    "                    x = expand_max_out\n",
    "                x = self.depth_conv(x)\n",
    "                x = self.point_linear(x)\n",
    "                return x\n",
    "                \n",
    "            elif len(gumbel[0]) == len(self.expand_ratio_list) + len(self.kernel_size_list):\n",
    "                if self.inverted_bottleneck:\n",
    "                    # 1. inverted bottleneck weights (max_expand_ratio)\n",
    "                    expand_weight = self.inverted_bottleneck.conv.weight\n",
    "                    expand_max_out = F.conv2d(x, expand_weight, stride=1, padding=0)\n",
    "                    expand_max_out = self.inverted_bottleneck.bn(expand_max_out)\n",
    "                    expand_max_out = self.inverted_bottleneck.act(expand_max_out)\n",
    "                    expand_max_out *= gumbel[:, len(self.expand_ratio_list)-1].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                    for i, expand_ratio in enumerate(self.expand_ratio_list[:-1]):\n",
    "                        out = F.conv2d(x, expand_weight[:expand_ratio*self.in_channels, :, :, :], stride=1, padding=0)\n",
    "                        out = F.batch_norm(out, self.inverted_bottleneck.bn.running_mean[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.running_var[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.weight[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.bias[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.training, self.inverted_bottleneck.bn.momentum, self.inverted_bottleneck.bn.eps)\n",
    "                        out = self.inverted_bottleneck.act(out)\n",
    "                        out *= gumbel[:, i].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                        out = F.pad(out, [0, 0, 0, 0, 0, expand_max_out.size(1) - out.size(1)], mode='constant', value=0) # zero pad\n",
    "                        expand_max_out += out\n",
    "                    x = expand_max_out\n",
    "                # 2. depthwise convolution weights (max_kernel_size)\n",
    "                depth_weight = self.depth_conv.conv.weight\n",
    "                pad = get_same_padding(self.max_kernel_size)\n",
    "                kernel_max_out = F.conv2d(x, depth_weight, stride=self.stride, padding=pad, groups=x.size(1))\n",
    "                kernel_max_out = self.depth_conv.bn(kernel_max_out)\n",
    "                kernel_max_out = self.depth_conv.act(kernel_max_out)\n",
    "                kernel_max_out *= gumbel[:, len(self.expand_ratio_list)].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                for i, active_kernel_size in enumerate(self.kernel_size_list[1:]):\n",
    "                    start, end = sub_filter_start_end(self.kernel_size_list[i], active_kernel_size)\n",
    "                    kernel_weight = depth_weight[:, :, start:end, start:end].contiguous()\n",
    "                    kernel_weight = kernel_weight.view(kernel_weight.size(0), kernel_weight.size(1), -1)\n",
    "                    kernel_weight = self.kernel_transform_linear_list[i](kernel_weight)\n",
    "                    kernel_weight = kernel_weight.view(kernel_weight.size(0), kernel_weight.size(1), active_kernel_size, active_kernel_size)\n",
    "                    pad = get_same_padding(active_kernel_size)\n",
    "                    kernel_out = F.conv2d(x, kernel_weight, stride=self.stride, padding=pad, groups=x.size(1))\n",
    "                    kernel_out = self.depth_conv.bn(kernel_out)\n",
    "                    kernel_out = self.depth_conv.act(kernel_out)\n",
    "                    kernel_out *= gumbel[:, len(self.expand_ratio_list) + i+1].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                    kernel_max_out += kernel_out\n",
    "                x = kernel_max_out\n",
    "                if self.use_se:\n",
    "                    x = self.depth_conv.se(x)\n",
    "                # 3. pointwise convolution weights (out_channels)\n",
    "                x = self.point_linear(x)\n",
    "                return x\n",
    "            else:\n",
    "                assert False, \"gumbel size is not match with expand_ratio_list and kernel_size_list\"\n",
    "    \n",
    "    def count_flops(self, gumbel_idx=None):\n",
    "        assert hasattr(self, 'input_width'), \"please run forward at least once\"\n",
    "        if gumbel_idx == None:\n",
    "            if self.inverted_bottleneck:\n",
    "                out_h, in_h, k_w, k_h  = self.inverted_bottleneck.conv.weight.shape\n",
    "                \n",
    "            \n",
    "            else:\n",
    "                flops = 0\n",
    "            flops += self.depth_conv.count_flops(self.input_width, self.input_height)\n",
    "            flops += self.point_linear.count_flops(self.input_width, self.input_height)\n",
    "            return flops\n",
    "            \n",
    "            \n",
    "    \n",
    "    @property\n",
    "    def module_str(self):\n",
    "        if self.mid_channels is None:\n",
    "            expand_ratio = self.max_expand_ratio\n",
    "        else:\n",
    "            expand_ratio = self.mid_channels // self.in_channels\n",
    "        layer_str = '%dx%d_GumbelMBConv%d_%s' % (self.max_kernel_size, self.max_kernel_size, expand_ratio, self.act_func.upper())\n",
    "        if self.use_se:\n",
    "            layer_str = 'SE_' + layer_str\n",
    "        layer_str += '_O%d' % self.out_channels\n",
    "        return layer_str\n",
    "\n",
    "    @property\n",
    "    def config(self):\n",
    "        return {\n",
    "            'name': MBGumbelInvertedConvLayer.__name__,\n",
    "            'in_channels': self.in_channels,\n",
    "            'out_channels': self.out_channels,\n",
    "            'kernel_size': self.max_kernel_size,\n",
    "            'kernel_size_list': self.kernel_size_list,\n",
    "            'stride': self.stride,\n",
    "            'expand_ratio': self.max_expand_ratio,\n",
    "            'expand_ratio_list': self.expand_ratio_list,\n",
    "            'mid_channels': self.mid_channels,\n",
    "            'act_func': self.act_func,\n",
    "            'use_se': self.use_se,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def build_from_config(config):\n",
    "        return MBGumbelInvertedConvLayer(**config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MobileGumbelInvertedResidualBlock(MyModule):\n",
    "\n",
    "    def __init__(self, mobile_inverted_conv, shortcut):\n",
    "        super(MobileGumbelInvertedResidualBlock, self).__init__()\n",
    "\n",
    "        self.mobile_inverted_conv = mobile_inverted_conv\n",
    "        self.shortcut = shortcut\n",
    "\n",
    "    def forward(self, x, gumbel_idx=None):\n",
    "        if self.mobile_inverted_conv is None or isinstance(self.mobile_inverted_conv, ZeroLayer):\n",
    "            res = x\n",
    "        elif self.shortcut is None or isinstance(self.shortcut, ZeroLayer) and gumbel_idx == None:\n",
    "            res = self.mobile_inverted_conv(x)\n",
    "        elif self.shortcut is None or isinstance(self.shortcut, ZeroLayer) and gumbel_idx != None:\n",
    "            res = self.mobile_inverted_conv(x, gumbel_idx)\n",
    "        elif self.shortcut is not None and gumbel_idx == None:\n",
    "            res = self.mobile_inverted_conv(x) + self.shortcut(x)\n",
    "        else:\n",
    "            res = self.mobile_inverted_conv(x, gumbel_idx) + self.shortcut(x)\n",
    "        return res\n",
    "\n",
    "    @property\n",
    "    def module_str(self):\n",
    "        return '(%s, %s)' % (\n",
    "            self.mobile_inverted_conv.module_str if self.mobile_inverted_conv is not None else None,\n",
    "            self.shortcut.module_str if self.shortcut is not None else None\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def config(self):\n",
    "        return {\n",
    "            'name': MobileGumbelInvertedResidualBlock.__name__,\n",
    "            'mobile_inverted_conv': self.mobile_inverted_conv.config if self.mobile_inverted_conv is not None else None,\n",
    "            'shortcut': self.shortcut.config if self.shortcut is not None else None,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def build_from_config(config):\n",
    "        mobile_inverted_conv = MBGumbelInvertedConvLayer.build_from_config(config['mobile_inverted_conv'])\n",
    "        shortcut = set_layer_from_config(config['shortcut'])\n",
    "        return MobileGumbelInvertedResidualBlock(mobile_inverted_conv, shortcut)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_from_module(module):\n",
    "        if isinstance(module, MobileGumbelInvertedResidualBlock):\n",
    "            print(\"build from gumbel module\")\n",
    "            return module\n",
    "        elif isinstance(module, MobileInvertedResidualBlock):\n",
    "            print(\"build from normal MobileInvertedResidualBlock module\")\n",
    "            mobile_inverted_conv = module.mobile_inverted_conv\n",
    "            shortcut = module.shortcut\n",
    "            return MobileGumbelInvertedResidualBlock(module.mobile_inverted_conv, module.shortcut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GumbelMCUNets(MyNetwork):\n",
    "    def __init__(self, first_conv, blocks, feature_mix_layer, classifier, gumbel_feature_extract_block):\n",
    "        super(GumbelMCUNets, self).__init__()\n",
    "        \n",
    "        self.first_conv = first_conv\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "        self.feature_mix_layer = feature_mix_layer\n",
    "        self.classifier = classifier\n",
    "        self.gumbel_feature_extract_block = gumbel_feature_extract_block\n",
    "        \n",
    "        self.gumbel_index_list = []\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            if i < self.gumbel_feature_extract_block:\n",
    "                continue\n",
    "            if len(block.mobile_inverted_conv.expand_ratio_list) > 1:\n",
    "                self.gumbel_index_list.append(len(block.mobile_inverted_conv.expand_ratio_list))\n",
    "                \n",
    "            if len(block.mobile_inverted_conv.kernel_size_list) > 1:\n",
    "                self.gumbel_index_list.append(len(block.mobile_inverted_conv.kernel_size_list))\n",
    "        \n",
    "        \n",
    "        self.gumbel_input_channel = blocks[gumbel_feature_extract_block].mobile_inverted_conv.out_channels\n",
    "        \n",
    "        self.avgpool_policy = nn.AdaptiveAvgPool2d((8, 8))\n",
    "        self.gumbel_features_flatten = nn.Flatten()\n",
    "        self.gumbel_fc1 = nn.Linear(self.gumbel_input_channel*8*8, 256)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.gumbel_fc2 = nn.Linear(256, sum(self.gumbel_index_list))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.first_conv(x)\n",
    "        for i, block in enumerate(self.blocks):            \n",
    "            if i == self.gumbel_feature_extract_block:\n",
    "                # feautre map and gumbel output extract\n",
    "                gumbel_input = self.avgpool_policy(x)\n",
    "                gumbel_input = self.gumbel_features_flatten(gumbel_input)\n",
    "                gumbel_input = self.gumbel_fc1(gumbel_input)\n",
    "                gumbel_input = self.dropout(gumbel_input)\n",
    "                gumbel_output = self.gumbel_fc2(gumbel_input)\n",
    "                gumbel_output = gumbel_output.view(-1, sum(self.gumbel_index_list))\n",
    "                break\n",
    "            x = block(x)\n",
    "\n",
    "        gumbel_index = 0\n",
    "        for j, block in enumerate(self.blocks[self.gumbel_feature_extract_block:]):\n",
    "            expand_index, kernel_index = len(block.mobile_inverted_conv.expand_ratio_list), len(block.mobile_inverted_conv.kernel_size_list)\n",
    "            print(f'{j} idx {gumbel_index} expand {expand_index} kernel {kernel_index}')\n",
    "            if expand_index > 1 and kernel_index > 1:\n",
    "                gumbel_input = gumbel_output[:, gumbel_index: gumbel_index + expand_index  + kernel_index]\n",
    "                gumbel_one_hot = F.gumbel_softmax(gumbel_input, tau=1, hard=True)\n",
    "                gumbel_index += expand_index + kernel_index\n",
    "                \n",
    "            elif expand_index > 1:\n",
    "                gumbel_input = gumbel_output[:, gumbel_index: gumbel_index + expand_index]\n",
    "                gumbel_one_hot = F.gumbel_softmax(gumbel_input, tau=1, hard=True)\n",
    "                gumbel_index += expand_index\n",
    "            elif kernel_index >1:\n",
    "                gumbel_input = gumbel_output[:, gumbel_index: gumbel_index + kernel_index]\n",
    "                gumbel_one_hot = F.gumbel_softmax(gumbel_input, tau=1, hard=True)\n",
    "                gumbel_index += kernel_index\n",
    "            else:\n",
    "                gumbel_one_hot = None\n",
    "            x = block(x, gumbel_one_hot)    \n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def module_str(self):\n",
    "        _str = self.first_conv.module_str + '\\n'\n",
    "        for block in self.blocks:\n",
    "            _str += block.module_str + '\\n'\n",
    "        _str += self.feature_mix_layer.module_str + '\\n'\n",
    "        _str += self.classifier.module_str\n",
    "        return _str\n",
    "        \n",
    "    @property\n",
    "    def config(self):\n",
    "        return {\n",
    "            'name': GumbelMCUNets.__name__,\n",
    "            'bn': self.get_bn_param(),\n",
    "            'first_conv': self.first_conv.config,\n",
    "            'blocks': [\n",
    "                block.config for block in self.blocks\n",
    "            ],\n",
    "            'feature_mix_layer': None if self.feature_mix_layer is None else self.feature_mix_layer.config,\n",
    "            'classifier': self.classifier.config,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def build_from_config(net_config, gumbel_config):\n",
    "        MBGumbelInvertedConvLayer.global_expand_ratio_list = gumbel_config['global_expand_ratio_list']\n",
    "        MBGumbelInvertedConvLayer.global_kernel_size_list = gumbel_config['global_kernel_size_list']\n",
    "        gumbel_feature_extract_block = gumbel_config['gumbel_feature_extract_block']\n",
    "        \n",
    "        first_conv = set_layer_from_config(net_config['first_conv'])\n",
    "        feature_mix_layer = set_layer_from_config(net_config['feature_mix_layer'])\n",
    "        classifier = set_layer_from_config(net_config['classifier'])\n",
    "        \n",
    "        blocks = []\n",
    "        \n",
    "        for i, block_config in enumerate(net_config['blocks']):\n",
    "            if i < gumbel_feature_extract_block:\n",
    "                print(i, block_config)\n",
    "                blocks.append(MobileInvertedResidualBlock.build_from_config(block_config))\n",
    "            else:\n",
    "                blocks.append(MobileGumbelInvertedResidualBlock.build_from_config(block_config))\n",
    "        \n",
    "        net = GumbelMCUNets(first_conv, blocks, feature_mix_layer, classifier, gumbel_feature_extract_block)\n",
    "        \n",
    "        if 'bn' in net_config:\n",
    "            net.set_bn_param(**net_config['bn'])\n",
    "        else:\n",
    "            net.set_bn_param(momentum=0.1, eps=1e-3)\n",
    "        \n",
    "        return net\n",
    "    \n",
    "    def load_pretrained_mcunet_param(self, mcunet):\n",
    "        \n",
    "        for n, p in self.named_parameters():\n",
    "            if has_deep_attr(mcunet, n):\n",
    "                print(\"load {} params ({})\".format(n, p.shape))\n",
    "                set_deep_attr(self, n, get_deep_attr(mcunet, n))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'name': 'MobileInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBInvertedConvLayer', 'in_channels': 32, 'out_channels': 16, 'kernel_size': 3, 'stride': 1, 'expand_ratio': 1, 'mid_channels': None, 'act_func': 'relu6', 'use_se': False}, 'shortcut': None}\n",
      "1 {'name': 'MobileInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBInvertedConvLayer', 'in_channels': 16, 'out_channels': 24, 'kernel_size': 7, 'stride': 2, 'expand_ratio': 3, 'mid_channels': 48, 'act_func': 'relu6', 'use_se': False}, 'shortcut': None}\n",
      "load first_conv.conv.weight params (torch.Size([32, 3, 3, 3]))\n",
      "load first_conv.bn.weight params (torch.Size([32]))\n",
      "load first_conv.bn.bias params (torch.Size([32]))\n",
      "load blocks.0.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([32, 1, 3, 3]))\n",
      "load blocks.0.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([32]))\n",
      "load blocks.0.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([32]))\n",
      "load blocks.0.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([16, 32, 1, 1]))\n",
      "load blocks.0.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([16]))\n",
      "load blocks.0.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([16]))\n",
      "load blocks.1.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([48, 16, 1, 1]))\n",
      "load blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([48]))\n",
      "load blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([48]))\n",
      "load blocks.1.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([48, 1, 7, 7]))\n",
      "load blocks.1.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([48]))\n",
      "load blocks.1.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([48]))\n",
      "load blocks.1.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([24, 48, 1, 1]))\n",
      "load blocks.1.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([24]))\n",
      "load blocks.1.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([24]))\n",
      "load blocks.2.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([120, 24, 1, 1]))\n",
      "load blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([120]))\n",
      "load blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([120]))\n",
      "load blocks.2.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([120, 1, 3, 3]))\n",
      "load blocks.2.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([120]))\n",
      "load blocks.2.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([120]))\n",
      "load blocks.2.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([24, 120, 1, 1]))\n",
      "load blocks.2.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([24]))\n",
      "load blocks.2.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([24]))\n",
      "load blocks.3.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([96, 24, 1, 1]))\n",
      "load blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([96]))\n",
      "load blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([96]))\n",
      "load blocks.3.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([96, 1, 5, 5]))\n",
      "load blocks.3.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([96]))\n",
      "load blocks.3.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([96]))\n",
      "load blocks.3.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([24, 96, 1, 1]))\n",
      "load blocks.3.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([24]))\n",
      "load blocks.3.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([24]))\n",
      "load blocks.4.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([120, 24, 1, 1]))\n",
      "load blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([120]))\n",
      "load blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([120]))\n",
      "load blocks.4.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([120, 1, 7, 7]))\n",
      "load blocks.4.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([120]))\n",
      "load blocks.4.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([120]))\n",
      "load blocks.4.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([40, 120, 1, 1]))\n",
      "load blocks.4.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([40]))\n",
      "load blocks.4.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([40]))\n",
      "load blocks.5.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([160, 40, 1, 1]))\n",
      "load blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([160]))\n",
      "load blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([160]))\n",
      "load blocks.5.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([160, 1, 3, 3]))\n",
      "load blocks.5.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([160]))\n",
      "load blocks.5.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([160]))\n",
      "load blocks.5.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([40, 160, 1, 1]))\n",
      "load blocks.5.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([40]))\n",
      "load blocks.5.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([40]))\n",
      "load blocks.6.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([160, 40, 1, 1]))\n",
      "load blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([160]))\n",
      "load blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([160]))\n",
      "load blocks.6.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([160, 1, 7, 7]))\n",
      "load blocks.6.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([160]))\n",
      "load blocks.6.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([160]))\n",
      "load blocks.6.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([40, 160, 1, 1]))\n",
      "load blocks.6.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([40]))\n",
      "load blocks.6.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([40]))\n",
      "load blocks.7.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([120, 40, 1, 1]))\n",
      "load blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([120]))\n",
      "load blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([120]))\n",
      "load blocks.7.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([120, 1, 7, 7]))\n",
      "load blocks.7.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([120]))\n",
      "load blocks.7.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([120]))\n",
      "load blocks.7.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([80, 120, 1, 1]))\n",
      "load blocks.7.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([80]))\n",
      "load blocks.7.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([80]))\n",
      "load blocks.8.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([240, 80, 1, 1]))\n",
      "load blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([240]))\n",
      "load blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([240]))\n",
      "load blocks.8.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([240, 1, 3, 3]))\n",
      "load blocks.8.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([240]))\n",
      "load blocks.8.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([240]))\n",
      "load blocks.8.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([80, 240, 1, 1]))\n",
      "load blocks.8.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([80]))\n",
      "load blocks.8.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([80]))\n",
      "load blocks.9.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([240, 80, 1, 1]))\n",
      "load blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([240]))\n",
      "load blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([240]))\n",
      "load blocks.9.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([240, 1, 7, 7]))\n",
      "load blocks.9.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([240]))\n",
      "load blocks.9.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([240]))\n",
      "load blocks.9.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([80, 240, 1, 1]))\n",
      "load blocks.9.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([80]))\n",
      "load blocks.9.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([80]))\n",
      "load blocks.10.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([320, 80, 1, 1]))\n",
      "load blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([320]))\n",
      "load blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([320]))\n",
      "load blocks.10.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([320, 1, 3, 3]))\n",
      "load blocks.10.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([320]))\n",
      "load blocks.10.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([320]))\n",
      "load blocks.10.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([96, 320, 1, 1]))\n",
      "load blocks.10.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([96]))\n",
      "load blocks.10.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([96]))\n",
      "load blocks.11.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([288, 96, 1, 1]))\n",
      "load blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([288]))\n",
      "load blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([288]))\n",
      "load blocks.11.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([288, 1, 5, 5]))\n",
      "load blocks.11.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([288]))\n",
      "load blocks.11.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([288]))\n",
      "load blocks.11.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([96, 288, 1, 1]))\n",
      "load blocks.11.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([96]))\n",
      "load blocks.11.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([96]))\n",
      "load blocks.12.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([288, 96, 1, 1]))\n",
      "load blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([288]))\n",
      "load blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([288]))\n",
      "load blocks.12.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([288, 1, 5, 5]))\n",
      "load blocks.12.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([288]))\n",
      "load blocks.12.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([288]))\n",
      "load blocks.12.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([96, 288, 1, 1]))\n",
      "load blocks.12.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([96]))\n",
      "load blocks.12.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([96]))\n",
      "load blocks.13.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([384, 96, 1, 1]))\n",
      "load blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([384]))\n",
      "load blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([384]))\n",
      "load blocks.13.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([384, 1, 7, 7]))\n",
      "load blocks.13.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([384]))\n",
      "load blocks.13.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([384]))\n",
      "load blocks.13.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([192, 384, 1, 1]))\n",
      "load blocks.13.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([192]))\n",
      "load blocks.13.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([192]))\n",
      "load blocks.14.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([576, 192, 1, 1]))\n",
      "load blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([576]))\n",
      "load blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([576]))\n",
      "load blocks.14.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([576, 1, 7, 7]))\n",
      "load blocks.14.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([576]))\n",
      "load blocks.14.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([576]))\n",
      "load blocks.14.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([192, 576, 1, 1]))\n",
      "load blocks.14.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([192]))\n",
      "load blocks.14.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([192]))\n",
      "load blocks.15.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([576, 192, 1, 1]))\n",
      "load blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([576]))\n",
      "load blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([576]))\n",
      "load blocks.15.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([576, 1, 5, 5]))\n",
      "load blocks.15.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([576]))\n",
      "load blocks.15.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([576]))\n",
      "load blocks.15.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([192, 576, 1, 1]))\n",
      "load blocks.15.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([192]))\n",
      "load blocks.15.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([192]))\n",
      "load blocks.16.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([768, 192, 1, 1]))\n",
      "load blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([768]))\n",
      "load blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([768]))\n",
      "load blocks.16.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([768, 1, 5, 5]))\n",
      "load blocks.16.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([768]))\n",
      "load blocks.16.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([768]))\n",
      "load blocks.16.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([320, 768, 1, 1]))\n",
      "load blocks.16.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([320]))\n",
      "load blocks.16.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([320]))\n",
      "load classifier.linear.weight params (torch.Size([1000, 320]))\n",
      "load classifier.linear.bias params (torch.Size([1000]))\n"
     ]
    }
   ],
   "source": [
    "gubmel_config = {'global_expand_ratio_list':[1,3,5,6], 'global_kernel_size_list':[3,5,7], 'gumbel_feature_extract_block':2}\n",
    "net = GumbelMCUNets.build_from_config(model.config, gubmel_config)\n",
    "net.load_pretrained_mcunet_param(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.gumbel_fc1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before forward grad :  None\n",
      "0 idx 0 expand 3 kernel 1\n",
      "gumbel shape :  torch.Size([32, 3])\n",
      "1 idx 3 expand 1 kernel 2\n",
      "gumbel shape :  torch.Size([32, 2])\n",
      "1 4 3 5 torch.Size([96, 1, 5, 5])\n",
      "2 idx 5 expand 3 kernel 3\n",
      "3 idx 11 expand 1 kernel 1\n",
      "4 idx 11 expand 1 kernel 3\n",
      "gumbel shape :  torch.Size([32, 3])\n",
      "1 6 5 7 torch.Size([160, 1, 7, 7])\n",
      "1 4 3 5 torch.Size([160, 1, 7, 7])\n",
      "5 idx 14 expand 2 kernel 3\n",
      "6 idx 19 expand 2 kernel 1\n",
      "gumbel shape :  torch.Size([32, 2])\n",
      "7 idx 21 expand 2 kernel 3\n",
      "gumbel shape :  torch.Size([32, 5])\n",
      "1 6 5 7 torch.Size([240, 1, 7, 7])\n",
      "1 4 3 5 torch.Size([240, 1, 7, 7])\n",
      "8 idx 26 expand 1 kernel 1\n",
      "9 idx 26 expand 2 kernel 2\n",
      "gumbel shape :  torch.Size([32, 4])\n",
      "1 4 3 5 torch.Size([288, 1, 5, 5])\n",
      "10 idx 30 expand 2 kernel 2\n",
      "gumbel shape :  torch.Size([32, 4])\n",
      "1 4 3 5 torch.Size([288, 1, 5, 5])\n",
      "11 idx 34 expand 1 kernel 3\n",
      "12 idx 37 expand 2 kernel 3\n",
      "gumbel shape :  torch.Size([32, 5])\n",
      "1 6 5 7 torch.Size([576, 1, 7, 7])\n",
      "1 4 3 5 torch.Size([576, 1, 7, 7])\n",
      "13 idx 42 expand 2 kernel 2\n",
      "gumbel shape :  torch.Size([32, 4])\n",
      "1 4 3 5 torch.Size([576, 1, 5, 5])\n",
      "14 idx 46 expand 1 kernel 2\n",
      "after forward grad : \n",
      " tensor([[ 1.5579e-06, -3.6754e-07, -5.6299e-07,  ...,  2.2749e-06,\n",
      "         -1.1263e-06, -6.0949e-07],\n",
      "        [-5.6689e-06, -2.7243e-06,  7.6726e-06,  ..., -1.2923e-06,\n",
      "         -5.3162e-06, -5.8807e-06],\n",
      "        [ 4.3257e-07,  2.3587e-06, -5.6974e-06,  ..., -2.8985e-06,\n",
      "          6.0482e-07, -1.2306e-06],\n",
      "        ...,\n",
      "        [ 2.3472e-06, -2.7084e-07, -8.4750e-08,  ...,  2.2909e-07,\n",
      "         -2.2209e-06,  8.1460e-07],\n",
      "        [ 6.2847e-06,  3.0346e-06, -3.1045e-06,  ...,  1.5993e-06,\n",
      "          6.7801e-06,  7.1899e-06],\n",
      "        [-3.7265e-06,  2.1225e-08,  3.8718e-06,  ..., -3.8565e-06,\n",
      "          2.3975e-06, -2.5180e-07]])\n"
     ]
    }
   ],
   "source": [
    "print(\"before forward grad : \", net.gumbel_fc1.weight.grad)\n",
    "out = net(torch.randn(32, 3, 160, 160))\n",
    "\n",
    "out.sum().backward()\n",
    "\n",
    "print(\"after forward grad : \\n\", net.gumbel_fc1.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0600e-06, -1.1182e-06, -4.1251e-06,  ...,  7.1878e-06,\n",
       "          1.6874e-06,  2.5609e-06],\n",
       "        [ 6.7503e-06,  5.0171e-06, -5.8395e-06,  ...,  6.9475e-07,\n",
       "         -1.2265e-06,  8.7869e-06],\n",
       "        [-3.8922e-06, -2.3463e-06, -9.2838e-07,  ...,  4.8356e-06,\n",
       "         -4.1079e-06, -1.0903e-06],\n",
       "        ...,\n",
       "        [ 3.7491e-06,  4.1430e-06, -8.1688e-06,  ..., -1.1423e-05,\n",
       "         -5.2271e-06, -8.3704e-06],\n",
       "        [ 2.5260e-06,  1.3305e-06,  1.4562e-08,  ...,  9.1271e-06,\n",
       "         -3.0333e-06,  3.6833e-06],\n",
       "        [ 2.8772e-07, -1.1172e-06,  2.8125e-06,  ...,  7.8197e-07,\n",
       "          3.9362e-06, -2.5796e-07]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_conv.conv.weight\n",
      "first_conv.bn.weight\n",
      "first_conv.bn.bias\n",
      "blocks.0.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.0.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.0.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.0.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.0.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.0.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.1.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.1.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.1.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.1.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.1.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.1.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.1.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.2.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.2.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.2.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.2.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.2.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.2.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.2.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.3.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.3.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.3.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.3.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.3.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.3.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.3.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.4.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.4.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.4.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.4.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.4.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.4.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.4.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.5.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.5.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.5.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.5.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.5.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.5.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.5.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.6.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.6.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.6.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.6.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.6.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.6.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.6.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.7.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.7.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.7.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.7.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.7.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.7.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.7.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.8.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.8.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.8.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.8.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.8.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.8.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.8.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.9.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.9.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.9.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.9.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.9.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.9.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.9.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.10.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.10.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.10.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.10.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.10.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.10.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.10.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.11.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.11.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.11.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.11.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.11.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.11.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.11.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.12.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.12.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.12.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.12.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.12.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.12.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.12.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.13.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.13.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.13.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.13.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.13.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.13.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.13.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.14.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.14.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.14.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.14.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.14.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.14.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.14.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.15.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.15.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.15.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.15.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.15.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.15.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.15.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.16.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.16.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.16.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.16.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.16.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.16.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.16.mobile_inverted_conv.point_linear.bn.bias\n",
      "classifier.linear.weight\n",
      "classifier.linear.bias\n"
     ]
    }
   ],
   "source": [
    "for n, p in net.named_parameters():\n",
    "    if has_deep_attr(model, n):\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProxylessNASNets(\n",
       "  (first_conv): ConvLayer(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): ReLU6(inplace=True)\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(48, 48, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=48, bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(24, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
       "          (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(120, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (3): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (4): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(24, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(120, 120, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=120, bias=False)\n",
       "          (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (6): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160, bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (7): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(120, 120, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=120, bias=False)\n",
       "          (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(120, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (9): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(240, 240, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=240, bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (10): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(320, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "          (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (12): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "          (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (13): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=384, bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(576, 576, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=576, bias=False)\n",
       "          (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (15): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): IdentityLayer()\n",
       "    )\n",
       "    (16): MobileInvertedResidualBlock(\n",
       "      (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "        (inverted_bottleneck): Sequential(\n",
       "          (conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (depth_conv): Sequential(\n",
       "          (conv): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
       "          (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6(inplace=True)\n",
       "        )\n",
       "        (point_linear): Sequential(\n",
       "          (conv): Conv2d(768, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): LinearLayer(\n",
       "    (linear): Linear(in_features=320, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'MBGumbelInvertedConvLayer',\n",
       " 'in_channels': 16,\n",
       " 'out_channels': 24,\n",
       " 'kernel_size': 7,\n",
       " 'kernel_size_list': [7, 5, 3],\n",
       " 'stride': 2,\n",
       " 'expand_ratio': 3,\n",
       " 'expand_ratio_list': [1, 3],\n",
       " 'mid_channels': 48,\n",
       " 'act_func': 'relu6',\n",
       " 'use_se': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbconv_test = MBGumbelInvertedConvLayer.build_from_config(m.mobile_inverted_conv.config)\n",
    "mbconv_test.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(2, 16, 32, 32)\n",
    "gumbel_inputs = torch.randn(2, 4, 8, 8)\n",
    "gumbel_inputs.requires_grad = True\n",
    "gumbel_layer = nn.Linear(4*8*8, 5)\n",
    "gumbel_output = gumbel_layer(gumbel_inputs.view(2, -1))\n",
    "gumbel_index = F.gumbel_softmax(gumbel_output, tau=1, hard=True)\n",
    "print(gumbel_index)\n",
    "out = mbconv_test.forward(torch.randn(2, 16, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.]], grad_fn=<AddBackward0>)\n",
      "gumbel shape :  torch.Size([2, 5])\n",
      "1 6 5 7 torch.Size([48, 1, 7, 7])\n",
      "1 4 3 5 torch.Size([48, 1, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(2, 16, 32, 32)\n",
    "gumbel_inputs = torch.randn(2, 4, 8, 8)\n",
    "gumbel_inputs.requires_grad = True\n",
    "gumbel_layer = nn.Linear(4*8*8, 5)\n",
    "gumbel_output = gumbel_layer(gumbel_inputs.view(2, -1))\n",
    "gumbel_index = F.gumbel_softmax(gumbel_output, tau=1, hard=True)\n",
    "print(gumbel_index)\n",
    "out = mbconv_test.forward(torch.randn(2, 16, 32, 32), gumbel_index)\n",
    "out.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gumbel_layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_mbconv_test_weight = copy.deepcopy(mbconv_test.depth_conv.conv.weight)\n",
    "print(original_mbconv_test_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m.mobile_inverted_conv.depth_conv.conv.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in m.mobile_inverted_conv.named_parameters():\n",
    "    if has_deep_attr(mbconv_test, n):\n",
    "        print(n, p)\n",
    "        set_deep_attr(mbconv_test, n, p)\n",
    "        print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in m.mobile_inverted_conv.named_parameters():\n",
    "    if has_deep_attr(mbconv_test, n):\n",
    "        print(n)\n",
    "        print(get_deep_attr(mbconv_test, n) - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbconv_test.forward(torch.randn(1,32,16,16), gumbel=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_layer = nn.BatchNorm2d(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 12, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 12\n",
    "out = F.batch_norm(x, bn_layer.running_mean[:feature_dim], bn_layer.running_var[:feature_dim], bn_layer.weight[:feature_dim], bn_layer.bias[:feature_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, img_size, desc = build_model(net_id='mcunet-in4', pretrained=True)\n",
    "\n",
    "backup_model = copy.deepcopy(model)\n",
    "model_copy = build_model(net_id='mcunet-in4', pretrained=False)[0]\n",
    "\n",
    "for (n1, p1), (n2, p2) in zip(backup_model.named_parameters(), model_copy.named_parameters()):\n",
    "    if n1 == n2:\n",
    "        print((p1 - p2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    if has_deep_attr(model_copy, n):\n",
    "        print(n)\n",
    "        set_deep_attr(model_copy, n, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (n1, p1), (n2, p2) in zip(backup_model.named_parameters(), model_copy.named_parameters()):\n",
    "    if n1 == n2:\n",
    "        print((p1-p2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
