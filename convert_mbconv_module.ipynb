{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mcunet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from mcunet.tinynas.nn.modules import MBInvertedConvLayer\n",
    "from mcunet.tinynas.nn.networks import MobileInvertedResidualBlock\n",
    "from mcunet.model_zoo import build_model\n",
    "\n",
    "from mcunet.utils import MyModule, MyNetwork, SEModule, build_activation, get_same_padding, sub_filter_start_end\n",
    "from mcunet.tinynas.nn.modules import ZeroLayer, set_layer_from_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deep_attr(obj, attrs):\n",
    "    for attr in attrs.split(\".\"):\n",
    "        obj = getattr(obj, attr)\n",
    "    return obj\n",
    "\n",
    "def has_deep_attr(obj, attrs):\n",
    "    try:\n",
    "        get_deep_attr(obj, attrs)\n",
    "        return True\n",
    "    except AttributeError:\n",
    "        return False\n",
    "\n",
    "def set_deep_attr(obj, attrs, value):\n",
    "    for attr in attrs.split(\".\")[:-1]:\n",
    "        obj = getattr(obj, attr)\n",
    "    setattr(obj, attrs.split(\".\")[-1], value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, img_size, desc = build_model(net_id='mcunet-in4', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.0\n",
      "MobileInvertedResidualBlock(\n",
      "  (mobile_inverted_conv): MBInvertedConvLayer(\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "blocks.1\n",
      "MobileInvertedResidualBlock(\n",
      "  (mobile_inverted_conv): MBInvertedConvLayer(\n",
      "    (inverted_bottleneck): Sequential(\n",
      "      (conv): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (depth_conv): Sequential(\n",
      "      (conv): Conv2d(48, 48, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=48, bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU6(inplace=True)\n",
      "    )\n",
      "    (point_linear): Sequential(\n",
      "      (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for n, m in model.named_modules():\n",
    "    if isinstance(m, MobileInvertedResidualBlock):\n",
    "        print(n)\n",
    "        print(m)\n",
    "        count += 2\n",
    "        if count > 3: \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'MobileInvertedResidualBlock',\n",
       " 'mobile_inverted_conv': {'name': 'MBInvertedConvLayer',\n",
       "  'in_channels': 16,\n",
       "  'out_channels': 24,\n",
       "  'kernel_size': 7,\n",
       "  'stride': 2,\n",
       "  'expand_ratio': 3,\n",
       "  'mid_channels': 48,\n",
       "  'act_func': 'relu6',\n",
       "  'use_se': False},\n",
       " 'shortcut': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm  = m.mobile_inverted_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'MBInvertedConvLayer',\n",
       " 'in_channels': 16,\n",
       " 'out_channels': 24,\n",
       " 'kernel_size': 7,\n",
       " 'stride': 2,\n",
       " 'expand_ratio': 3,\n",
       " 'mid_channels': 48,\n",
       " 'act_func': 'relu6',\n",
       " 'use_se': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class MBGumbelInvertedConvLayer(MyModule):\n",
    "    global_kernel_size_list = [3,5,7]\n",
    "    global_expand_ratio_list = [1,3,4,5,6]\n",
    "    def __init__(self, in_channels, out_channels,\n",
    "                 kernel_size=3, stride=1, expand_ratio=6, mid_channels=None, act_func='relu6', use_se=False, **kwargs):\n",
    "        super(MBGumbelInvertedConvLayer, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.max_kernel_size = kernel_size\n",
    "        self.kernel_size_list = []\n",
    "        self.stride = stride\n",
    "        self.max_expand_ratio = expand_ratio\n",
    "        self.expand_ratio_list = []\n",
    "        self.mid_channels = mid_channels\n",
    "        self.act_func = act_func\n",
    "        self.use_se = use_se\n",
    "        \n",
    "        \n",
    "        if self.max_kernel_size in self.global_kernel_size_list:\n",
    "            for kernel in sorted(self.global_kernel_size_list):\n",
    "                if kernel == self.max_kernel_size:\n",
    "                    self.kernel_size_list.append(kernel)\n",
    "                    break\n",
    "                self.kernel_size_list.append(kernel)\n",
    "            \n",
    "            self.kernel_size_list.reverse() # sorted in descending order\n",
    "        \n",
    "        else:\n",
    "            self.kernel_size_list = [self.max_kernel_size]\n",
    "        \n",
    "        if self.max_expand_ratio in self.global_expand_ratio_list:        \n",
    "            for expand in sorted(self.global_expand_ratio_list):\n",
    "                if expand == self.max_expand_ratio:\n",
    "                    self.expand_ratio_list.append(expand)\n",
    "                    break\n",
    "                self.expand_ratio_list.append(expand)\n",
    "        \n",
    "        else:\n",
    "            self.expand_ratio_list = [self.max_expand_ratio]\n",
    "        \n",
    "\n",
    "        if self.mid_channels is None:\n",
    "            feature_dim = round(self.in_channels * self.max_expand_ratio)\n",
    "        else:\n",
    "            feature_dim = self.mid_channels\n",
    "\n",
    "        if self.max_expand_ratio == 1:\n",
    "            self.inverted_bottleneck = None\n",
    "        else:\n",
    "            self.inverted_bottleneck = nn.Sequential(OrderedDict([\n",
    "                ('conv', nn.Conv2d(self.in_channels, feature_dim, 1, 1, 0, bias=False)),\n",
    "                ('bn', nn.BatchNorm2d(feature_dim)),\n",
    "                ('act', build_activation(self.act_func, inplace=True)),\n",
    "            ]))\n",
    "\n",
    "        pad = get_same_padding(self.max_kernel_size)\n",
    "        depth_conv_modules = [\n",
    "            ('conv', nn.Conv2d(feature_dim, feature_dim, kernel_size, stride, pad, groups=feature_dim, bias=False)),\n",
    "            ('bn', nn.BatchNorm2d(feature_dim)),\n",
    "            ('act', build_activation(self.act_func, inplace=True))\n",
    "        ]\n",
    "        if self.use_se:\n",
    "            depth_conv_modules.append(('se', SEModule(feature_dim)))\n",
    "        self.depth_conv = nn.Sequential(OrderedDict(depth_conv_modules))\n",
    "\n",
    "        self.point_linear = nn.Sequential(OrderedDict([\n",
    "            ('conv', nn.Conv2d(feature_dim, out_channels, 1, 1, 0, bias=False)),\n",
    "            ('bn', nn.BatchNorm2d(out_channels)),\n",
    "        ]))\n",
    "\n",
    "        self.kernel_transform_linear_list = nn.ModuleList()\n",
    "        \n",
    "        for i, kernel in enumerate(self.kernel_size_list[1:]):\n",
    "            kernel_linear = nn.Linear(kernel*kernel, kernel*kernel)\n",
    "            self.kernel_transform_linear_list.append(kernel_linear)\n",
    "\n",
    "    def forward(self, x, gumbel=None):\n",
    "        \"\"\"\n",
    "        gumbel: [batch_size, len(self.expand_ratio_list) + len(self.kernel_size_list)]\n",
    "        \"\"\"\n",
    "        if gumbel==None:\n",
    "            if self.inverted_bottleneck:\n",
    "                x = self.inverted_bottleneck(x)\n",
    "            x = self.depth_conv(x)\n",
    "            x = self.point_linear(x)\n",
    "            return x\n",
    "        else:    \n",
    "            if len(self.expand_ratio_list) == 1: ## \n",
    "                if len(self.kernel_size_list) == 1:\n",
    "                    if self.inverted_bottleneck:\n",
    "                        x = self.inverted_bottleneck(x)\n",
    "                    x = self.depth_conv(x)\n",
    "                    x = self.point_linear(x)\n",
    "                    return x\n",
    "                else:\n",
    "                    assert len(gumbel[0]) == len(self.kernel_size_list), \"gumbel size is not match with kernel_size_list\"\n",
    "                    if self.inverted_bottleneck:\n",
    "                        x = self.inverted_bottleneck(x)\n",
    "                    \n",
    "                    depth_weight = self.depth_conv.conv.weight\n",
    "                    pad = get_same_padding(self.max_kernel_size)\n",
    "                    kernel_max_out = F.conv2d(x, depth_weight, stride=self.stride, padding=pad, groups=x.size(1))\n",
    "                    kernel_max_out = self.depth_conv.bn(kernel_max_out)\n",
    "                    kernel_max_out = self.depth_conv.act(kernel_max_out)\n",
    "                    kernel_max_out *= gumbel[:, len(self.expand_ratio_list)].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                    for i, active_kernel_size in enumerate(self.kernel_size_list[1:]):\n",
    "                        start, end = sub_filter_start_end(self.kernel_size_list[i], active_kernel_size)\n",
    "                        print(start, end, active_kernel_size, self.kernel_size_list[i], depth_weight.shape)\n",
    "                        kernel_weight = depth_weight[:, :, start:end, start:end].contiguous()\n",
    "                        kernel_weight = kernel_weight.view(kernel_weight.size(0), kernel_weight.size(1), -1)\n",
    "                        kernel_weight = self.kernel_transform_linear_list[i](kernel_weight)\n",
    "                        kernel_weight = kernel_weight.view(kernel_weight.size(0), kernel_weight.size(1), active_kernel_size, active_kernel_size)\n",
    "                        pad = get_same_padding(active_kernel_size)\n",
    "                        kernel_out = F.conv2d(x, kernel_weight, stride=self.stride, padding=pad, groups=x.size(1))\n",
    "                        kernel_out = self.depth_conv.bn(kernel_out)\n",
    "                        kernel_out = self.depth_conv.act(kernel_out)\n",
    "                        kernel_out *= gumbel[:, len(self.expand_ratio_list) + i + 1].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                        kernel_max_out += kernel_out\n",
    "                    x = kernel_max_out\n",
    "                    if self.use_se:\n",
    "                        x = self.depth_conv.se(x)\n",
    "                    # 3. pointwise convolution weights (out_channels)\n",
    "                    x = self.point_linear(x)\n",
    "                    return x\n",
    "            \n",
    "            elif len(self.kernel_size_list) == 1:\n",
    "                \n",
    "                assert len(gumbel[0]) == len(self.expand_ratio_list), \"gumbel size is not match with expand_ratio_list\"\n",
    "                \n",
    "                if self.inverted_bottleneck:\n",
    "                    # 1. inverted bottleneck weights (max_expand_ratio)\n",
    "                    expand_weight = self.inverted_bottleneck.conv.weight\n",
    "                    expand_max_out = F.conv2d(x, expand_weight, stride=1, padding=0)\n",
    "                    expand_max_out = self.inverted_bottleneck.bn(expand_max_out)\n",
    "                    expand_max_out = self.inverted_bottleneck.act(expand_max_out)\n",
    "                    expand_max_out *= gumbel[:, len(self.expand_ratio_list)].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                    for i, expand_ratio in enumerate(self.expand_ratio_list[:-1]):\n",
    "                        out = F.conv2d(x, expand_weight[:expand_ratio*self.in_channels, :, :, :], stride=1, padding=0)\n",
    "                        out = F.batch_norm(out, self.inverted_bottleneck.bn.running_mean[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.running_var[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.weight[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.bias[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.training, self.inverted_bottleneck.bn.momentum, self.inverted_bottleneck.bn.eps)\n",
    "                        out = self.inverted_bottleneck.act(out)\n",
    "                        out *= gumbel[:, i].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                        out = F.pad(out, [0, 0, 0, 0, 0, expand_max_out.size(1) - out.size(1)], mode='constant', value=0) # zero pad\n",
    "                        expand_max_out += out\n",
    "                    x = expand_max_out\n",
    "                x = self.depth_conv(x)\n",
    "                x = self.point_linear(x)\n",
    "                return x\n",
    "                \n",
    "            elif len(gumbel[0]) == len(self.expand_ratio_list) + len(self.kernel_size_list):\n",
    "                if self.inverted_bottleneck:\n",
    "                    # 1. inverted bottleneck weights (max_expand_ratio)\n",
    "                    expand_weight = self.inverted_bottleneck.conv.weight\n",
    "                    expand_max_out = F.conv2d(x, expand_weight, stride=1, padding=0)\n",
    "                    expand_max_out = self.inverted_bottleneck.bn(expand_max_out)\n",
    "                    expand_max_out = self.inverted_bottleneck.act(expand_max_out)\n",
    "                    expand_max_out *= gumbel[:, len(self.expand_ratio_list)].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                    for i, expand_ratio in enumerate(self.expand_ratio_list[:-1]):\n",
    "                        out = F.conv2d(x, expand_weight[:expand_ratio*self.in_channels, :, :, :], stride=1, padding=0)\n",
    "                        out = F.batch_norm(out, self.inverted_bottleneck.bn.running_mean[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.running_var[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.weight[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.bias[:expand_ratio*self.in_channels], self.inverted_bottleneck.bn.training, self.inverted_bottleneck.bn.momentum, self.inverted_bottleneck.bn.eps)\n",
    "                        out = self.inverted_bottleneck.act(out)\n",
    "                        out *= gumbel[:, i].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                        out = F.pad(out, [0, 0, 0, 0, 0, expand_max_out.size(1) - out.size(1)], mode='constant', value=0) # zero pad\n",
    "                        expand_max_out += out\n",
    "                    x = expand_max_out\n",
    "                # 2. depthwise convolution weights (max_kernel_size)\n",
    "                depth_weight = self.depth_conv.conv.weight\n",
    "                pad = get_same_padding(self.max_kernel_size)\n",
    "                kernel_max_out = F.conv2d(x, depth_weight, stride=self.stride, padding=pad, groups=x.size(1))\n",
    "                kernel_max_out = self.depth_conv.bn(kernel_max_out)\n",
    "                kernel_max_out = self.depth_conv.act(kernel_max_out)\n",
    "                kernel_max_out *= gumbel[:, len(self.expand_ratio_list)].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                for i, active_kernel_size in enumerate(self.kernel_size_list[1:]):\n",
    "                    start, end = sub_filter_start_end(self.kernel_size_list[i], active_kernel_size)\n",
    "                    print(start, end, active_kernel_size, self.kernel_size_list[i], depth_weight.shape)\n",
    "                    kernel_weight = depth_weight[:, :, start:end, start:end].contiguous()\n",
    "                    kernel_weight = kernel_weight.view(kernel_weight.size(0), kernel_weight.size(1), -1)\n",
    "                    kernel_weight = self.kernel_transform_linear_list[i](kernel_weight)\n",
    "                    kernel_weight = kernel_weight.view(kernel_weight.size(0), kernel_weight.size(1), active_kernel_size, active_kernel_size)\n",
    "                    pad = get_same_padding(active_kernel_size)\n",
    "                    kernel_out = F.conv2d(x, kernel_weight, stride=self.stride, padding=pad, groups=x.size(1))\n",
    "                    kernel_out = self.depth_conv.bn(kernel_out)\n",
    "                    kernel_out = self.depth_conv.act(kernel_out)\n",
    "                    kernel_out *= gumbel[:, len(self.expand_ratio_list) + i + 1].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "                    kernel_max_out += kernel_out\n",
    "                x = kernel_max_out\n",
    "                if self.use_se:\n",
    "                    x = self.depth_conv.se(x)\n",
    "                # 3. pointwise convolution weights (out_channels)\n",
    "                x = self.point_linear(x)\n",
    "                return x\n",
    "            else:\n",
    "                assert False, \"gumbel size is not match with expand_ratio_list and kernel_size_list\"\n",
    "            \n",
    "    \n",
    "    @property\n",
    "    def module_str(self):\n",
    "        if self.mid_channels is None:\n",
    "            expand_ratio = self.max_expand_ratio\n",
    "        else:\n",
    "            expand_ratio = self.mid_channels // self.in_channels\n",
    "        layer_str = '%dx%d_GumbelMBConv%d_%s' % (self.max_kernel_size, self.max_kernel_size, expand_ratio, self.act_func.upper())\n",
    "        if self.use_se:\n",
    "            layer_str = 'SE_' + layer_str\n",
    "        layer_str += '_O%d' % self.out_channels\n",
    "        return layer_str\n",
    "\n",
    "    @property\n",
    "    def config(self):\n",
    "        return {\n",
    "            'name': MBGumbelInvertedConvLayer.__name__,\n",
    "            'in_channels': self.in_channels,\n",
    "            'out_channels': self.out_channels,\n",
    "            'kernel_size': self.max_kernel_size,\n",
    "            'kernel_size_list': self.kernel_size_list,\n",
    "            'stride': self.stride,\n",
    "            'expand_ratio': self.max_expand_ratio,\n",
    "            'expand_ratio_list': self.expand_ratio_list,\n",
    "            'mid_channels': self.mid_channels,\n",
    "            'act_func': self.act_func,\n",
    "            'use_se': self.use_se,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def build_from_config(config):\n",
    "        return MBGumbelInvertedConvLayer(**config)\n",
    "    \n",
    "    #@staticmethod\n",
    "    #def build_from_module(module: MBInvertedConvLayer):\n",
    "    #    mbgumbel = MBGumbelInvertedConvLayer.build_from_config(module.config)\n",
    "    #    for n, m in module.named_parameters():\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MobileGumbelInvertedResidualBlock(MyModule):\n",
    "\n",
    "    def __init__(self, mobile_inverted_conv, shortcut):\n",
    "        super(MobileGumbelInvertedResidualBlock, self).__init__()\n",
    "\n",
    "        self.mobile_inverted_conv = mobile_inverted_conv\n",
    "        self.shortcut = shortcut\n",
    "\n",
    "    def forward(self, x, gumbel_idx=None):\n",
    "        if self.mobile_inverted_conv is None or isinstance(self.mobile_inverted_conv, ZeroLayer):\n",
    "            res = x\n",
    "        elif self.shortcut is None or isinstance(self.shortcut, ZeroLayer) and gumbel_idx == None:\n",
    "            res = self.mobile_inverted_conv(x)\n",
    "        elif self.shortcut is None or isinstance(self.shortcut, ZeroLayer) and gumbel_idx != None:\n",
    "            res = self.mobile_inverted_conv(x, gumbel_idx)\n",
    "        elif self.shortcut is not None and gumbel_idx == None:\n",
    "            res = self.mobile_inverted_conv(x) + self.shortcut(x)\n",
    "        else:\n",
    "            res = self.mobile_inverted_conv(x, gumbel_idx) + self.shortcut(x)\n",
    "        return res\n",
    "\n",
    "    @property\n",
    "    def module_str(self):\n",
    "        return '(%s, %s)' % (\n",
    "            self.mobile_inverted_conv.module_str if self.mobile_inverted_conv is not None else None,\n",
    "            self.shortcut.module_str if self.shortcut is not None else None\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def config(self):\n",
    "        return {\n",
    "            'name': MobileGumbelInvertedResidualBlock.__name__,\n",
    "            'mobile_inverted_conv': self.mobile_inverted_conv.config if self.mobile_inverted_conv is not None else None,\n",
    "            'shortcut': self.shortcut.config if self.shortcut is not None else None,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def build_from_config(config):\n",
    "        mobile_inverted_conv = MBGumbelInvertedConvLayer.build_from_config(config['mobile_inverted_conv'])\n",
    "        shortcut = set_layer_from_config(config['shortcut'])\n",
    "        return MobileGumbelInvertedResidualBlock(mobile_inverted_conv, shortcut)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_from_module(module):\n",
    "        if isinstance(module, MobileGumbelInvertedResidualBlock):\n",
    "            print(\"build from gumbel module\")\n",
    "            return module\n",
    "        elif isinstance(module, MobileInvertedResidualBlock):\n",
    "            print(\"build from normal MobileInvertedResidualBlock module\")\n",
    "            mobile_inverted_conv = module.mobile_inverted_conv\n",
    "            shortcut = module.shortcut\n",
    "            return MobileGumbelInvertedResidualBlock(module.mobile_inverted_conv, module.shortcut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GumbelMCUNets(MyNetwork):\n",
    "    def __init__(self, first_conv, blocks, feature_mix_layer, classifier, gumbel_feature_extract_block):\n",
    "        super(GumbelMCUNets, self).__init__()\n",
    "        \n",
    "        self.first_conv = first_conv\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "        self.feature_mix_layer = feature_mix_layer\n",
    "        self.classifier = classifier\n",
    "        self.gumbel_feature_extract_block = gumbel_feature_extract_block\n",
    "        \n",
    "        self.gumbel_index = 0\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            print(i, block.config, type(block))\n",
    "            if i < self.gumbel_feature_extract_block:\n",
    "                continue\n",
    "            if len(block.mobile_inverted_conv.expand_ratio_list) > 1:\n",
    "                self.gumbel_index += len(block.mobile_inverted_conv.expand_ratio_list)\n",
    "                \n",
    "            if len(block.mobile_inverted_conv.kernel_size_list) > 1:\n",
    "                self.gumbel_index += len(block.mobile_inverted_conv.kernel_size_list)\n",
    "        \n",
    "        \n",
    "        self.gumbel_input_channel = blocks[gumbel_feature_extract_block].mobile_inverted_conv.out_channels\n",
    "        \n",
    "        self.avgpool_policy = nn.AdaptiveAvgPool2d((8, 8))\n",
    "        self.gumbel_features_flatten = nn.Flatten()\n",
    "        self.gumbel_fc1 = nn.Linear(self.gumbel_input_channel*8*8, 256)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.gumbel_fc2 = nn.Linear(256, self.gumbel_index)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def module_str(self):\n",
    "        _str = self.first_conv.module_str + '\\n'\n",
    "        for block in self.blocks:\n",
    "            _str += block.module_str + '\\n'\n",
    "        _str += self.feature_mix_layer.module_str + '\\n'\n",
    "        _str += self.classifier.module_str\n",
    "        return _str\n",
    "        \n",
    "    @property\n",
    "    def config(self):\n",
    "        return {\n",
    "            'name': GumbelMCUNets.__name__,\n",
    "            'bn': self.get_bn_param(),\n",
    "            'first_conv': self.first_conv.config,\n",
    "            'blocks': [\n",
    "                block.config for block in self.blocks\n",
    "            ],\n",
    "            'feature_mix_layer': None if self.feature_mix_layer is None else self.feature_mix_layer.config,\n",
    "            'classifier': self.classifier.config,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def build_from_config(net_config, gumbel_config):\n",
    "        MBGumbelInvertedConvLayer.global_expand_ratio_list = gumbel_config['global_expand_ratio_list']\n",
    "        MBGumbelInvertedConvLayer.global_kernel_size_list = gumbel_config['global_kernel_size_list']\n",
    "        gumbel_feature_extract_block = gumbel_config['gumbel_feature_extract_block']\n",
    "        \n",
    "        first_conv = set_layer_from_config(net_config['first_conv'])\n",
    "        feature_mix_layer = set_layer_from_config(net_config['feature_mix_layer'])\n",
    "        classifier = set_layer_from_config(net_config['classifier'])\n",
    "        \n",
    "        blocks = []\n",
    "        \n",
    "        for i, block_config in enumerate(net_config['blocks']):\n",
    "            if i < gumbel_feature_extract_block:\n",
    "                print(i, block_config)\n",
    "                blocks.append(MobileInvertedResidualBlock.build_from_config(block_config))\n",
    "            else:\n",
    "                blocks.append(MobileGumbelInvertedResidualBlock.build_from_config(block_config))\n",
    "        \n",
    "        net = GumbelMCUNets(first_conv, blocks, feature_mix_layer, classifier, gumbel_feature_extract_block)\n",
    "        \n",
    "        if 'bn' in net_config:\n",
    "            net.set_bn_param(**net_config['bn'])\n",
    "        else:\n",
    "            net.set_bn_param(momentum=0.1, eps=1e-3)\n",
    "        \n",
    "        return net\n",
    "    \n",
    "    def load_pretrained_mcunet_param(self, mcunet):\n",
    "        \n",
    "        for n, p in self.named_parameters():\n",
    "            if has_deep_attr(mcunet, n):\n",
    "                print(\"load {} params ({})\".format(n, p.shape))\n",
    "                set_deep_attr(self, n, get_deep_attr(mcunet, n))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'name': 'MobileInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBInvertedConvLayer', 'in_channels': 32, 'out_channels': 16, 'kernel_size': 3, 'stride': 1, 'expand_ratio': 1, 'mid_channels': None, 'act_func': 'relu6', 'use_se': False}, 'shortcut': None}\n",
      "1 {'name': 'MobileInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBInvertedConvLayer', 'in_channels': 16, 'out_channels': 24, 'kernel_size': 7, 'stride': 2, 'expand_ratio': 3, 'mid_channels': 48, 'act_func': 'relu6', 'use_se': False}, 'shortcut': None}\n",
      "0 {'name': 'MobileInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBInvertedConvLayer', 'in_channels': 32, 'out_channels': 16, 'kernel_size': 3, 'stride': 1, 'expand_ratio': 1, 'mid_channels': None, 'act_func': 'relu6', 'use_se': False}, 'shortcut': None} <class 'mcunet.tinynas.nn.networks.proxyless_nets.MobileInvertedResidualBlock'>\n",
      "1 {'name': 'MobileInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBInvertedConvLayer', 'in_channels': 16, 'out_channels': 24, 'kernel_size': 7, 'stride': 2, 'expand_ratio': 3, 'mid_channels': 48, 'act_func': 'relu6', 'use_se': False}, 'shortcut': None} <class 'mcunet.tinynas.nn.networks.proxyless_nets.MobileInvertedResidualBlock'>\n",
      "2 {'name': 'MobileGumbelInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBGumbelInvertedConvLayer', 'in_channels': 24, 'out_channels': 24, 'kernel_size': 3, 'kernel_size_list': [3], 'stride': 1, 'expand_ratio': 5, 'expand_ratio_list': [1, 3, 5], 'mid_channels': 120, 'act_func': 'relu6', 'use_se': False}, 'shortcut': {'name': 'IdentityLayer', 'in_channels': [24], 'out_channels': [24], 'use_bn': False, 'act_func': None, 'dropout_rate': 0, 'ops_order': 'weight_bn_act'}} <class '__main__.MobileGumbelInvertedResidualBlock'>\n",
      "3 {'name': 'MobileGumbelInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBGumbelInvertedConvLayer', 'in_channels': 24, 'out_channels': 24, 'kernel_size': 5, 'kernel_size_list': [5, 3], 'stride': 1, 'expand_ratio': 4, 'expand_ratio_list': [4], 'mid_channels': 96, 'act_func': 'relu6', 'use_se': False}, 'shortcut': {'name': 'IdentityLayer', 'in_channels': [24], 'out_channels': [24], 'use_bn': False, 'act_func': None, 'dropout_rate': 0, 'ops_order': 'weight_bn_act'}} <class '__main__.MobileGumbelInvertedResidualBlock'>\n",
      "4 {'name': 'MobileGumbelInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBGumbelInvertedConvLayer', 'in_channels': 24, 'out_channels': 40, 'kernel_size': 7, 'kernel_size_list': [7, 5, 3], 'stride': 2, 'expand_ratio': 5, 'expand_ratio_list': [1, 3, 5], 'mid_channels': 120, 'act_func': 'relu6', 'use_se': False}, 'shortcut': None} <class '__main__.MobileGumbelInvertedResidualBlock'>\n",
      "5 {'name': 'MobileGumbelInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBGumbelInvertedConvLayer', 'in_channels': 40, 'out_channels': 40, 'kernel_size': 3, 'kernel_size_list': [3], 'stride': 1, 'expand_ratio': 4, 'expand_ratio_list': [4], 'mid_channels': 160, 'act_func': 'relu6', 'use_se': False}, 'shortcut': {'name': 'IdentityLayer', 'in_channels': [40], 'out_channels': [40], 'use_bn': False, 'act_func': None, 'dropout_rate': 0, 'ops_order': 'weight_bn_act'}} <class '__main__.MobileGumbelInvertedResidualBlock'>\n",
      "6 {'name': 'MobileGumbelInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBGumbelInvertedConvLayer', 'in_channels': 40, 'out_channels': 40, 'kernel_size': 7, 'kernel_size_list': [7, 5, 3], 'stride': 1, 'expand_ratio': 4, 'expand_ratio_list': [4], 'mid_channels': 160, 'act_func': 'relu6', 'use_se': False}, 'shortcut': {'name': 'IdentityLayer', 'in_channels': [40], 'out_channels': [40], 'use_bn': False, 'act_func': None, 'dropout_rate': 0, 'ops_order': 'weight_bn_act'}} <class '__main__.MobileGumbelInvertedResidualBlock'>\n",
      "7 {'name': 'MobileGumbelInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBGumbelInvertedConvLayer', 'in_channels': 40, 'out_channels': 80, 'kernel_size': 7, 'kernel_size_list': [7, 5, 3], 'stride': 2, 'expand_ratio': 3, 'expand_ratio_list': [1, 3], 'mid_channels': 120, 'act_func': 'relu6', 'use_se': False}, 'shortcut': None} <class '__main__.MobileGumbelInvertedResidualBlock'>\n",
      "8 {'name': 'MobileGumbelInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBGumbelInvertedConvLayer', 'in_channels': 80, 'out_channels': 80, 'kernel_size': 3, 'kernel_size_list': [3], 'stride': 1, 'expand_ratio': 3, 'expand_ratio_list': [1, 3], 'mid_channels': 240, 'act_func': 'relu6', 'use_se': False}, 'shortcut': {'name': 'IdentityLayer', 'in_channels': [80], 'out_channels': [80], 'use_bn': False, 'act_func': None, 'dropout_rate': 0, 'ops_order': 'weight_bn_act'}} <class '__main__.MobileGumbelInvertedResidualBlock'>\n",
      "9 {'name': 'MobileGumbelInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBGumbelInvertedConvLayer', 'in_channels': 80, 'out_channels': 80, 'kernel_size': 7, 'kernel_size_list': [7, 5, 3], 'stride': 1, 'expand_ratio': 3, 'expand_ratio_list': [1, 3], 'mid_channels': 240, 'act_func': 'relu6', 'use_se': False}, 'shortcut': {'name': 'IdentityLayer', 'in_channels': [80], 'out_channels': [80], 'use_bn': False, 'act_func': None, 'dropout_rate': 0, 'ops_order': 'weight_bn_act'}} <class '__main__.MobileGumbelInvertedResidualBlock'>\n",
      "10 {'name': 'MobileGumbelInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBGumbelInvertedConvLayer', 'in_channels': 80, 'out_channels': 96, 'kernel_size': 3, 'kernel_size_list': [3], 'stride': 1, 'expand_ratio': 4, 'expand_ratio_list': [4], 'mid_channels': 320, 'act_func': 'relu6', 'use_se': False}, 'shortcut': None} <class '__main__.MobileGumbelInvertedResidualBlock'>\n",
      "11 {'name': 'MobileGumbelInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBGumbelInvertedConvLayer', 'in_channels': 96, 'out_channels': 96, 'kernel_size': 5, 'kernel_size_list': [5, 3], 'stride': 1, 'expand_ratio': 3, 'expand_ratio_list': [1, 3], 'mid_channels': 288, 'act_func': 'relu6', 'use_se': False}, 'shortcut': {'name': 'IdentityLayer', 'in_channels': [96], 'out_channels': [96], 'use_bn': False, 'act_func': None, 'dropout_rate': 0, 'ops_order': 'weight_bn_act'}} <class '__main__.MobileGumbelInvertedResidualBlock'>\n",
      "12 {'name': 'MobileGumbelInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBGumbelInvertedConvLayer', 'in_channels': 96, 'out_channels': 96, 'kernel_size': 5, 'kernel_size_list': [5, 3], 'stride': 1, 'expand_ratio': 3, 'expand_ratio_list': [1, 3], 'mid_channels': 288, 'act_func': 'relu6', 'use_se': False}, 'shortcut': {'name': 'IdentityLayer', 'in_channels': [96], 'out_channels': [96], 'use_bn': False, 'act_func': None, 'dropout_rate': 0, 'ops_order': 'weight_bn_act'}} <class '__main__.MobileGumbelInvertedResidualBlock'>\n",
      "13 {'name': 'MobileGumbelInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBGumbelInvertedConvLayer', 'in_channels': 96, 'out_channels': 192, 'kernel_size': 7, 'kernel_size_list': [7, 5, 3], 'stride': 2, 'expand_ratio': 4, 'expand_ratio_list': [4], 'mid_channels': 384, 'act_func': 'relu6', 'use_se': False}, 'shortcut': None} <class '__main__.MobileGumbelInvertedResidualBlock'>\n",
      "14 {'name': 'MobileGumbelInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBGumbelInvertedConvLayer', 'in_channels': 192, 'out_channels': 192, 'kernel_size': 7, 'kernel_size_list': [7, 5, 3], 'stride': 1, 'expand_ratio': 3, 'expand_ratio_list': [1, 3], 'mid_channels': 576, 'act_func': 'relu6', 'use_se': False}, 'shortcut': {'name': 'IdentityLayer', 'in_channels': [192], 'out_channels': [192], 'use_bn': False, 'act_func': None, 'dropout_rate': 0, 'ops_order': 'weight_bn_act'}} <class '__main__.MobileGumbelInvertedResidualBlock'>\n",
      "15 {'name': 'MobileGumbelInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBGumbelInvertedConvLayer', 'in_channels': 192, 'out_channels': 192, 'kernel_size': 5, 'kernel_size_list': [5, 3], 'stride': 1, 'expand_ratio': 3, 'expand_ratio_list': [1, 3], 'mid_channels': 576, 'act_func': 'relu6', 'use_se': False}, 'shortcut': {'name': 'IdentityLayer', 'in_channels': [192], 'out_channels': [192], 'use_bn': False, 'act_func': None, 'dropout_rate': 0, 'ops_order': 'weight_bn_act'}} <class '__main__.MobileGumbelInvertedResidualBlock'>\n",
      "16 {'name': 'MobileGumbelInvertedResidualBlock', 'mobile_inverted_conv': {'name': 'MBGumbelInvertedConvLayer', 'in_channels': 192, 'out_channels': 320, 'kernel_size': 5, 'kernel_size_list': [5, 3], 'stride': 1, 'expand_ratio': 4, 'expand_ratio_list': [4], 'mid_channels': 768, 'act_func': 'relu6', 'use_se': False}, 'shortcut': None} <class '__main__.MobileGumbelInvertedResidualBlock'>\n"
     ]
    }
   ],
   "source": [
    "gubmel_config = {'global_expand_ratio_list':[1,3,5,6], 'global_kernel_size_list':[3,5,7], 'gumbel_feature_extract_block':2}\n",
    "net = GumbelMCUNets.build_from_config(model.config, gubmel_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load first_conv.conv.weight params (torch.Size([32, 3, 3, 3]))\n",
      "load first_conv.bn.weight params (torch.Size([32]))\n",
      "load first_conv.bn.bias params (torch.Size([32]))\n",
      "load blocks.0.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([32, 1, 3, 3]))\n",
      "load blocks.0.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([32]))\n",
      "load blocks.0.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([32]))\n",
      "load blocks.0.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([16, 32, 1, 1]))\n",
      "load blocks.0.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([16]))\n",
      "load blocks.0.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([16]))\n",
      "load blocks.1.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([48, 16, 1, 1]))\n",
      "load blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([48]))\n",
      "load blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([48]))\n",
      "load blocks.1.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([48, 1, 7, 7]))\n",
      "load blocks.1.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([48]))\n",
      "load blocks.1.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([48]))\n",
      "load blocks.1.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([24, 48, 1, 1]))\n",
      "load blocks.1.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([24]))\n",
      "load blocks.1.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([24]))\n",
      "load blocks.2.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([120, 24, 1, 1]))\n",
      "load blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([120]))\n",
      "load blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([120]))\n",
      "load blocks.2.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([120, 1, 3, 3]))\n",
      "load blocks.2.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([120]))\n",
      "load blocks.2.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([120]))\n",
      "load blocks.2.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([24, 120, 1, 1]))\n",
      "load blocks.2.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([24]))\n",
      "load blocks.2.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([24]))\n",
      "load blocks.3.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([96, 24, 1, 1]))\n",
      "load blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([96]))\n",
      "load blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([96]))\n",
      "load blocks.3.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([96, 1, 5, 5]))\n",
      "load blocks.3.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([96]))\n",
      "load blocks.3.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([96]))\n",
      "load blocks.3.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([24, 96, 1, 1]))\n",
      "load blocks.3.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([24]))\n",
      "load blocks.3.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([24]))\n",
      "load blocks.4.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([120, 24, 1, 1]))\n",
      "load blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([120]))\n",
      "load blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([120]))\n",
      "load blocks.4.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([120, 1, 7, 7]))\n",
      "load blocks.4.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([120]))\n",
      "load blocks.4.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([120]))\n",
      "load blocks.4.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([40, 120, 1, 1]))\n",
      "load blocks.4.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([40]))\n",
      "load blocks.4.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([40]))\n",
      "load blocks.5.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([160, 40, 1, 1]))\n",
      "load blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([160]))\n",
      "load blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([160]))\n",
      "load blocks.5.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([160, 1, 3, 3]))\n",
      "load blocks.5.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([160]))\n",
      "load blocks.5.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([160]))\n",
      "load blocks.5.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([40, 160, 1, 1]))\n",
      "load blocks.5.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([40]))\n",
      "load blocks.5.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([40]))\n",
      "load blocks.6.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([160, 40, 1, 1]))\n",
      "load blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([160]))\n",
      "load blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([160]))\n",
      "load blocks.6.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([160, 1, 7, 7]))\n",
      "load blocks.6.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([160]))\n",
      "load blocks.6.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([160]))\n",
      "load blocks.6.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([40, 160, 1, 1]))\n",
      "load blocks.6.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([40]))\n",
      "load blocks.6.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([40]))\n",
      "load blocks.7.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([120, 40, 1, 1]))\n",
      "load blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([120]))\n",
      "load blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([120]))\n",
      "load blocks.7.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([120, 1, 7, 7]))\n",
      "load blocks.7.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([120]))\n",
      "load blocks.7.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([120]))\n",
      "load blocks.7.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([80, 120, 1, 1]))\n",
      "load blocks.7.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([80]))\n",
      "load blocks.7.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([80]))\n",
      "load blocks.8.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([240, 80, 1, 1]))\n",
      "load blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([240]))\n",
      "load blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([240]))\n",
      "load blocks.8.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([240, 1, 3, 3]))\n",
      "load blocks.8.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([240]))\n",
      "load blocks.8.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([240]))\n",
      "load blocks.8.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([80, 240, 1, 1]))\n",
      "load blocks.8.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([80]))\n",
      "load blocks.8.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([80]))\n",
      "load blocks.9.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([240, 80, 1, 1]))\n",
      "load blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([240]))\n",
      "load blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([240]))\n",
      "load blocks.9.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([240, 1, 7, 7]))\n",
      "load blocks.9.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([240]))\n",
      "load blocks.9.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([240]))\n",
      "load blocks.9.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([80, 240, 1, 1]))\n",
      "load blocks.9.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([80]))\n",
      "load blocks.9.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([80]))\n",
      "load blocks.10.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([320, 80, 1, 1]))\n",
      "load blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([320]))\n",
      "load blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([320]))\n",
      "load blocks.10.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([320, 1, 3, 3]))\n",
      "load blocks.10.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([320]))\n",
      "load blocks.10.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([320]))\n",
      "load blocks.10.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([96, 320, 1, 1]))\n",
      "load blocks.10.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([96]))\n",
      "load blocks.10.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([96]))\n",
      "load blocks.11.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([288, 96, 1, 1]))\n",
      "load blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([288]))\n",
      "load blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([288]))\n",
      "load blocks.11.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([288, 1, 5, 5]))\n",
      "load blocks.11.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([288]))\n",
      "load blocks.11.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([288]))\n",
      "load blocks.11.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([96, 288, 1, 1]))\n",
      "load blocks.11.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([96]))\n",
      "load blocks.11.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([96]))\n",
      "load blocks.12.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([288, 96, 1, 1]))\n",
      "load blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([288]))\n",
      "load blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([288]))\n",
      "load blocks.12.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([288, 1, 5, 5]))\n",
      "load blocks.12.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([288]))\n",
      "load blocks.12.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([288]))\n",
      "load blocks.12.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([96, 288, 1, 1]))\n",
      "load blocks.12.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([96]))\n",
      "load blocks.12.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([96]))\n",
      "load blocks.13.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([384, 96, 1, 1]))\n",
      "load blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([384]))\n",
      "load blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([384]))\n",
      "load blocks.13.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([384, 1, 7, 7]))\n",
      "load blocks.13.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([384]))\n",
      "load blocks.13.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([384]))\n",
      "load blocks.13.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([192, 384, 1, 1]))\n",
      "load blocks.13.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([192]))\n",
      "load blocks.13.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([192]))\n",
      "load blocks.14.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([576, 192, 1, 1]))\n",
      "load blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([576]))\n",
      "load blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([576]))\n",
      "load blocks.14.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([576, 1, 7, 7]))\n",
      "load blocks.14.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([576]))\n",
      "load blocks.14.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([576]))\n",
      "load blocks.14.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([192, 576, 1, 1]))\n",
      "load blocks.14.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([192]))\n",
      "load blocks.14.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([192]))\n",
      "load blocks.15.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([576, 192, 1, 1]))\n",
      "load blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([576]))\n",
      "load blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([576]))\n",
      "load blocks.15.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([576, 1, 5, 5]))\n",
      "load blocks.15.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([576]))\n",
      "load blocks.15.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([576]))\n",
      "load blocks.15.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([192, 576, 1, 1]))\n",
      "load blocks.15.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([192]))\n",
      "load blocks.15.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([192]))\n",
      "load blocks.16.mobile_inverted_conv.inverted_bottleneck.conv.weight params (torch.Size([768, 192, 1, 1]))\n",
      "load blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.weight params (torch.Size([768]))\n",
      "load blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.bias params (torch.Size([768]))\n",
      "load blocks.16.mobile_inverted_conv.depth_conv.conv.weight params (torch.Size([768, 1, 5, 5]))\n",
      "load blocks.16.mobile_inverted_conv.depth_conv.bn.weight params (torch.Size([768]))\n",
      "load blocks.16.mobile_inverted_conv.depth_conv.bn.bias params (torch.Size([768]))\n",
      "load blocks.16.mobile_inverted_conv.point_linear.conv.weight params (torch.Size([320, 768, 1, 1]))\n",
      "load blocks.16.mobile_inverted_conv.point_linear.bn.weight params (torch.Size([320]))\n",
      "load blocks.16.mobile_inverted_conv.point_linear.bn.bias params (torch.Size([320]))\n",
      "load classifier.linear.weight params (torch.Size([1000, 320]))\n",
      "load classifier.linear.bias params (torch.Size([1000]))\n"
     ]
    }
   ],
   "source": [
    "net.load_pretrained_mcunet_param(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_conv.conv.weight\n",
      "first_conv.bn.weight\n",
      "first_conv.bn.bias\n",
      "blocks.0.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.0.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.0.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.0.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.0.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.0.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.1.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.1.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.1.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.1.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.1.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.1.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.1.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.1.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.2.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.2.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.2.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.2.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.2.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.2.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.2.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.2.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.3.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.3.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.3.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.3.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.3.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.3.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.3.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.3.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.4.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.4.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.4.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.4.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.4.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.4.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.4.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.4.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.5.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.5.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.5.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.5.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.5.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.5.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.5.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.5.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.6.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.6.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.6.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.6.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.6.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.6.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.6.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.6.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.7.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.7.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.7.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.7.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.7.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.7.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.7.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.7.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.8.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.8.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.8.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.8.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.8.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.8.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.8.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.8.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.9.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.9.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.9.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.9.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.9.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.9.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.9.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.9.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.10.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.10.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.10.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.10.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.10.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.10.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.10.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.10.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.11.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.11.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.11.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.11.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.11.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.11.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.11.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.11.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.12.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.12.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.12.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.12.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.12.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.12.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.12.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.12.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.13.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.13.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.13.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.13.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.13.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.13.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.13.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.13.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.14.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.14.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.14.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.14.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.14.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.14.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.14.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.14.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.15.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.15.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.15.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.15.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.15.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.15.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.15.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.15.mobile_inverted_conv.point_linear.bn.bias\n",
      "blocks.16.mobile_inverted_conv.inverted_bottleneck.conv.weight\n",
      "blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.weight\n",
      "blocks.16.mobile_inverted_conv.inverted_bottleneck.bn.bias\n",
      "blocks.16.mobile_inverted_conv.depth_conv.conv.weight\n",
      "blocks.16.mobile_inverted_conv.depth_conv.bn.weight\n",
      "blocks.16.mobile_inverted_conv.depth_conv.bn.bias\n",
      "blocks.16.mobile_inverted_conv.point_linear.conv.weight\n",
      "blocks.16.mobile_inverted_conv.point_linear.bn.weight\n",
      "blocks.16.mobile_inverted_conv.point_linear.bn.bias\n",
      "classifier.linear.weight\n",
      "classifier.linear.bias\n"
     ]
    }
   ],
   "source": [
    "for n, p in net.named_parameters():\n",
    "    if has_deep_attr(model, n):\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbconv_test = MBGumbelInvertedConvLayer.build_from_config(m.mobile_inverted_conv.config)\n",
    "mbconv_test.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(2, 16, 32, 32)\n",
    "gumbel_inputs = torch.randn(2, 4, 8, 8)\n",
    "gumbel_inputs.requires_grad = True\n",
    "gumbel_layer = nn.Linear(4*8*8, 5)\n",
    "gumbel_output = gumbel_layer(gumbel_inputs.view(2, -1))\n",
    "gumbel_index = F.gumbel_softmax(gumbel_output, tau=1, hard=True)\n",
    "print(gumbel_index)\n",
    "out = mbconv_test.forward(torch.randn(2, 16, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(2, 16, 32, 32)\n",
    "gumbel_inputs = torch.randn(2, 4, 8, 8)\n",
    "gumbel_inputs.requires_grad = True\n",
    "gumbel_layer = nn.Linear(4*8*8, 5)\n",
    "gumbel_output = gumbel_layer(gumbel_inputs.view(2, -1))\n",
    "gumbel_index = F.gumbel_softmax(gumbel_output, tau=1, hard=True)\n",
    "print(gumbel_index)\n",
    "out = mbconv_test.forward(torch.randn(2, 16, 32, 32), gumbel_index)\n",
    "out.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel_layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbconv_test(torch.randn(1, 32, 32, 32), gumbel=[1, 0, 0, 1, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_mbconv_test_weight = copy.deepcopy(mbconv_test.depth_conv.conv.weight)\n",
    "print(original_mbconv_test_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m.mobile_inverted_conv.depth_conv.conv.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in m.mobile_inverted_conv.named_parameters():\n",
    "    if has_deep_attr(mbconv_test, n):\n",
    "        print(n, p)\n",
    "        set_deep_attr(mbconv_test, n, p)\n",
    "        print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in m.mobile_inverted_conv.named_parameters():\n",
    "    if has_deep_attr(mbconv_test, n):\n",
    "        print(n)\n",
    "        print(get_deep_attr(mbconv_test, n) - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbconv_test.forward(torch.randn(1,32,16,16), gumbel=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_layer = nn.BatchNorm2d(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 12, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 12\n",
    "out = F.batch_norm(x, bn_layer.running_mean[:feature_dim], bn_layer.running_var[:feature_dim], bn_layer.weight[:feature_dim], bn_layer.bias[:feature_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, img_size, desc = build_model(net_id='mcunet-in4', pretrained=True)\n",
    "\n",
    "backup_model = copy.deepcopy(model)\n",
    "model_copy = build_model(net_id='mcunet-in4', pretrained=False)[0]\n",
    "\n",
    "for (n1, p1), (n2, p2) in zip(backup_model.named_parameters(), model_copy.named_parameters()):\n",
    "    if n1 == n2:\n",
    "        print((p1 - p2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    if has_deep_attr(model_copy, n):\n",
    "        print(n)\n",
    "        set_deep_attr(model_copy, n, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (n1, p1), (n2, p2) in zip(backup_model.named_parameters(), model_copy.named_parameters()):\n",
    "    if n1 == n2:\n",
    "        print((p1-p2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
