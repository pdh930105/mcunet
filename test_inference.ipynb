{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "sys.path.append('./mcunet')\n",
    "\n",
    "from mcunet.gumbel_module.gumbel_net import GumbelMCUNet\n",
    "from mcunet.gumbel_module.gumbel_layer import MBGumbelInvertedConvLayer, MobileGumbelInvertedResidualBlock, count_conv_gumbel_flops\n",
    "from mcunet.tinynas.nn.modules import MBInvertedConvLayer\n",
    "from mcunet.tinynas.nn.networks import MobileInvertedResidualBlock\n",
    "from mcunet.model_zoo import build_model\n",
    "\n",
    "from mcunet.utils import MyModule, MyNetwork, SEModule, build_activation, get_same_padding, sub_filter_start_end, rm_bn_from_net, get_deep_attr, has_deep_attr\n",
    "from mcunet.tinynas.nn.modules import ZeroLayer, set_layer_from_config\n",
    "\n",
    "from fvcore.nn import FlopCountAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_model, img_size, desc = build_model(net_id='mcunet-in4', pretrained=True)\n",
    "gubmel_config = {'global_expand_ratio_list':[1,3,4,5,6], 'global_kernel_size_list':[3,5,7], 'gumbel_feature_extract_block_idx':2}\n",
    "gumbel_model = GumbelMCUNet.build_from_config(ori_model.config, gubmel_config)\n",
    "gumbel_model.load_pretrained_mcunet_param(ori_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in ori_model.named_parameters():\n",
    "    if has_deep_attr(gumbel_model, n):\n",
    "        gumbel_param = get_deep_attr(gumbel_model, n).data\n",
    "        print(n)\n",
    "        print((p-gumbel_param).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import distrib\n",
    "from src import dataset\n",
    "from src.trainer import Trainer\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = edict()\n",
    "args.db = edict()\n",
    "args.db.name = 'imagenet'\n",
    "args.db.root = '/dataset/ImageNet/Classification/'\n",
    "args.flops_penalty = 0.0\n",
    "args.lr_sched = None\n",
    "args.device = 0\n",
    "args.epochs = 0\n",
    "args.max_norm = 0.5\n",
    "args.continue_from = False\n",
    "args.checkpoint = None\n",
    "args.history_file = None\n",
    "args.restart=False\n",
    "args.num_prints=10\n",
    "args.mixed=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, num_class = dataset.get_loader(args, img_resize=160)\n",
    "data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=4)\n",
    "data= {'tr':train_dataset, 'tt':data_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = None\n",
    "original_flops = 100000\n",
    "ori_trainer = Trainer(data, ori_model.cuda(), criterion, optimizer, args, original_flops)\n",
    "gumbel_trainer = Trainer(data, gumbel_model.cuda(), criterion, optimizer, args, original_flops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_trainer.test(ori_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward original\n",
      "loss : 0.70, acc : 79.69\n",
      "forward original\n",
      "loss : 0.76, acc : 79.49\n",
      "forward original\n",
      "loss : 0.64, acc : 82.81\n",
      "forward original\n",
      "loss : 0.62, acc : 83.98\n",
      "forward original\n",
      "loss : 0.62, acc : 84.06\n",
      "forward original\n",
      "loss : 0.68, acc : 82.88\n",
      "forward original\n",
      "loss : 0.82, acc : 79.63\n",
      "forward original\n",
      "loss : 0.86, acc : 77.78\n",
      "forward original\n",
      "loss : 0.91, acc : 77.17\n",
      "forward original\n",
      "loss : 0.94, acc : 76.17\n",
      "forward original\n",
      "loss : 0.97, acc : 75.36\n",
      "forward original\n",
      "loss : 1.02, acc : 74.22\n",
      "forward original\n",
      "loss : 1.07, acc : 73.26\n",
      "forward original\n",
      "loss : 1.07, acc : 73.07\n",
      "forward original\n",
      "loss : 1.07, acc : 72.99\n",
      "forward original\n",
      "loss : 1.08, acc : 73.12\n",
      "forward original\n",
      "loss : 1.05, acc : 73.74\n",
      "forward original\n",
      "loss : 1.02, acc : 74.59\n",
      "forward original\n",
      "loss : 0.99, acc : 75.29\n",
      "forward original\n",
      "loss : 0.97, acc : 75.55\n",
      "forward original\n",
      "loss : 0.98, acc : 75.73\n",
      "forward original\n",
      "loss : 0.97, acc : 75.87\n",
      "forward original\n",
      "loss : 0.97, acc : 75.99\n",
      "forward original\n",
      "loss : 0.98, acc : 75.90\n",
      "forward original\n",
      "loss : 0.99, acc : 75.61\n",
      "forward original\n",
      "loss : 0.97, acc : 76.23\n",
      "forward original\n",
      "loss : 0.95, acc : 76.65\n",
      "forward original\n",
      "loss : 0.93, acc : 76.93\n",
      "forward original\n",
      "loss : 0.92, acc : 77.33\n",
      "forward original\n",
      "loss : 0.92, acc : 77.27\n",
      "forward original\n",
      "loss : 0.92, acc : 77.18\n",
      "forward original\n",
      "loss : 0.93, acc : 76.93\n",
      "forward original\n",
      "loss : 0.95, acc : 76.29\n",
      "forward original\n",
      "loss : 0.96, acc : 76.00\n",
      "forward original\n",
      "loss : 0.96, acc : 75.97\n",
      "forward original\n",
      "loss : 0.97, acc : 75.77\n",
      "forward original\n",
      "loss : 0.98, acc : 75.31\n",
      "forward original\n",
      "loss : 0.98, acc : 75.07\n",
      "forward original\n",
      "loss : 0.98, acc : 74.96\n",
      "forward original\n",
      "loss : 0.98, acc : 74.89\n",
      "forward original\n",
      "loss : 0.98, acc : 74.83\n",
      "forward original\n",
      "loss : 0.98, acc : 74.79\n",
      "forward original\n",
      "loss : 0.97, acc : 74.94\n",
      "forward original\n",
      "loss : 0.97, acc : 74.85\n",
      "forward original\n",
      "loss : 0.98, acc : 74.80\n",
      "forward original\n",
      "loss : 0.98, acc : 74.66\n",
      "forward original\n",
      "loss : 0.98, acc : 74.49\n",
      "forward original\n",
      "loss : 0.98, acc : 74.43\n",
      "forward original\n",
      "loss : 0.98, acc : 74.22\n",
      "forward original\n",
      "loss : 0.97, acc : 74.51\n",
      "forward original\n",
      "loss : 0.97, acc : 74.66\n",
      "forward original\n",
      "loss : 0.97, acc : 74.65\n",
      "forward original\n",
      "loss : 0.97, acc : 74.54\n",
      "forward original\n",
      "loss : 0.97, acc : 74.57\n",
      "forward original\n",
      "loss : 0.97, acc : 74.50\n",
      "forward original\n",
      "loss : 0.98, acc : 74.37\n",
      "forward original\n",
      "loss : 0.97, acc : 74.49\n",
      "forward original\n",
      "loss : 0.97, acc : 74.73\n",
      "forward original\n",
      "loss : 0.97, acc : 74.79\n",
      "forward original\n",
      "loss : 0.97, acc : 74.70\n",
      "forward original\n",
      "loss : 0.97, acc : 74.57\n",
      "forward original\n",
      "loss : 0.98, acc : 74.46\n",
      "forward original\n",
      "loss : 0.97, acc : 74.61\n",
      "forward original\n",
      "loss : 0.96, acc : 74.85\n",
      "forward original\n",
      "loss : 0.96, acc : 74.93\n",
      "forward original\n",
      "loss : 0.96, acc : 75.09\n",
      "forward original\n",
      "loss : 0.96, acc : 75.13\n",
      "forward original\n",
      "loss : 0.95, acc : 75.16\n",
      "forward original\n",
      "loss : 0.95, acc : 75.15\n",
      "forward original\n",
      "loss : 0.96, acc : 75.01\n",
      "forward original\n",
      "loss : 0.95, acc : 75.03\n",
      "forward original\n",
      "loss : 0.95, acc : 75.10\n",
      "forward original\n",
      "loss : 0.96, acc : 75.07\n",
      "forward original\n",
      "loss : 0.96, acc : 75.07\n",
      "forward original\n",
      "loss : 0.96, acc : 74.88\n",
      "forward original\n",
      "loss : 0.96, acc : 74.88\n",
      "forward original\n",
      "loss : 0.96, acc : 74.92\n",
      "forward original\n",
      "loss : 0.96, acc : 74.93\n",
      "forward original\n",
      "loss : 0.97, acc : 74.75\n",
      "forward original\n",
      "loss : 0.97, acc : 74.71\n",
      "forward original\n",
      "loss : 0.98, acc : 74.49\n",
      "forward original\n",
      "loss : 0.99, acc : 74.30\n",
      "forward original\n",
      "loss : 1.00, acc : 74.20\n",
      "forward original\n",
      "loss : 1.00, acc : 74.19\n",
      "forward original\n",
      "loss : 1.00, acc : 74.12\n",
      "forward original\n",
      "loss : 1.01, acc : 73.92\n",
      "forward original\n",
      "loss : 1.01, acc : 73.84\n",
      "forward original\n",
      "loss : 1.02, acc : 73.74\n",
      "forward original\n",
      "loss : 1.03, acc : 73.62\n",
      "forward original\n",
      "loss : 1.03, acc : 73.55\n",
      "forward original\n",
      "loss : 1.05, acc : 73.27\n",
      "forward original\n",
      "loss : 1.05, acc : 73.17\n",
      "forward original\n",
      "loss : 1.05, acc : 73.24\n",
      "forward original\n",
      "loss : 1.06, acc : 73.09\n",
      "forward original\n",
      "loss : 1.06, acc : 72.90\n",
      "forward original\n",
      "loss : 1.07, acc : 72.75\n",
      "forward original\n",
      "loss : 1.08, acc : 72.60\n",
      "forward original\n",
      "loss : 1.09, acc : 72.42\n",
      "forward original\n",
      "loss : 1.10, acc : 72.22\n",
      "forward original\n",
      "loss : 1.10, acc : 72.14\n",
      "forward original\n",
      "loss : 1.11, acc : 72.03\n",
      "forward original\n",
      "loss : 1.11, acc : 71.99\n",
      "forward original\n",
      "loss : 1.11, acc : 71.82\n",
      "forward original\n",
      "loss : 1.12, acc : 71.71\n",
      "forward original\n",
      "loss : 1.12, acc : 71.71\n",
      "forward original\n",
      "loss : 1.13, acc : 71.62\n",
      "forward original\n",
      "loss : 1.13, acc : 71.57\n",
      "forward original\n",
      "loss : 1.13, acc : 71.59\n",
      "forward original\n",
      "loss : 1.13, acc : 71.59\n",
      "forward original\n",
      "loss : 1.13, acc : 71.54\n",
      "forward original\n",
      "loss : 1.13, acc : 71.52\n",
      "forward original\n",
      "loss : 1.13, acc : 71.59\n",
      "forward original\n",
      "loss : 1.13, acc : 71.63\n",
      "forward original\n",
      "loss : 1.13, acc : 71.62\n",
      "forward original\n",
      "loss : 1.14, acc : 71.44\n",
      "forward original\n",
      "loss : 1.14, acc : 71.32\n",
      "forward original\n",
      "loss : 1.15, acc : 71.25\n",
      "forward original\n",
      "loss : 1.15, acc : 71.10\n",
      "forward original\n",
      "loss : 1.15, acc : 71.13\n",
      "forward original\n",
      "loss : 1.15, acc : 71.21\n",
      "forward original\n",
      "loss : 1.16, acc : 71.10\n",
      "forward original\n",
      "loss : 1.16, acc : 70.90\n",
      "forward original\n",
      "loss : 1.16, acc : 70.91\n",
      "forward original\n",
      "loss : 1.17, acc : 70.77\n",
      "forward original\n",
      "loss : 1.18, acc : 70.62\n",
      "forward original\n",
      "loss : 1.18, acc : 70.59\n",
      "forward original\n",
      "loss : 1.18, acc : 70.58\n",
      "forward original\n",
      "loss : 1.19, acc : 70.50\n",
      "forward original\n",
      "loss : 1.19, acc : 70.39\n",
      "forward original\n",
      "loss : 1.19, acc : 70.29\n",
      "forward original\n",
      "loss : 1.19, acc : 70.31\n",
      "forward original\n",
      "loss : 1.20, acc : 70.25\n",
      "forward original\n",
      "loss : 1.20, acc : 70.21\n",
      "forward original\n",
      "loss : 1.20, acc : 70.18\n",
      "forward original\n",
      "loss : 1.20, acc : 70.13\n",
      "forward original\n",
      "loss : 1.21, acc : 70.05\n",
      "forward original\n",
      "loss : 1.21, acc : 70.06\n",
      "forward original\n",
      "loss : 1.21, acc : 70.02\n",
      "forward original\n",
      "loss : 1.21, acc : 69.93\n",
      "forward original\n",
      "loss : 1.21, acc : 69.97\n",
      "forward original\n",
      "loss : 1.21, acc : 69.95\n",
      "forward original\n",
      "loss : 1.21, acc : 69.97\n",
      "forward original\n",
      "loss : 1.22, acc : 69.85\n",
      "forward original\n",
      "loss : 1.22, acc : 69.81\n",
      "forward original\n",
      "loss : 1.23, acc : 69.77\n",
      "forward original\n",
      "loss : 1.23, acc : 69.68\n",
      "forward original\n",
      "loss : 1.23, acc : 69.60\n",
      "forward original\n",
      "loss : 1.23, acc : 69.57\n",
      "forward original\n",
      "loss : 1.24, acc : 69.53\n",
      "forward original\n",
      "loss : 1.24, acc : 69.46\n",
      "forward original\n",
      "loss : 1.24, acc : 69.48\n",
      "forward original\n",
      "loss : 1.24, acc : 69.41\n",
      "forward original\n",
      "loss : 1.24, acc : 69.38\n",
      "forward original\n",
      "loss : 1.25, acc : 69.33\n",
      "forward original\n",
      "loss : 1.25, acc : 69.29\n",
      "forward original\n",
      "loss : 1.25, acc : 69.23\n",
      "forward original\n",
      "loss : 1.25, acc : 69.28\n",
      "forward original\n",
      "loss : 1.25, acc : 69.24\n",
      "forward original\n",
      "loss : 1.26, acc : 69.12\n",
      "forward original\n",
      "loss : 1.26, acc : 69.08\n",
      "forward original\n",
      "loss : 1.26, acc : 69.11\n",
      "forward original\n",
      "loss : 1.26, acc : 69.03\n",
      "forward original\n",
      "loss : 1.27, acc : 68.99\n",
      "forward original\n",
      "loss : 1.27, acc : 68.82\n",
      "forward original\n",
      "loss : 1.28, acc : 68.75\n",
      "forward original\n",
      "loss : 1.28, acc : 68.66\n",
      "forward original\n",
      "loss : 1.28, acc : 68.70\n",
      "forward original\n",
      "loss : 1.28, acc : 68.65\n",
      "forward original\n",
      "loss : 1.28, acc : 68.59\n",
      "forward original\n",
      "loss : 1.29, acc : 68.55\n",
      "forward original\n",
      "loss : 1.28, acc : 68.58\n",
      "forward original\n",
      "loss : 1.29, acc : 68.50\n",
      "forward original\n",
      "loss : 1.29, acc : 68.43\n",
      "forward original\n",
      "loss : 1.29, acc : 68.43\n",
      "forward original\n",
      "loss : 1.29, acc : 68.39\n",
      "forward original\n",
      "loss : 1.29, acc : 68.36\n",
      "forward original\n",
      "loss : 1.30, acc : 68.33\n",
      "forward original\n",
      "loss : 1.30, acc : 68.19\n",
      "forward original\n",
      "loss : 1.30, acc : 68.22\n",
      "forward original\n",
      "loss : 1.30, acc : 68.25\n",
      "forward original\n",
      "loss : 1.30, acc : 68.20\n",
      "forward original\n",
      "loss : 1.30, acc : 68.17\n",
      "forward original\n",
      "loss : 1.30, acc : 68.22\n",
      "forward original\n",
      "loss : 1.30, acc : 68.26\n",
      "forward original\n",
      "loss : 1.29, acc : 68.32\n",
      "forward original\n",
      "loss : 1.29, acc : 68.33\n",
      "forward original\n",
      "loss : 1.29, acc : 68.40\n",
      "forward original\n",
      "loss : 1.29, acc : 68.37\n",
      "forward original\n",
      "loss : 1.29, acc : 68.35\n",
      "forward original\n",
      "loss : 1.30, acc : 68.27\n",
      "forward original\n",
      "loss : 1.30, acc : 68.23\n",
      "forward original\n",
      "loss : 1.30, acc : 68.23\n",
      "forward original\n",
      "loss : 1.29, acc : 68.32\n",
      "forward original\n",
      "loss : 1.29, acc : 68.42\n",
      "forward original\n",
      "loss : 1.29, acc : 68.48\n",
      "forward original\n",
      "loss : 1.29, acc : 68.44\n",
      "Valid Summary | End of Epoch 1 | Time 70.15s | valid Loss 1.29222 | valid accuracy 68.44\n"
     ]
    }
   ],
   "source": [
    "gumbel_trainer.test(ori_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel_model.eval()\n",
    "ori_model.eval()\n",
    "for n, m in gumbel_model.named_modules():\n",
    "    if has_deep_attr(ori_model, n):\n",
    "        if isinstance(m, MobileGumbelInvertedResidualBlock):\n",
    "            ori_m = get_deep_attr(ori_model, n)\n",
    "            m = m.cuda()\n",
    "            ori_m = ori_m.cuda()\n",
    "            in_c = ori_m.mobile_inverted_conv.in_channels\n",
    "            input_rand_tensor = torch.randn(1, in_c, 16, 16).cuda()\n",
    "            ori_out = ori_m(input_rand_tensor)\n",
    "            out = m(input_rand_tensor)\n",
    "            print(f\"module name : {n}\")\n",
    "            print(\"distance : \", ori_out-out)\n",
    "            print(\"==\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test = torch.randn(1,3, 160, 160).cuda()\n",
    "ori_model = ori_model.cuda()\n",
    "gumbel_model = gumbel_model.cuda()\n",
    "ori_output = ori_model.first_conv(inputs_test)\n",
    "gumbel_output = gumbel_model.first_conv(inputs_test)\n",
    "print(\"difference : \", ori_output - gumbel_output)\n",
    "\n",
    "for i in range(len(ori_model.blocks)):\n",
    "    ori_output = ori_model.blocks[i](ori_output)\n",
    "    gumbel_output = gumbel_model.blocks[i](gumbel_output)\n",
    "    print(f\"{i}'s difference : \", ori_output - gumbel_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_output = ori_output.mean(3).mean(2)\n",
    "gumbel_output = gumbel_output.mean(3).mean(2)\n",
    "ori_output = ori_model.classifier(ori_output)\n",
    "gumbel_output = gumbel_model.classifier(gumbel_output)\n",
    "print(\"difference : \", (ori_output - gumbel_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
